+++
title = "When Every Bulge Bracket Bank Agrees on AI"
seoTitle = "I Read 12 Bank AI Research Reports So You Don't Have To"
date = 2026-03-01
lastmod = 2026-03-01
publishDate = 2026-03-01T03:00:00Z
images = ["https://static.philippdubach.com/ograph/ograph-banks-ai-research1.jpg"]
description = "I read 12 AI research reports from Goldman Sachs, JPMorgan, UBS, and 6 other banks. Here's the consensus they're pushing, and what they're not saying."
keywords = ["AI bubble 2026", "bank AI research reports", "AI capex productivity gap", "second-order AI beneficiaries", "Wall Street AI consensus", "hyperscaler AI spending 2026", "AI investment outlook 2026", "sell-side AI research consensus", "enterprise AI adoption rate", "AI project failure rate", "Goldman Sachs AI report", "Morgan Stanley AI analysis", "AI bubble vs dot-com", "AI capex ROI", "Jevons paradox AI energy", "AI data centre power demand", "AI general-purpose technology", "nuclear energy data centres", "AI infrastructure investment thesis", "AI market concentration risk", "hyperscaler capex ROI 2026", "AI stock market outlook 2026", "AI productivity paradox"]
categories = ["AI", "Investing"]
type = "Analysis"
draft = false
unlisted = false
takeaways = [
  "Not a single report from any of the nine institutions recommends reducing AI exposure. The absence of a bearish voice is itself the most important signal in the entire collection",
  "The macro productivity estimates span from +0.7% to +15% TFP over ten years, using the same underlying academic papers, cherry-picked to support nine different commercial narratives",
  "Only ~10% of US companies are productively using AI and 42% have abandoned GenAI projects. The gap between capex commitment and actual adoption is the most underweighted risk in the consensus",
  "AI capex already contributed 1.4–1.5 percentage points to US GDP growth in H1 2025, making infrastructure spending the dominant driver of US economic expansion in that period",
  "Morgan Stanley's historical data shows second-order beneficiaries outperform first-order enablers by 10–100x over long horizons, yet nearly every bank's current positioning favours first-order plays anyway",
]
faq = [
  {question = "Why are all major banks bullish on AI?", answer = "Every institution covered here (Goldman Sachs, JPMorgan, Morgan Stanley, UBS, Barclays, BofA, HSBC, Citi, Deutsche Bank, Santander) has direct commercial exposure to the AI boom: advisory fees on data centre deals, asset management inflows from AI-themed funds, trading volume from AI volatility, and lending to infrastructure projects. The unanimous bullishness is genuine analysis in some cases, but the incentive to be bullish is overwhelming in all cases. The absence of a single bearish voice from nine institutions with hundreds of billions in AI-related revenue is itself the most important signal in the collection."},
  {question = "Is AI in a bubble like the dot-com crash?", answer = "Banks argue no. Nvidia trades at 25–30x forward earnings versus Cisco's ~140x in 2000, and the Magnificent 6 trade at ~35x versus the TMT peak of ~55x. But a BofA fund manager survey in October 2025 found 54% of global managers believe AI equities are in a bubble. The dot-com PE comparison is reassuring. The market concentration data (top 10 companies at 40% of the S&P 500, the highest in half a century) is alarming. Both are true simultaneously."},
  {question = "What are second-order AI beneficiaries and why do they matter?", answer = "Second-order AI beneficiaries are companies that use AI infrastructure to serve customers, rather than companies that build the infrastructure itself. Morgan Stanley's historical data shows second-order beneficiaries dramatically outperform first-order enablers over long horizons: Walmart (1,622x) vs Ford (23x) in the railroad era; Netflix (519x) vs Cisco (4x) in the internet era. The paradox is that nearly every bank's current investment positioning still favours first-order enablers: Nvidia, ASML, hyperscalers, data centre REITs."},
  {question = "What is the AI capex productivity gap?", answer = "The AI capex productivity gap describes the lag between massive infrastructure investment and measurable productivity gains. Hyperscalers spent over $400 billion on AI capex in 2025. Yet Santander's research shows only ~10% of US companies are productively using AI, and 42% abandoned GenAI projects in 2024. MIT's 2025 GenAI Divide report found 95% of enterprise pilots fail to reach production. The gap is historically normal. Railroads and electricity both required massive upfront investment before productivity arrived, but the timeline and scale of this cycle are uncertain."},
  {question = "How much are hyperscalers spending on AI in 2026?", answer = "Goldman Sachs estimates hyperscalers were spending approximately $800M per day on AI-related capex through 2025, with total hyperscaler capex projected to exceed $500 billion in 2026. UBS reported AI capex grew +67% in 2025. Bank of America, using actual GDP data, found AI capex contributed 1.4–1.5 percentage points to US GDP growth in H1 2025, making it the single largest driver of US economic expansion in that period."},
  {question = "Which bank AI research report is most worth reading?", answer = "Bank of America's 'Economic Shifts in the Age of AI' is the most empirically grounded: every claim is anchored to BLS and BEA data, not projections. Santander's macroeconomic report is the most academically rigorous and most willing to present unflattering adoption statistics. Morgan Stanley's second-order effects report contains the most analytically interesting framework for where value ultimately accrues. Goldman Sachs's 'Powering the AI Era' is the most bullish and the most useful for understanding the infrastructure investment thesis at its strongest."},
]
+++
{{< img src="pdf_covers_overview.png" alt="Cover pages of 12 AI research reports from Goldman Sachs, JPMorgan, Morgan Stanley, UBS, Barclays, Bank of America, HSBC, Citi, Deutsche Bank, and Santander." width="100%" >}}

I spent the last week reading 12 bank AI research reports from nine of the world's largest financial institutions: Goldman Sachs, JPMorgan, Morgan Stanley (three separate reports), UBS, Barclays, Bank of America, HSBC, Citi, Deutsche Bank, and Santander. Not as investment advice. I wasn't looking for stock picks. I wanted to understand how institutions that collectively manage trillions of dollars and employ thousands of analysts actually see this technology heading into 2026: where they agree, where they diverge, and what they're being less than forthcoming about.

What I found is useful, sometimes impressive, and _(mostly)_ worth reading.

## Concerning consensus

Every single institution frames AI as a general-purpose technology, not a product cycle. The analogies converge almost word-for-word: [Goldman Sachs](https://www.goldmansachs.com/what-we-do/investment-banking/insights/articles/powering-the-ai-era/report.pdf) draws the line through railroads, electrification, and telecom. [Santander](https://www.santander.com/en/press-room/the-year-ahead-2025/the-macroeconomic-effects-of-artificial-intelligence) deploys a formal three-stage GPT framework: steam, ICT, AI. [Morgan Stanley's semiconductor team](https://www.morganstanley.com/im/en-us/individual-investor/insights/tales-from-the-emerging-world/ais-silicon-backbone.html) writes that AI is "closer to electricity than consumer gadgets." Deutsche Bank projects **+$7 trillion** in global GDP over the decade. [UBS](https://www.ubs.com/global/en/wealthmanagement/insights/artificial-intelligence.html) puts the AI revenue opportunity at **$2.6 trillion** by 2030.

Not one of the twelve reports seriously entertains the possibility that AI is more like 3D printing: genuinely useful in pockets, broadly disappointing in aggregate. Santander comes closest, citing [Daron Acemoglu's](https://www.nber.org/papers/w32487) conservative **+0.7% cumulative TFP** estimate over ten years, but even Santander frames that as the floor of the range, not the central case. The optimistic end of the same distribution sits at **+10–15%**. That's not a rounding error. It's a fundamental disagreement about whether AI will re-run the productivity miracle of electrification or prove more modest in aggregate, and most banks quietly pick the point on the distribution that best supports their commercial positioning.

The chart below plots each bank by how bullish they are on AI's economic impact against how grounded their analysis is in current empirical data versus forward projections. Bank of America sits alone in the top-right: data-driven and moderately bullish. Goldman sits at the bottom-right: maximally bullish, maximally projective. Santander is the lone occupant of the top-left: empirical and cautious.

{{< img src="exhibit-1-macro-conviction1.png" alt="Bank AI research reports compared on two axes: macro conviction (cautious to bullish) and evidence basis (projective to empirical). BofA is the only data-driven bull. Goldman Sachs is a projective bull. Santander is the only data-driven skeptic. Most institutions cluster in the bullish-projective quadrant." width="90%" >}}

That chart is an editorial interpretation, not a precise measurement. But the shape is right. Bank of America is the only institution that consistently anchors its claims to actual GDP data rather than projections. Goldman Sachs, at the other extreme, produces a report that reads as a pitch to every infrastructure CFO and sovereign wealth fund in the world. Both can be making valid arguments. They're just not making the same kind.

{{< readnext slug="ai-productivity-gap" >}}

## What’s happening vs. what might happen

BofA and Santander are the two worth pausing on, because they're doing something different from the rest: they're reporting what's happening rather than what might happen.

Bank of America, using Bureau of Labor Statistics and Bureau of Economic Analysis data, finds that AI capex contributed **1.4–1.5 percentage points** to US GDP growth in H1 2025. Headline growth rates were running around 2% in that period. So AI infrastructure spending was the single largest driver of US economic expansion. That's a real number from real data, and it's the most important figure in any of these reports.

BofA also finds a *positive* correlation between AI adoption and employment in white-collar sectors: software developers are up **+17.9%**, while insurance appraisers, a role where AI substitutes directly for human judgment, are down **-20%**. The disruption is concentrated in specific tasks. It hasn't shown up in aggregate employment. Yet.

Then there's Santander, which writes the most academically rigorous report of the twelve and includes numbers the consensus would rather not linger on. The enterprise AI adoption rate data is sobering: only around **10% of US companies** are actually using AI to produce goods and services. **42% of companies abandoned GenAI projects in 2024**, a figure corroborated by [MIT's 2025 GenAI Divide research](https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf), which found 95% of enterprise pilots fail to reach production. Only **1%** of companies describe their rollouts as mature. Meanwhile, 78% say they use AI in at least one function. The gap between "we have a pilot" and "this is generating value" is enormous.

Goldman's **$800 million per day** in hyperscaler capex and Santander's 42% abandonment rate aren't as contradictory as they look. Capex precedes productivity in every infrastructure cycle. That part is historically unambiguous. The question is how long the gap lasts, and whether the eventual productivity gains justify what's been spent getting there.

## Dotcom comparison

Every report that addresses the bubble question reaches the same conclusion: this isn't the late 1990s.

The primary evidence is valuation. Nvidia trades at **25–30x forward earnings** versus Cisco's **~140x** at the March 2000 peak. The Magnificent 6 sit at roughly **35x** versus **55x** for the TMT index at its apex. [Morgan Stanley's Silicon Backbone report](https://www.morganstanley.com/im/en-us/individual-investor/insights/tales-from-the-emerging-world/ais-silicon-backbone.html) makes this comparison rigorously, and I think they're right that the earnings quality is categorically different from dot-com era technology stocks.

But the comparison works less cleanly when you look at concentration rather than individual valuations. Deutsche Bank notes that the top 10 S&P 500 companies now represent **40% of total market cap**, an extreme not seen at the dot-com peak. A [Bank of America fund manager survey](https://www.investing.com/news/stock-market-news/bofas-survey-shows-54-of-investors-say-ai-in-bubble-60-say-stocks-overvalued-4284842) from October 2025 found **54% of global managers believe AI equities are in a bubble**, and **60% view global equities as overvalued**. You can simultaneously hold that Nvidia's PE is reasonable and that a portfolio with 40% weight in ten companies carries concentration risk that PE comparisons don't capture. Reassuring on one axis. Alarming on another. Most sell-side AI research cites whichever data point supports its preferred conclusion and leaves the tension sitting there unaddressed.

There's also a subtler version of the bubble question that none of the twelve reports asks directly. The "infrastructure comes before productivity" argument is historically correct: railroads were overbuilt before they transformed commerce; the internet fibre glut of 1999–2000 eventually became the backbone of the digital economy. But the investors who financed Global Crossing and 360networks still lost everything. The infrastructure thesis being correct in the long run isn't the same as every current valuation being justified. Goldman's report is particularly careful to avoid addressing that distinction. The implicit message, "we financed the pipes before and it worked out," skips past the question of which financiers got paid and which got wiped out in the transition.

{{< readnext slug="buying-the-haystack-might-not-work-this-year" >}}

## Sell side

The following chart maps risk awareness against bullishness of tone, and the clustering is revealing.

{{< img src="exhibit-3-risk-bullishness1.png" alt="Goldman Sachs and UBS AI research reports plotted as aggressively bullish and risk-dismissive. Santander and BofA are measured and risk-aware. HSBC is an optimistic hand-waver. Chart maps risk awareness vs bullishness of tone across 12 bank AI research reports." width="90%" >}}

Goldman and UBS are in the bottom-right: aggressively bullish, risk-dismissive. Santander and BofA are in the top-left, actually wrestling with the uncertainty. HSBC is the clearest case of motivated reasoning: the report is written explicitly to stop private banking clients from panic-selling their SaaS positions after multiple quarters of multiple compression. _(Whether that advice turns out to be right is a separate question.)_

I don't think this makes any of these reports dishonest. But the reader needs to supply the discount rate that each institution's interests warrant.

Goldman Sachs earns advisory fees on the data centre and energy deals it describes. Barclays lends to energy infrastructure projects. Morgan Stanley is selling both EM equity exposure and second-order stock-picking strategies through its asset management arm. UBS provides a clean three-layer investment framework that maps directly to its wealth management product shelf. Citi frames AI as accelerating the electronification of markets, the very trend that drives Citi's trading revenue. [Deutsche Bank](https://fortune.com/2026/02/18/will-ai-destroy-jobs-deutsche-bank-asks-ai-to-predict/), most self-aware of the ten, used AI to generate its AI report. The meta-commentary is right there in the methodology.

Not a single report concludes "this may be overhyped and you should meaningfully reduce exposure." Every institution has a commercial interest in the AI narrative staying bullish. That doesn't mean the narrative is wrong. It does mean unanimous conviction from nine sell-side AI research teams is not the same thing as nine independent analyses reaching the same conclusion.

## Second-order AI beneficiaries 

The next two charts contain what I think is the most interesting tension across all twelve reports.

{{< img src="exhibit-2-value-chain1.png" alt="Value chain focus vs time horizon: which banks favour first-order AI enablers (chips, data centres) vs second-order AI beneficiaries (deploying companies). Goldman Sachs and Barclays are near-term first-order plays. Morgan Stanley second-order report sits in long-term deployers quadrant." width="90%" >}}

{{< img src="exhibit-4-disruption-timeline1.png" alt="AI disruption magnitude vs timeline across 12 bank research reports. Goldman Sachs and Barclays expect large near-term disruption. Santander sees incremental long-term change. Morgan Stanley robotics and JPMorgan see radical but distant disruption. BofA sees moderate disruption already underway." width="90%" >}}

[Morgan Stanley's Counterpoint Global team](https://www.morganstanley.com/im/en-us/individual-investor/insights/articles/investing-in-second-order-effects.html), in the second-order effects report, presents historical data that should make the rest of this collection at least slightly uncomfortable. In the railroad era, Walmart's equivalent outperformed Ford's equivalent by **1,622x to 23x**. In the internet era, Netflix returned **519x** versus Cisco's **4x**. It's the same pattern every time: the companies that *use* the infrastructure to serve customers dramatically outperform the companies that *build* it.

Yet nearly every bank's actual investment positioning sits in Nvidia, ASML, hyperscalers, data centre REITs, nuclear utilities, overwhelmingly first-order enablers. Either the historical pattern won't repeat this time (possible, but not argued anywhere in these reports), or there's a valid timing explanation (first-order wins in the buildout phase, second-order wins in deployment) or most of these recommendations will look dated within five years.

Morgan Stanley's own three reports collectively make the case for second-order investing over the long run while still recommending first-order plays in the near term. That's not quite inconsistent. But the tension deserves more acknowledgment than it gets.

{{< readnext slug="the-most-expensive-assumption-in-ai" >}}

## Power

If I had to pick one analytical claim that holds up regardless of where the productivity debate lands, it's this: power is the binding constraint, and the infrastructure required to relieve it is real, expensive, and already being built.

The numbers are consistent across institutions. US data centre power consumption runs at **150–175 TWh** today. [Barclays](https://www.ib.barclays/our-insights/ai-revolution-meeting-massive-infrastructure-demand.html) projects **560 TWh by 2030**, approximately 13% of total US electricity. Goldman Sachs estimates **60%** of new data centre power through 2030 will require net-new generation capacity. The US power grid has an average age of **40 years**. Token consumption grew **4,274%** in a single year. Data centre construction spending has grown roughly **60% year-on-year** since ChatGPT launched in late 2022.

Barclays frames this as a Jevons paradox: efficiency improvements in model inference will, counterintuitively, increase total energy consumption because they make AI cheaper and drive higher usage. I think that's right. It's exactly how personal computing and the internet played out. Every report that addresses energy lands on nuclear as the preferred long-term solution: [four executive orders](https://www.energy.gov/ne/articles/9-key-takeaways-president-trumps-executive-orders-nuclear-energy) in early 2025, a 400 GW capacity target by 2050, the [Three Mile Island restart](https://www.constellationenergy.com/news/2024/Constellation-to-Launch-Crane-Clean-Energy-Center-Restoring-Jobs-and-Carbon-Free-Power-to-The-Grid.html). That consensus may prove correct. It may also be the sector where the infrastructure-before-returns gap runs longest.

## What the reports don't say

The quadrant charts map where the banks are looking. They're less revealing about what's off the frame entirely.

No report models a structured downside scenario: AI capex producing disappointing returns, hyperscalers pulling back, or a major data centre financing default triggering something worse. The closest is Santander's 42% abandonment statistic, but even Santander doesn't ask what happens if that number climbs to 60%.

No report discusses AI safety or alignment risks. [UBS](https://www.ubs.com/global/en/wealthmanagement/insights/artificial-intelligence.html) notes that AI task completion duration has doubled every seven months and explicitly references the AGI trajectory, then moves directly to investment implications, as if "AGI trajectory" carries no risk premium at all. I find that strange.

The collision between AI energy demand and climate commitments gets almost no treatment. Only [Barclays](https://www.ib.barclays/our-insights/ai-revolution-meeting-massive-infrastructure-demand.html) mentions that global CO2 emissions hit a record **37.7 gigatonnes** [in 2023](https://www.iea.org/reports/global-energy-review-2025/co2-emissions). The institutions projecting AI consuming 13% of US electricity by 2030 don't reconcile that with the net-zero commitments in their own sustainability reports.

[JPMorgan](https://www.jpmorganchase.com/content/dam/jpmorganchase/documents/center-for-geopolitics/decoding-the-new-global-operating-system.pdf), which provides the most detailed geopolitical analysis of the twelve, never models a Taiwan Strait disruption scenario. [Morgan Stanley](https://www.morganstanley.com/im/en-us/individual-investor/insights/tales-from-the-emerging-world/ais-silicon-backbone.html) identifies Taiwan, Korea, and China as "irreplaceable" nodes in the AI hardware supply chain, while calling emerging market semiconductor exposure "long-term infrastructure participation." Those two characterisations sit in very uncomfortable proximity, and neither report acknowledges it.

I came away from this with real respect for several of these pieces, particularly BofA's empirical rigour and Santander's willingness to cite unflattering numbers. The energy infrastructure thesis seems to me the most durable of the lot: the power bottleneck is real regardless of where you land on the productivity question.

But I also came away convinced that this consensus is shaped as much by institutional incentive as by analytical independence. When nine institutions with combined AI-related revenue exposure in the hundreds of billions all agree you should increase AI exposure, the interesting question isn't whether they're right. They may well be.