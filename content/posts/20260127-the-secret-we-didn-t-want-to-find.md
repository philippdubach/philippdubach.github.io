---
title: "The Secret We Didn't Want to Find"
date: 2026-01-27
images:
- https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg
description: How large language models challenge our understanding of human consciousness through compression theory and pattern matching.
keywords:
- AI consciousness
- large language models
- compression theory
- human thought
- artificial intelligence philosophy
categories:
- AI
type: Essay
draft: true
---

Douglas Hofstadter spent decades searching for the secret of human thought. His 1979 book "GÃ¶del, Escher, Bach" won a Pulitzer and made him famous. He believed that understanding how minds work would be beautiful, complex, worthy of a lifetime's pursuit. Then GPT-4 arrived. "I'm mind-boggled by some of the things that the systems do," he [told The New Yorker](https://www.newyorker.com/magazine/2025/11/10/the-case-that-ai-is-thinking) this fall. "It would have been inconceivable even only ten years ago."

But here's what struck me most. Hofstadter isn't celebrating. He's mourning. "When I was younger, much younger, I wanted to know what underlay creativity, the mechanisms of creativity. That was a holy grail for me. But now I want it to remain a mystery."

The article introduces Eric Baum's simple claim from 2003: understanding is compression, and compression is understanding. When you truly grasp something, you can represent it more efficiently. A calculator compresses millions of arithmetic examples better than any zip file because it understands the rules. Large language models trained on terabytes of text compress that into something one six-hundredth the size. That compression ratio keeps improving. And as it improves, the models do things we once called thinking. Uri Hasson, a Princeton neuroscientist, put it bluntly: 

>I have the opposite worry of most people. My worry is not that these models are similar to us. It's that we are similar to these models.

There's something almost religious about our resistance to this idea. We want human thought to be special, irreducible, touched by something the universe doesn't hand out to silicon. We built cathedrals to celebrate human consciousness. We wrote poetry about the mystery of the mind. Now a group of researchers applying gradient descent to predict the next word in a sentence have built something that reasons, creates analogies, and grasps what you're talking about. Not perfectly. But well enough to make the old questions feel different.

The article compares AI researchers to nuclear scientists in the 1930s. They knew the implications were grave. They couldn't stop because of curiosity. I think there's a better analogy. In 1953, Francis Crick walked into a Cambridge pub and announced he'd discovered the secret of life. DNA turned out to be a double helix, elegant and simple enough that every high schooler learns it now. Life wasn't demystified exactly, but it became less mysterious. We're still here. We still find meaning. But we know something about ourselves we didn't know before.

Maybe that's where we're headed with thought. Not that machines are conscious in the way we are. Not that there's nothing special about human experience. But that the basic machinery of understanding, the compression and pattern-matching and "seeing as" that lets us navigate the world, might be simpler than we hoped. Simple enough that it emerges from training on text. Simple enough that a high schooler, or a machine, could understand.

Hofstadter wanted the mystery preserved. But mysteries don't stay mysteries because we want them to. They stay mysteries until someone finds the answer.
