<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=.5"><title>Projects - philippdubach</title><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.147.8"><title>Projects - philippdubach</title><meta name=description content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><meta name=keywords content="Finance,Economics,Technology,Data,Machine Learning"><meta property="og:url" content="http://localhost:1313/projects/"><meta property="og:site_name" content="philippdubach"><meta property="og:title" content="Projects"><meta property="og:description" content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Projects"><meta name=twitter:description content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><link rel=canonical href=http://localhost:1313/projects/><link href=/projects/index.xml rel=alternate type=application/rss+xml title=philippdubach><link href=/projects/index.xml rel=feed type=application/rss+xml title=philippdubach><link rel=stylesheet href=/css/custom.css><link rel=icon type=image/png href=/static/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/static/icons/favicon.svg><link rel="shortcut icon" href=/static/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/static/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/static/icons/site.webmanifest><meta name=theme-color content="#434648"></head></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><h1 class=site-title><a href=http://localhost:1313/>philippdubach</a></h1><p class=site-description>Personal Projects, Curated Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Archive</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><div class=posts><article class=post><header class=post-header><div class=post-meta><time datetime=2025-05-30T00:00:00Z>May 30, 2025
</time><span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/05/30/modeling-glycemic-response-with-xgboost/>Modeling Glycemic Response with XGBoost</a></h2></header><div class=post-content><p>Earlier this year I wrote how <a href=/2025/01/02/i-built-a-cgm-data-reader/>I built a CGM data reader</a> afer wearing a continuous glucose monitor myself. Since I was already logging my macronutrients a learning more about molecular biology in an <a href=https://ocw.mit.edu/courses/res-7-008-7-28x-molecular-biology/>MIT MOOC</a> I became curious if given a meal&rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI) could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Personalized Nutrition by Prediction of Glycemic Responses</a> which did exactly that. Yet neither the data nor the code was publicly available. And - I wanted to predict my <em>own</em> glycemic response curve. So I decided to build my own model. In the process I wrote this <a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf>working paper</a>.
<a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf><picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/working_paper_overview.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/working_paper_overview.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/working_paper_overview.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/working_paper_overview.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/working_paper_overview.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/working_paper_overview.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/working_paper_overview.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/working_paper_overview.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/working_paper_overview.jpg" alt="Overview of Working Paper Pages" loading=lazy style=width:100%;height:auto;display:block>
</picture></a>The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Zeevi et al.</a>â€™s approach. I quickly realized that training a model on my own data <em>only</em> was not very promising if not impossible. To tackle this, I used the publicly available <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a> containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper).
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-workflow-graph.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-workflow-graph.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-workflow-graph.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-workflow-graph.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-workflow-graph.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-workflow-graph.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-workflow-graph.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-workflow-graph.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow" loading=lazy style=width:100%;height:auto;display:block>
</picture>Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts).
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-fitted-curve-large1.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-fitted-curve-large1.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-fitted-curve-large1.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-fitted-curve-large1.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-fitted-curve-large1.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements" loading=lazy style=width:100%;height:auto;display:block>
</picture>The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others the majority of postprandial responses were well-captured, though there&rsquo;s clear variation between individuals and meals. Some responses are high amplitude, narrow width, while others are more gradual and prolonged.
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/example-fitted-cgm-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/example-fitted-cgm-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/example-fitted-cgm-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/example-fitted-cgm-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/example-fitted-cgm-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves" loading=lazy style=width:100%;height:auto;display:block>
</picture>I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise I trained three separate XGBoost regressors - one for each Gaussian parameter.</p><p>While the model achieved moderate success predicting amplitude (RÂ² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (RÂ² = -0.76), and curve width prediction was barely better (RÂ² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of RÂ² > 0.7. Studies that have achieved better predictive performance typically used much larger datasets (>1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training data sets, would be necessary.</p><p>The complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my <a href=https://github.com/philippdubach/glucose-response-analysis>GitHub repository</a>.<br>_ _</p><p><em>(10/06/205) Update: Today I came across Marcel SalathÃ©&rsquo;s <a href="https://www.linkedin.com/posts/salathe_myfoodrepo-digitalhealth-precisionnutrition-activity-7337806988082393088-2Lsu?utm_source=share&amp;utm_medium=member_ios&amp;rcm=ACoAADeInT4BJMhtg5DSjxX1jVtIAs5w_KxZm-g">LinkedIn post</a> on a publication out of EPFL: <a href=https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2025.1539118/full>Personalized glucose prediction using in situ data only</a>.</em></p><blockquote><p><em>With data from over 1,000 participants of the Food & You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).</em></p></blockquote><p><em>As expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs RÂ² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a>) represents a fundamental difference in statistical power and generalizability. They adressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the <a href=https://pubmed.ncbi.nlm.nih.gov/38033170/>&ldquo;Food & You&rdquo; study</a> (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).</em></p><p><em>Apart from that I am excited to - at a first glance - observe the following similarities:
(1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications.
(2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (RÂ², RMSE, MAE, Pearson correlation).
(3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics.
(4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC).
(5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning.
(6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.</em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-01-02T00:00:00Z>January 2, 2025
</time><span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/01/02/i-built-a-cgm-data-reader/>I Built a CGM Data Reader</a></h2></header><div class=post-content><p>Last year I put a Continuous Glucose Monitor (CGM) sensor, specifically the <a href=https://www.freestyle.abbott>Abbott Freestyle Libre 3</a>, on my left arm. Why? I wanted to optimize my nutrition for an endurance cycling competitions. Where I live, the sensor is easy to getâ€”without any medical prescriptionâ€”and even easier to use. Unfortunately, Abbott&rsquo;s <a href=https://apps.apple.com/us/app/freestyle-librelink-us/id1325992472>FreeStyle LibreLink</a> app is less than optimal (3,250 other people with an average rating of 2.9/5.0 seem to agree). To their defense, the web app LibreView does offer some nice reports which can be generated as PDFsâ€”not very dynamic, but still something! What I had in mind was more in the fashion of the <a href=https://ultrahuman.com/m1>Ultrahuman M1 dashboard</a>. Unfortunately, I wasn&rsquo;t allowed to use my Libre sensor (EU firmware) with their app (yes, I spoke to customer service).</p><p>At that point, I wasn&rsquo;t left with much enthusiasm, only a coin-sized sensor in my arm. The LibreView website fortunately lets you download most of your (own) data in a CSV report (<em>there is also a <a href=https://github.com/FokkeZB/libreview-unofficial>reverse engineered API</a></em>), which is nice. So that&rsquo;s what I did: download the data, <code>pd.read_csv()</code> it into my notebook, calculate summary statistics, and plot the values.
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/libre-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/libre-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/libre-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/libre-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/libre-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/libre-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/libre-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/libre-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/libre-measurements.jpg" alt="Visualized CGM Datapoints" loading=lazy style=width:100%;height:auto;display:block>
</picture>After some interpolation, I now had the same view as the LibreLink app (which I had rejected earlier) provided. Yet, this setup allowed me to do further analysis and visualizations by adding other datapoints (workouts, sleep, nutrition) I was also collecting at that time:</p><ul><li>Blood sugar from <a href=https://www.libreview.com/>LibreView</a>: Measurement timestamps + glucose values</li><li>Nutrition from <a href=https://macrofactorapp.com/>MacroFactor</a>: Meal timestamps + macronutrients (carbs, protein, and fat)</li><li>Sleep data from <a href=https://sleepcycle.com/>Sleep Cycle</a>: Sleep start timestamp + time in bed + time asleep (+ sleep quality, which is a proprietary measure calculated by the app)</li><li>Cardio workouts from <a href=https://connect.garmin.com/>Garmin</a>: Workout start timestamp + workout duration</li><li>Strength workouts from <a href=https://www.hevyapp.com/>Hevy</a>: Workout start timestamp + workout duration</li></ul><p><picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-dashboard.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-dashboard.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-dashboard.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-dashboard.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-dashboard.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-dashboard.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-dashboard.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-dashboard.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-dashboard.jpg" alt="Final Dashboard" loading=lazy style=width:100%;height:auto;display:block>
</picture>After structuring those datapoints in a dataframe and normalizing timestamps, I was able to quickly highlight sleep (blue boxes with callouts for time in bed, time asleep, and sleep quality) and workouts (red traces on glucose measurements for strength workouts, green traces for cardio workouts) by plotting highlighted traces on top of the historic glucose trail for a set period. Furthermore, I was able to add annotations for nutrition events with the respective macronutrients.</p><p>I asked Claude to create some sample data and streamline the functions to reduce dependencies on the specific data sources I used. The resulting notebook is a comprehensive CGM data analysis tool that loads and processes glucose readings alongside lifestyle data (nutrition, workouts, and sleep), then creates an integrated dashboard for visualization. The code handles data preprocessing including interpolation of missing glucose values, timeline synchronization across different data sources, and statistical analysis with key metrics like time-in-range and coefficient of variation. The main output is a day-by-day dashboard that overlays workout periods, nutrition events, and sleep phases onto continuous glucose monitoring data, enabling users to identify patterns and correlations between lifestyle factors and blood sugar responses.</p><p>You can find the complete <a href=https://github.com/philippdubach/glucose-tracker/blob/fd5992961cfb4630dad439c782430190937414a3/notebooks/data_exploration.ipynb>notebook</a> as well as the sample data in my <a href=https://github.com/philippdubach/glucose-tracker/>GitHub repository</a>.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2024-03-15T00:00:00Z>March 15, 2024
</time><span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2024/03/15/my-first-optimal-portfolio/>My First 'Optimal' Portfolio</a></h2></header><div class=post-content><p>My introduction to quantitative portfolio optimization happened during my undergraduate years, inspired by Attilio Meucci&rsquo;s <a href=https://link.springer.com/book/10.1007/978-3-540-27904-4>Risk and Asset Allocation</a> and the convex optimization <a href=https://web.stanford.edu/~boyd/teaching.html>teachings of Diamond and Boyd at Stanford</a>. With enthusiasm and perhaps more confidence than expertise, I created my first &ldquo;optimal&rdquo; portfolio. What struck me most was the disconnect between theory and accessibility. Modern Portfolio Theory had been established since 1990, yet the optimization tools remained largely locked behind proprietary software.</p><blockquote><p>Nevertheless, only a few comprehensive software models are available publicly to use, study, or modify. We tackle this issue by engineering practical tools for asset allocation and implementing them in the Python programming language.</p></blockquote><p>This gap inspired what would eventually become a published as: <a href=https://digitalcollection.zhaw.ch/handle/11475/24351>A Python integration of practical asset allocation based on modern portfolio theory and its advancements</a>.</p><p>My approach centered on a simple philosophy:</p><blockquote><p>The focus is to keep the tools simple enough for interested practitioners to understand the underlying theory yet provide adequate numerical solutions.</p></blockquote><p>Today, the landscape has evolved dramatically. Projects like <a href=https://github.com/robertmartin8/PyPortfolioOpt>PyPortfolioOpt</a> and <a href=https://github.com/dcajasn/Riskfolio-Lib>Riskfolio-Lib</a> have established themselves as sophisticated open-source alternatives, far surpassing my early efforts in both scope and sophistication. Despite its limitations, the project yielded several meaningful insights:
<picture style="display:block;width:70%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/efficient-frontier.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/efficient-frontier.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/efficient-frontier.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/efficient-frontier.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/efficient-frontier.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/efficient-frontier.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/efficient-frontier.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/efficient-frontier.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/efficient-frontier.jpg" alt="Efficient Frontier Visualization" loading=lazy style=width:100%;height:auto;display:block>
</picture>First I set out to visualize Modern Portfolio Theory&rsquo;s fundamental principleâ€”the risk-return tradeoff that drives optimization decisions. This scatter plot showing the efficient frontier demonstrates said core concept.
<picture style="display:block;width:70%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/results-vs-benchmark-table.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/results-vs-benchmark-table.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/results-vs-benchmark-table.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/results-vs-benchmark-table.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/results-vs-benchmark-table.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/results-vs-benchmark-table.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/results-vs-benchmark-table.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/results-vs-benchmark-table.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/results-vs-benchmark-table.jpg" alt="Benchmark vs Optimized Results" loading=lazy style=width:100%;height:auto;display:block>
</picture>The results of my first optimization: maintaining a 9.386% return while reducing volatility from 14.445% to 5.574%, effectively tripling the Sharpe ratio from 0.650 to 1.684.
<picture style="display:block;width:70%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/risk-aversion-parameters.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/risk-aversion-parameters.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/risk-aversion-parameters.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/risk-aversion-parameters.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/risk-aversion-parameters.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/risk-aversion-parameters.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/risk-aversion-parameters.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/risk-aversion-parameters.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/risk-aversion-parameters.jpg" alt="Risk Aversion Parameter Effects" loading=lazy style=width:100%;height:auto;display:block>
</picture>By varying the risk aversion parameter (gamma), the framework successfully adapted to different investor profiles, showcasing the flexibility of the optimization approach. This efficient frontier plot with different gamma values illustrates how the optimization framework adapts to different investor risk preferences.
<picture style="display:block;width:70%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/oos-performance-table.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/oos-performance-table.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/oos-performance-table.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/oos-performance-table.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/oos-performance-table.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/oos-performance-table.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/oos-performance-table.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/oos-performance-table.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/oos-performance-table.jpg" alt="Out-of-Sample Performance" loading=lazy style=width:100%;height:auto;display:block>
</picture>Perhaps most importantly, out-of-sample testing across diverse market conditionsâ€”including the 2018 bear market and 2019 bull marketâ€”demonstrated consistent CVaR reduction and improved risk-adjusted returns.</p><blockquote><p>We demonstrate how even in an environment with high correlation, achieving a competitive return with a lower expected shortfall and lower excess risk than the given benchmark over multiple periods is possible.</p></blockquote><p>Looking back, the project feels embarrassingly naiveâ€”and surprisingly foundational. While it earned some recognition at the time, it now serves as a valuable reminder: sometimes the best foundation is built before you know enough to doubt yourself.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2024-01-15T00:00:00Z>January 15, 2024
</time><span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2024/01/15/the-tech-behind-this-site/>The Tech behind this Site</a></h2></header><div class=post-content><p>Similar to how Simon Willison describes his difficulties managing images for his <a href=https://simonwillison.net/2024/Dec/22/link-blog/>approach to running a link blog</a> I found it hard to remain true to pure markdown syntax but have images embedded in a responsive way on this site.</p><p>My current pipeline is as follows: I host my all my images in a R2 bucket and serve them from <code>static.philippdubach.com</code>. I use Cloudflares&rsquo;s image resizing CDN do I never have to worry about serving images in appropriate size or format. I basically just upload them with the highes possible quality and Cloudflare takes care of the rest.</p><p>Since the site runs on Hugo, I needed a solution that would work within this static site generation workflow. Pure markdown syntax like <code>![alt](url)</code> is clean and portable, but it doesn&rsquo;t give me the responsive image capabilities I was looking for.</p><p>The solution I settled on was creating a <a href=https://gist.github.com/philippdubach/167189c7090c6813c5110c467cb5ebe9>Hugo shortcode</a> that leverages Cloudflare&rsquo;s image transformations while maintaining a simple, markdown-like syntax.
The shortcode generates a <code>&lt;picture></code> element with multiple <code>&lt;source></code> tags, each targeting different screen sizes and serving WebP format. Here&rsquo;s how it works: instead of writing standard markdown image syntax, I use <code>{{ img src="image.jpg" alt="Description" }}</code> in my posts. Behind the scenes, the shortcode constructs URLs for different breakpoints. This means I upload one high-quality image, but users receive perfectly sized versions - a 320px wide WebP for mobile users, a 1600px version for desktop, and everything in between. The shortcode defaults to displaying images at 80% width and centered, but I can override this with a width parameter when needed. It&rsquo;s a nice compromise between the simplicity of markdown and the power of modern responsive image techniques. The syntax remains clean and the performance benefits are substantial - especially important since images are often the heaviest assets on any webpage.</p></div></article></div></main></div></body></html>