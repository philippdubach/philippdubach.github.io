<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://gc.zgo.at; base-uri 'self';"><meta name=robots content="index, follow"><title>Projects - philippdubach.com</title><meta name=description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=keywords content="Finance,Economics,Technology,Data,Machine Learning"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/projects/><link href=/projects/index.xml rel=alternate type=application/rss+xml title=philippdubach><link href=/projects/index.xml rel=feed type=application/rss+xml title=philippdubach><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#f8f9fa}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#f8f9fa;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;padding-bottom:3rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem;line-height:1.3}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600;line-height:1.3}.post-title a:hover{color:#007acc}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.post-meta a{color:#007acc;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content p:last-child{margin-bottom:.5rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}@supports(text-wrap:balance){.archive-title{text-wrap:balance}}.single .post-title{font-size:1.5rem;margin-bottom:1rem;line-height:1.3}.pagination{margin-top:2rem;margin-bottom:1rem;text-align:center;padding-top:2rem;padding-bottom:1rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}.img-lightbox{cursor:pointer;transition:opacity .2s}.img-lightbox:hover{opacity:.9}.lightbox-overlay{display:none;position:fixed;top:0;left:0;width:100%;height:100%;background:#f8f9fa;z-index:9999;cursor:pointer;align-items:center;justify-content:center;padding:2rem;box-sizing:border-box}.lightbox-overlay:target{display:flex}.lightbox-overlay img{max-width:95%;max-height:95%;object-fit:contain;background:#f8f9fa}.feedback-footer{margin-top:.75rem;padding-top:.75rem;border-top:1px solid #e9ecef;text-align:center;color:#666;font-size:.9rem;margin-bottom:2rem}.feedback-footer p{margin:0;line-height:1.6}.feedback-footer a{color:#007acc;text-decoration:none}.feedback-footer a:hover{text-decoration:underline}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important;padding-bottom:.5rem !important}.pagination{margin-bottom:1.5rem !important;padding-bottom:1.5rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}.post-title,.post-title a,.single .post-title{line-height:1.2 !important}.post-content p:last-child{margin-bottom:.25rem !important}.feedback-footer{margin-top:.5rem !important;padding-top:.5rem !important;margin-bottom:1rem !important}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="Projects"><meta property="og:description" content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/projects/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:type" content="image/jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Projects"><meta name=twitter:description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-post.jpg"></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><h1 class=site-title><a href=http://localhost:1313/>philippdubach</a></h1><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Archive</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><div class=posts><article class=post><header class=post-header><div class=post-meta><time datetime=2025-12-05T00:00:00Z>December 5, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/12/05/how-i-invest-my-money-in-2026/>How I Invest my Money in 2026</a></h2></header><div class=post-content><p>Two lines about my investment philosophy: I have two portfolios: (1) Long term diversified low cost ETFs. (2) Collecting diamonds in front of bulldozers i.e. short term option plays and some stock plays I find interesting. The overall allocation is around 9:1. In this here we are only going to look at portfolio one. But let&rsquo;s start with the conclusion, heres how I will rebalance my portfolio starting 2026:</p><a href=#lightbox-allocation_comparison-png-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/allocation_comparison.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/allocation_comparison.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/allocation_comparison.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/allocation_comparison.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/allocation_comparison.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/allocation_comparison.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/allocation_comparison.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/allocation_comparison.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/allocation_comparison.png" alt="Donut charts comparing 2025 and 2026 asset allocation: Domestic Equities (24%), US Equities (33%), European Equities (10%), Asia Developed (3%), Asia Emerging (10%), Fixed Income (10%), Metals (5%), Alternative Assets (5%)" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-allocation_comparison-png-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/allocation_comparison.png" alt="Donut charts comparing 2025 and 2026 asset allocation: Domestic Equities (24%), US Equities (33%), European Equities (10%), Asia Developed (3%), Asia Emerging (10%), Fixed Income (10%), Metals (5%), Alternative Assets (5%)"></a><p>What changed: -5% US Equities Valuation elevated, less exceptional growth ahead; Avoid double hit from equity normalization + USD depreciation. +5% Europe Fiscal revolution, 22% valuation discount. Natural currency positioning; EUR stable/stronger vs CHF. +3% Fixed Income. Best yields since GFC, rate cuts ahead. Diversification, income; hedge if USD exposure +2% Asia Developed. Japan reforms, Takaichi stimulus | JPY strengthening vs USD (and vs CHF) adds return. +2% Asia EM China tech opportunity, stimulus supporting CNY appreciation vs USD; diversification from developed +2% Alternatives Portfolio resilience, uncorrelated returnsAccess to Swiss private markets; currency matched Metals unchanged Gold strong; copper attractive Inflation hedge; benefits from USD weakness. Since my base currency is CHF I will include an <a href=#fxhedge>FX / hedge section</a> at the end, since this might not apply to everyone. Also <a href=#end>scroll to the end</a> for a short, more technical insight on how I structured my research process.</p><a href=#lightbox-portfolio_performance_transparent-png-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/portfolio_performance_transparent.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/portfolio_performance_transparent.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/portfolio_performance_transparent.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/portfolio_performance_transparent.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/portfolio_performance_transparent.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/portfolio_performance_transparent.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/portfolio_performance_transparent.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/portfolio_performance_transparent.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/portfolio_performance_transparent.png" alt="alt text here" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-portfolio_performance_transparent-png-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/portfolio_performance_transparent.png" alt="alt text here"></a><p>This essay is structured along five themes I believe to be true for 2026:<br><a href=#section1>(1)</a> Market Concentration<br><a href=#section1>(2)</a> US Dollar Depreciation Expected Despite Continued Dominance<br><a href=#section1>(3)</a> AI Investment Remains Central But Requires Scrutiny<br><a href=#section1>(4)</a> European Fiscal Revolution Creates Investment Opportunities<br><a href=#section1>(5) </a>Fixed Income Offers Best Prospects Since Global Financial Crisis</p><p><strong>Market Concentration and High Valuations</strong>: The S&amp;P 500 has become dangerously concentrated: The top 10 companies now represent approximately 38% of the S&amp;P 500&rsquo;s value (a historic concentration level), with Nvidia alone accounting for 7%. This means what was once a diversified investment across 500 companies is now heavily weighted toward a small number of tech giants, many of which are betting heavily on AI.</p><a href=#lightbox-sp500_donut-png-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/sp500_donut.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/sp500_donut.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/sp500_donut.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/sp500_donut.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/sp500_donut.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/sp500_donut.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/sp500_donut.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/sp500_donut.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/sp500_donut.png" alt="Pie chart showing top 7 S&amp;P 500 companies make up 35.63% of the index, with the remaining 493 companies comprising 64.37%" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-sp500_donut-png-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/sp500_donut.png" alt="Pie chart showing top 7 S&amp;P 500 companies make up 35.63% of the index, with the remaining 493 companies comprising 64.37%"></a><blockquote><p>The top 10 US companies dominate the world equity market: Top 5 US tech firms alone have a collective value ($17.6) that exceeds the combined GDP of the Japan, India, UK, France, and Italy ($17.1).</p></blockquote><p><a href=#lightbox-market_cap_comparison-png-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/market_cap_comparison.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/market_cap_comparison.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/market_cap_comparison.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/market_cap_comparison.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/market_cap_comparison.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/market_cap_comparison.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/market_cap_comparison.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/market_cap_comparison.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/market_cap_comparison.png" alt="Bar chart showing top US companies dominate global equity markets, with top 5 tech firms valued at $17.6 trillion, exceeding most national GDPs" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-market_cap_comparison-png-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/market_cap_comparison.png" alt="Bar chart showing top US companies dominate global equity markets, with top 5 tech firms valued at $17.6 trillion, exceeding most national GDPs">
</a><em>Source: Compustat, IBES, FactSet, Goldman Sachs Global Investment Research. As of October 8, 2025 (via Goldman Sachs Investment Outlook 2026)</em></p><p>Even though there might be a consensus view among analysts that elevated valuations are supported by earnings growth rather than multiple expansion alone,</p><blockquote><p>Valuations are especially high in the US. The S&amp;P500 trades at 23 times forward earnings, near the top of its historical range. While the Nasdaq’s 30× trailing P/E is well below the dotcom bubble peak, it still reflects significant optimism. Outside the US, valuations are more moderate: European and Chinese equities are 10% and 7% above their 20-year average valuations, respectively, and Japan’s index trades at a discount to its long-term average. <em>via UBS Year Ahead</em></p></blockquote><p><a href=#lightbox-cape_history-png-4 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cape_history.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cape_history.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cape_history.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cape_history.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cape_history.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cape_history.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cape_history.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cape_history.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cape_history.png" alt="S&amp;P 500 Index Shiller CAPE Ratio (1871-2025)" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cape_history-png-4 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cape_history.png" alt="S&amp;P 500 Index Shiller CAPE Ratio (1871-2025)">
</a><em>Source: Stock Market Data Used in &ldquo;Irrational Exuberance&rdquo; Princeton University Press, 2000, 2005, 2015, updated Robert J. Shiller</em></p><p>Under these circumstances, small-cap and international equities offering more attractive entry points than US large-cap indices. This offers the opportunity to shift part of the US equity holding out of the S&amp;P 500 into a mix of: S&amp;P 500 value index funds (excluding high P/E ratio stocks), mid-cap stocks, international index funds (for geographic diversification), and small-cap stocks (which have more normal valuations and haven&rsquo;t experienced the same speculative growth). This also aligns with my view that <a href=/2025/11/23/is-ai-really-eating-the-world/>the AI boom might not end with a winner-takes-all situation for the hyperscalers</a>.</p><p><strong>US Dollar Depreciation Expected Despite Continued Dominance</strong>: There is a larger consensus among analysts for a continued dollar weakness, with JP Morgan estimating the currency remains ~10% overvalued and Goldman Sachs projecting 4% depreciation over the coming year. Goldman Sachs makes a crucial distinction: dollar dominance in global finance will erode only slowly over decades through structural shifts in trade and GDP share, while dollar valuation can decline much faster due to less exceptional US economic performance and difficulty attracting unhedged capital flows. The key driver is the US&rsquo;s shrinking share of global trade and persistent fiscal deficits, not an imminent collapse of reserve currency status. Which aligns with a lot of the points we outlined in our previous review of <a href=/2025/10/26/pozsars-bretton-woods-iii-three-years-later-2/2/>Pozsar&rsquo;s Bretton Woods III</a>.</p><p>This distinction is clearly visible in historical data: the dollar&rsquo;s share of global reserves has declined gradually from 72% in 1999 to 56% by 2024—a structural erosion occurring over 25 years. In contrast, the trade-weighted dollar index has experienced far more volatile swings, fluctuating between 95 and 130 over the same period, with particularly sharp movements during crisis periods (2008 financial crisis, 2020 pandemic). The dollar can lose 15-20% of its value in just a few years while maintaining its reserve currency dominance. Recent strength to 130 in 2022-2024 appears unsustainable given widening fiscal deficits and declining US share of global trade, suggesting room for significant near-term depreciation even as the dollar&rsquo;s reserve status erodes only gradually.</p><p><a href=#lightbox-dollar_dominance_chart-png-5 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/dollar_dominance_chart.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/dollar_dominance_chart.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/dollar_dominance_chart.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/dollar_dominance_chart.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/dollar_dominance_chart.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/dollar_dominance_chart.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/dollar_dominance_chart.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/dollar_dominance_chart.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/dollar_dominance_chart.png" alt="Dual-axis line chart showing Dollar Share of Global Reserves (declining gradually from 72% in 1999 to 56% in 2024) versus Trade Weighted Dollar Index (fluctuating between 95-130), illustrating slow structural decline in dominance versus faster cyclical valuation changes" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-dollar_dominance_chart-png-5 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/dollar_dominance_chart.png" alt="Dual-axis line chart showing Dollar Share of Global Reserves (declining gradually from 72% in 1999 to 56% in 2024) versus Trade Weighted Dollar Index (fluctuating between 95-130), illustrating slow structural decline in dominance versus faster cyclical valuation changes">
</a><em>Source: IMF COFER (Quarterly) and Federal Reserve FRED Trade-Weighted Dollar Index (Monthly), 1999-2024</em></p><p>The divergence between structural dominance (slow decline) and cyclical valuation (rapid fluctuations) demonstrates that dollar depreciation can occur independently of reserve currency status changes. Gold and the dollar typically move in opposite directions—when the dollar weakens, gold becomes more attractive as an alternative store of value, driving its price higher. The outlook for gold in 2026 reflects a convergence of supportive factors beyond simple dollar weakness. Gold has already broken above $4'000/oz for the first time, driven by &ldquo;persistent inflation volatility and increasing demand from both investors and central banks.&rdquo; The structural case strengthens as central banks accelerate reserve diversification, with official sector gold purchases reaching record levels in 2023-2024 as institutions reduce dollar concentration.</p><p><a href=#lightbox-gold_dollar_chart-png-6 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/gold_dollar_chart.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/gold_dollar_chart.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/gold_dollar_chart.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/gold_dollar_chart.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/gold_dollar_chart.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/gold_dollar_chart.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/gold_dollar_chart.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/gold_dollar_chart.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/gold_dollar_chart.png" alt="Chart comparing Gold prices and Dollar Index from 1985-2024, showing gold's rise from $300 to $2,700 and the dollar's cyclical fluctuations, illustrating their inverse relationship" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-gold_dollar_chart-png-6 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/gold_dollar_chart.png" alt="Chart comparing Gold prices and Dollar Index from 1985-2024, showing gold's rise from $300 to $2,700 and the dollar's cyclical fluctuations, illustrating their inverse relationship">
</a><em>Source: Yahoo Finance GC=F and DX-Y.NYB daily closing prices since January 2000</em></p><p>I modestly increased my FX-hedged gold position from 4.6% to 5.0%, reflecting upgraded return forecasts but keeping the allocation measured given gold&rsquo;s already strong performance (up 45% in 2025). This increase captures institutional conviction without chasing performance. For more on the USD positions see the <a href=#fxhedge>FX / hedge section</a>.</p><p>• <strong>AI Investment Remains Central But Requires Scrutiny</strong>: All four reports position AI as the dominant investment catalyst, with capex projected to reach $571 billion in 2026 (UBS) and potentially $1.3 trillion by 2030. The five largest hyperscalers now account for ~27% of S&amp;P 500 capital expenditure.
<a href=#lightbox-ai_capex_historical-png-7 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/ai_capex_historical.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/ai_capex_historical.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/ai_capex_historical.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/ai_capex_historical.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/ai_capex_historical.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/ai_capex_historical.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/ai_capex_historical.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/ai_capex_historical.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/ai_capex_historical.png" alt="Bar chart of infrastructure investment peaks as % of US GDP. AI capex projections for 2026 (1.9%, $571B) and 2030 (3.8%, $1.3T) would surpass all historical infrastructure booms including Broadband 2000 (1.15%) and Electricity 1949 (0.98%). Asterisks denote projected values from UBS" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-ai_capex_historical-png-7 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/ai_capex_historical.png" alt="Bar chart of infrastructure investment peaks as % of US GDP. AI capex projections for 2026 (1.9%, $571B) and 2030 (3.8%, $1.3T) would surpass all historical infrastructure booms including Broadband 2000 (1.15%) and Electricity 1949 (0.98%). Asterisks denote projected values from UBS">
</a><em>Sources: UBS (2026: $571B projection, 2030: $1.3T projection). Historical comparisons: BEA, Manhattan District History, Federal Highway Administration, company filings.</em></p><p>AI capital expenditure is projected to reach $1.3 trillion by 2030 (3.8% of US GDP), which would exceed all previous infrastructure booms including broadband (1.15%), electricity (0.98%), and the Apollo program (0.74%). However, as UBS notes,</p><blockquote><p>no investment boom has ever seen capital spending perfectly match future demand.</p></blockquote><p>I personally view the current AI boom as potentially speculative at least in terms of the current valuations, with many top S&amp;P companies having inflated price-to-earnings ratios. <a href=/2025/11/23/is-ai-really-eating-the-world/>I&rsquo;m also not convinced that AGI is imminent or that AI model providers will capture most of the economic value, believing AI may become a competitive commodity</a> where value flows to companies using AI rather than those providing it.</p><p>In terms of portfolio allocation the derived actions are consistent with what we outlined in <a href=#section1>(1)</a> Market Concentration and Active Management Opportunity.</p><p>• <strong>European Fiscal Revolution Creates Investment Opportunities</strong>: Germany&rsquo;s historic abandonment of its debt brake policy, committing over €1 trillion to infrastructure, defense, and security spending (with an additional €600 billion in private sector commitments), represents a paradigm shift. JP Morgan upgrades eurozone growth to 1.5% and Goldman Sachs identifies a &ldquo;new paradigm&rdquo; focused on defense independence, energy security, and reindustrialization. This fiscal activism is expected to narrow the US-Europe growth differential from 60bps to 30bps, making European equities—currently trading at a 22% discount to global peers—increasingly attractive despite elevated valuations elsewhere.</p><p>• <strong>Fixed Income Offers Best Prospects Since Global Financial Crisis</strong>: Higher starting yields and steeper curves have dramatically improved bond return potential, with JP Morgan forecasting 10-year US Treasuries to deliver 4.6% and expecting medium-duration quality bonds to generate &ldquo;mid-single-digit returns.&rdquo; All reports project 2-3 additional Fed rate cuts in 2026, while the ECB is expected to hold steady and the Bank of Japan to continue hiking. Goldman Sachs emphasizes that &ldquo;front-end yields are more sensitive to central bank policy and offer strong counter-cyclical properties,&rdquo; while fiscal concerns drive term-risk premia higher at the long end, benefiting strategic curve positioning.</p><p><a href=#lightbox-historic_crisis_returns-png-8 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/historic_crisis_returns.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/historic_crisis_returns.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/historic_crisis_returns.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/historic_crisis_returns.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/historic_crisis_returns.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/historic_crisis_returns.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/historic_crisis_returns.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/historic_crisis_returns.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/historic_crisis_returns.png" alt="Bar chart showing 60/40 portfolio returns minus cash at 1-year and 3-year intervals after major crises (1990-2022). Average returns: 7% at 1-year, 22% at 3-year" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-historic_crisis_returns-png-8 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/historic_crisis_returns.png" alt="Bar chart showing 60/40 portfolio returns minus cash at 1-year and 3-year intervals after major crises (1990-2022). Average returns: 7% at 1-year, 22% at 3-year">
</a><em>Source: Bloomberg, NBER, J.P. Morgan Asset Management; data as of September 2025. See Dario Caldara and Matteo Iacoviello, “Measuring Geopolitical Risk,” American Economic Review, 112, no. 4, April 2022. (via: J.P.Morgan Asset Management 2026 Long-Term Capital Market Assumptions)</em></p><blockquote><p>It is shocking how little geopolitics actually matters to markets unless it gets truly terrible.</p></blockquote><p>Michael Cembalest, Chairman of Market and Investment Strategy, J.P. Morgan Asset & Wealth Management</p><p>After market shocks, a 60/40 portfolio beats cash 75% of the time by an average of 7% after one year, and 100% of the
time by an average of 22% after three years
Exhibit 5: Performance of a 60/40 portfolio vs. cash if invested one month before a market shock</p><p>• <strong>Private Markets Show Valuation Stress But Selective Opportunities Remain</strong>: JP Morgan and Goldman Sachs provide extensive analysis revealing that ~15% of private credit borrowers cannot cover interest payments with operating profits, and private equity holding valuations appear elevated with general partners willing to accept 11-20% discounts in 25% of cases to exit positions. However, both firms view this as manageable rather than systemic, with Goldman Sachs noting that &ldquo;borrowers with coverage ratios above 1.5x (representing 55-60% of the market)&rdquo; have sufficient equity cushions. The critical distinction is vintage year: 2021-2022 investments face challenges from peak valuations, while 2018-2020 vintages remain &ldquo;positioned for attractive returns.&rdquo; Manager selection and entry timing are paramount.</p><p><a href=#lightbox-returns_heatmap-png-9 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/returns_heatmap.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/returns_heatmap.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/returns_heatmap.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/returns_heatmap.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/returns_heatmap.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/returns_heatmap.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/returns_heatmap.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/returns_heatmap.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/returns_heatmap.png" alt="Performance heatmap showing returns ranking for major asset classes across periods from 1995-2025, with each asset color-coded consistently across all time periods" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-returns_heatmap-png-9 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/returns_heatmap.png" alt="Performance heatmap showing returns ranking for major asset classes across periods from 1995-2025, with each asset color-coded consistently across all time periods">
</a><em>Source: Bloomberg, Datastream, Haver, J.P. Morgan Asset Management; data as of September 2025. IG: investment grade; HY: high yield. HFRI FOF is the
HFRI hedge fund of funds composite total return index. (via: J.P.Morgan Asset Management 2026 Long-Term Capital Market Assumptions)</em></p><p>Over the last 30 years, equities, gold and REITs are winners, but the 60/40 has delivered steady returns in most time periods Relative performance of selected assets over discrete five-year periods from 1995-2025</p><a href=#lightbox-allocation_comparison_bars-png-10 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/allocation_comparison_bars.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/allocation_comparison_bars.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/allocation_comparison_bars.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/allocation_comparison_bars.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/allocation_comparison_bars.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/allocation_comparison_bars.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/allocation_comparison_bars.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/allocation_comparison_bars.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/allocation_comparison_bars.png" alt="Horizontal bar chart comparing 2025 and 2026 portfolio allocations across 8 asset classes, showing US Equities decreasing 4.4% (from 32.4% to 28.0%) and European Equities increasing 3.0% (from 10.2% to 13.2%)" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-allocation_comparison_bars-png-10 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/allocation_comparison_bars.png" alt="Horizontal bar chart comparing 2025 and 2026 portfolio allocations across 8 asset classes, showing US Equities decreasing 4.4% (from 32.4% to 28.0%) and European Equities increasing 3.0% (from 10.2% to 13.2%)"></a><p>** Other points to consider **</p><p>(1) Economic Growth Outlook</p><p>UBS: Global growth resilient, accelerating through year
JP Morgan: US growth 1.8% (down from 2.0%), global 2.5% unchanged
GS Report 1: US growth discussed in context of dollar implications
GS Report 2: Focus on &ldquo;less exceptional&rdquo; US performance</p><p>(2) Inflation and Monetary Policy</p><p>UBS: Persistent pricing pressures, inflation volatility
JP Morgan: Higher inflation volatility, elevated inflation expectations
GS Report 1: Inflation as factor in dollar weakness
GS Report 2: Fed easing cycles as catalyst; 12% US effective tariff rate</p><p>(3) Fiscal Activism/Government Spending</p><p>UBS: European fiscal stimulus, German infrastructure spending
JP Morgan: Fiscal activism as core theme; Germany&rsquo;s €1 trillion spending bill
GS Report 1: Fiscal deficits as dollar weakness driver
GS Report 2: European fiscal expansion, infrastructure investment</p><p>(4) Trade Policy/Economic Nationalism</p><p>UBS: Trade tensions as risk factor
JP Morgan: Economic nationalism as key theme; tariffs at highest since 1934
GS Report 1: Trade policy reshaping global dynamics
GS Report 2: 12% US effective tariff rate; new trade order</p><p>(5) China Market Outlook</p><p>UBS: China tech sector as top global opportunity
JP Morgan: China TFP raised to 1.0%; technology-intensive investment
GS Report 1: Yuan appreciation expected
GS Report 2: China stimulus supporting equity market</p><p>(6) Fixed Income/Bond Outlook</p><p>UBS: Quality bonds offer attractive yields
JP Morgan: Better starting valuations boost bond returns; 4.6% 10-year UST
GS Report 1: Higher term-risk premia
GS Report 2: Fixed income opportunities in easing cycle</p><p>(7) Geopolitical Risks</p><p>UBS: Russia-Ukraine, Middle East tensions
JP Morgan: Geopolitical risks remain high
GS Report 1: Geopolitical factors in dollar dynamics
GS Report 2: Gaza ceasefire, ongoing tensions</p><p>(8) Crypto</p><details><summary>Full Breakdown of 2026 Asset Allocation [EXPAND]</summary><div class=table-container style="width:100%;overflow-x:auto;margin:2rem 0"><iframe src=https://static.philippdubach.com/html/allocation_table2.html style="width:100%;height:850px;border:none;background:0 0" scrolling=auto></iframe></div></details><br><section id=fxhedge></section>** Section on FX risk here**<details><summary>Currency Exposure Breakdown [EXPAND]</summary><div class=table-container style="width:100%;overflow-x:auto;margin:2rem 0"><iframe src=https://static.philippdubach.com/html/currency_exposure.html style="width:100%;height:700px;border:none;background:0 0" scrolling=auto></iframe></div></details><p>For CHF-based investors specifically, gold&rsquo;s appeal is amplified through multiple channels. First, the expected 4-10% dollar depreciation translates directly into higher gold prices in dollar terms, but CHF-hedged gold exposure (as in our iShares CH Gold CHF Hedged ETF position) isolates this return from currency fluctuations, capturing gold&rsquo;s intrinsic move. Second, gold serves as a portfolio stabilizer during periods when stock-bond correlations turn positive—a risk all three reports highlight given higher inflation volatility. Goldman Sachs notes that gold has historically provided &ldquo;returns that are uncorrelated to public markets&rdquo; and particularly shines during &ldquo;negative supply shocks and fiscal misbehavior shocks&rdquo; where traditional bonds fail as hedges. Third, the structural de-dollarization trend, while slow, creates persistent buying pressure from official institutions seeking alternatives to dollar reserves.</p><p>Given this outlook, our portfolio adjustments incorporate three specific responses. First, we maintain full CHF hedging on our US equity exposure (28% of portfolio via iShares S&amp;P 500 CHF Hedged ETF), protecting against the 4-10% dollar depreciation consensus while capturing US equity returns. This hedging decision is critical—an unhedged 28% US position would face potential currency losses of 1.1-2.8% even if US stocks perform well in local terms.</p><p>Third, we leave our European (13.2%), Japanese (3.2%), and emerging Asian (12.5%) equity exposures unhedged, as these currencies are expected to strengthen against the dollar (EUR to 1.20, JPY to 118, CNY appreciation of ~10%). For CHF investors, this creates a favorable dynamic where European fiscal stimulus and Asian growth drive equity gains while currency movements provide additional tailwinds rather than headwinds.</p><p>The combination of hedged US exposure, increased gold allocation, and strategic unhedged positions in appreciating-currency markets represents a balanced approach to the dollar depreciation thesis. It protects against the downside (dollar losses on US assets) while capturing upside (currency gains on non-US assets and gold&rsquo;s inverse correlation to the dollar). For context, if the dollar depreciates 7% (midpoint of forecasts) over 2026, an unhedged US equity portfolio would require 7% local currency gains just to break even in CHF terms, while our hedged approach requires no such offset. Meanwhile, our 4.9% gold position benefits from both dollar weakness and structural central bank demand, potentially contributing 0.25-0.30% to total portfolio returns (5.5% return on 4.9% allocation) with low correlation to other holdings. This positioning aligns with Goldman Sachs&rsquo; observation that &ldquo;in a world of evolving megatrends,&rdquo; combining &ldquo;growth assets with real assets like gold&rdquo; creates resilience against multiple macro scenarios including dollar depreciation, inflation surprises, and geopolitical shocks.</p><p>Position Current Hedge Status Recommended Action Rationale
S&amp;P 500 (30%) CHF hedged Keep hedged Correct - protects from USD depreciation
Gold (5%) CHF hedged Keep hedged Correct - isolates gold returns from USD
Euro Stoxx 50 (15%) Unhedged EUR Leave unhedged EUR stable/stronger vs CHF expected
Japan (4%) Unhedged JPY Leave unhedged JPY appreciation is part of thesis
EM IMI (10%) Unhedged (mixed) Leave unhedged Natural diversification across EM currencies
Hang Seng Tech (2%) Unhedged CNY/HKD Leave unhedged CNY appreciation expected
Global Agg Bond (12%) Verify! Must be CHF hedged Duration + currency risk too much
New Infrastructure (2%) TBD Prefer hedged if available Isolate infrastructure returns
New Alternatives (2%) TBD Prefer hedged if US/global Isolate equity beta from FX</p><section id=end></section><p>But how did we get here: (1) After combing through insights and data from analyst and research outlooks by <a href=https://am.gs.com/en-hk/advisors/insights/article/investment-outlook>Goldman Sachs Asset Management</a>, <a href=https://am.jpmorgan.com/content/dam/jpm-am-aem/global/en/insights/portfolio-insights/ltcma/noindex/ltcma-full-report.pdf>J.P. Morgan Asset Management</a>, <a href=https://www.morganstanley.com/insights/articles/stock-market-investment-outlook-2026>Morgan Stanley</a>, and <a href=https://www.ubs.com/global/en/wealthmanagement/insights/year-ahead-registration.html>UBS Investment Research</a>. (2) I wrote a <a href=https://gist.github.com/philippdubach/0087fdaefb8ca905e5df87176c1a31e3>script to convert large PDSs to Markdown</a> and optimise them for LLM processing. (3) I then Claude agents to look for differences and similarities in the reports <a href=https://gist.github.com/philippdubach/5ebd726295f2fac39915d535000ce63a>which created an extensive overview</a> (4)that then served, together with my own thoughts and opinions, as the basis for my 2026 Allocation.</p><p><em>I created the graphs with python, if you you&rsquo;re interested in that, you can find the code on <a href>GitHub</a>.</em></p><p><em><h6>This article is for informational purposes only, you should not consider any information or other material on this site as investment, financial, or other advice. There are risks associated with investing.</h6></em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-11-30T00:00:00Z>November 30, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/11/30/deploying-to-production-with-ai-agents-testing-cursor-on-azure/>Deploying to Production with AI Agents: Testing Cursor on Azure</a></h2></header><div class=post-content><p>I&rsquo;ve been curious about <a href=https://cursor.com/features>Cursor&rsquo;s capabilities</a> for a while, but never had a good reason to try it. This weekend I decided to host my own URL shortener and deployed <a href=https://yourls.org>YOURLS</a>, a free and open-source link shortener, on a fresh Azure VM. It seemed like a solid test case since it involves SSH access, server configuration, database setup, and SSL certificates. If an AI assistant could handle that end-to-end, it would be genuinely useful.</p><p>I was honestly surprised. Cursor didn&rsquo;t just write commands it connected via SSH, navigated the server, installed dependencies, configured Apache virtual hosts, set up MySQL, and handled the SSL certificate setup. It made sensible decisions about file permissions, security settings, and configuration details. When I asked for a custom YOURLS plugin to add date prefixes to short URLs, it built it on the first try. The whole build and deployment took about 15 minutes, which previously took me at least an hour of manual work and troubleshooting.</p><p>The URL shortener is now live and working. You can find this article at <a href=https://pdub.click/2511308>pdub.click/2511308</a>. I made the full scrubbed <a href=https://gist.github.com/philippdubach/d913591f906447041e2752729cd406e5>transcript available</a> if you want to see exactly how Cursor handled each step. If you want to do this installation yourself, I wrote a <a href=https://philippdubach.com/standalone/yourls-azure-tutorial/>step-by-step tutorial</a> covering the entire process, or you might as well let Cursor do it.</p><p>Right after finishing, I closed my laptop and went to clean my bathroom. This reminded me of <a href="https://x.com/AuthorJMac/status/1773679197631701238?lang=en">Joanna Maciejewska&rsquo;s quote</a>:</p><blockquote><p>I want AI to do my laundry and dishes so that I can do art and writing, not for AI to do my art and writing so that I can do laundry and dishes.</p></blockquote></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-08-23T00:00:00Z>August 23, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/08/23/visualizing-gradients-with-pytorch/>Visualizing Gradients with PyTorch</a></h2></header><div class=post-content><p><a href=https://en.wikipedia.org/wiki/Gradient>Gradients</a> are one of the most important concepts in calculus and machine learning, but it&rsquo;s often poorly understood. Trying to understand them better myself, I wanted to build a visualization tool that helps me develop the correct mental picture of what the gradient of a function is. I came across <a href=https://github.com/GistNoesis/VisualizeGradient>GistNoesis/VisualizeGradient</a>, so I went on from there to write my own iteration. This mental model generalizes beautifully to higher dimensions and is crucial for understanding optimization algorithms.
<a href=#lightbox-torch-gradients_Figure_2-png-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/torch-gradients_Figure_2.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/torch-gradients_Figure_2.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/torch-gradients_Figure_2.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/torch-gradients_Figure_2.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/torch-gradients_Figure_2.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/torch-gradients_Figure_2.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/torch-gradients_Figure_2.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/torch-gradients_Figure_2.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/torch-gradients_Figure_2.png" alt="2D Gradient Plot: The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-torch-gradients_Figure_2-png-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/torch-gradients_Figure_2.png" alt="2D Gradient Plot: The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent.">
</a><em>The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent.</em></p><p>If you are interested in having a closer look or replicating my approach, the full project can be found on my <a href=https://github.com/philippdubach/torch-gradients/>GitHub</a>. I&rsquo;m also looking forward to doing something similar on the <a href=https://blog.foletta.net/post/2025-07-14-clt/>Central Limit Theorem</a> as well as doing a short tutorial on <a href=https://static.philippdubach.com/opt_vol_surface_plot_fig1.png>plotting options volatility surfaces with python</a>, a project I have been waiting to finish for some time now.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-07-06T00:00:00Z>July 6, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/07/06/counting-cards-with-computer-vision/>Counting Cards with Computer Vision</a></h2></header><div class=post-content><p>After installing <a href=https://www.anthropic.com/claude-code>Claude Code</a></p><blockquote><p>the agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster through natural language commands</p></blockquote><p>I was looking for a task to test its abilities. Fairly quickly we wrote <a href=https://gist.github.com/philippdubach/741cbd56498e43375892966ca691b9c2>less than 200 lines of python code predicting black jack odds</a> using Monte Carlo Simulation. When I went on to test this little tool on <a href=https://games.washingtonpost.com/games/blackjack>Washington Post&rsquo;s</a> online Black Jack (I also didn&rsquo;t know that existed!) I quickly noticed how impractical it was to manually input all the card values on the table manually. What if the tool would also automatically recognize the cards that are on the table and calculate the odds from it? I have never done anything with computer vision so this seemed like a good challenge.
<a href=#lightbox-classification-gif-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/classification.gif 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/classification.gif 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/classification.gif 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/classification.gif 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/classification.gif 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/classification.gif 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/classification.gif 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/classification.gif 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/classification.gif" alt="alt text here" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-classification-gif-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/classification.gif" alt="alt text here">
</a>To get to any reasonable result we have to start with classification where we &ldquo;teach&rdquo; the model to categorize data by showing them lots of examples with correct labels. But where do the labels come from? I manually annotated <a href=https://universe.roboflow.com/cards-agurd/playing_card_classification>409 playing cards across 117 images</a> using Roboflow Annotate (at first I only did half as much - why this wasn&rsquo;t a good idea we&rsquo;ll see in a minute). Once enough screenshots of cards were annotated we can train the model to recognize the cards and predict card values on tables it has never seen before. I was able to use a <a href=https://www.nvidia.com/en-us/data-center/tesla-t4/>NVIDIA T4 GPU</a> inside Google Colab which offers some GPU time for free when capacity is available.
<a href=#lightbox-gpu_setup_colab-png-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/gpu_setup_colab.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/gpu_setup_colab.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/gpu_setup_colab.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/gpu_setup_colab.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/gpu_setup_colab.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/gpu_setup_colab.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/gpu_setup_colab.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/gpu_setup_colab.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/gpu_setup_colab.png" alt="alt text here" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-gpu_setup_colab-png-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/gpu_setup_colab.png" alt="alt text here">
</a>During training, the algorithm learns patterns from this example data, adjusting its internal parameters millions of times until it gets really good at recognizing the differences between categories (in this case different cards). Once trained, the model can then make predictions on new, unseen data by applying the patterns it learned. With the annotated dataset ready, it was time to implement the actual computer vision model. I chose to run inference on <a href=https://docs.ultralytics.com/de/models/yolo11/>Ultralytics&rsquo; YOLOv11</a> pre-trained model, a state-of-the-art object detection algorithm. I set up the environment in Google Colab following the <a href=https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolo11-object-detection-on-custom-dataset.ipynb>&ldquo;How to Train YOLO11 Object Detection on a Custom Dataset&rdquo;</a> notebook. After extracting the annotated dataset from Roboflow, I began training the model using the pre-trained YOLOv11s weights as a starting point. This approach, called <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, allows the model to leverage patterns already learned from millions of general images and adapt them to this specific task.
I initially set it up to <a href=https://docs.ultralytics.com/guides/model-training-tips/#other-techniques-to-consider-when-handling-a-large-dataset>run for 350 epochs</a>, though the model&rsquo;s built-in early stopping mechanism kicked in after 242 epochs when no improvement was observed for 100 consecutive epochs. The best results were achieved at epoch 142, taking around 13 minutes to complete on the Tesla T4 GPU.
The initial results were quite promising, with an overall mean Average Precision (mAP) of 80.5% at IoU threshold 0.5. Most individual card classes achieved good precision and recall scores, with only a few cards like the 6 and Queen showing slightly lower precision values.
<a href=#lightbox-run1_results-png-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/run1_results.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/run1_results.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/run1_results.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/run1_results.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/run1_results.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/run1_results.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/run1_results.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/run1_results.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/run1_results.png" alt="Training results showing confusion matrix and loss curves" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-run1_results-png-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/run1_results.png" alt="Training results showing confusion matrix and loss curves">
</a>However, looking at the confusion matrix and loss curves revealed some interesting patterns. While the model was learning effectively (as shown by the steadily decreasing loss), there were still some misclassifications between similar cards, particularly among the numbered cards. This highlighted exactly why I mentioned earlier that annotating only half the amount of data initially &ldquo;wasn&rsquo;t a good idea&rdquo; - more training examples would likely improve these edge cases and reduce confusion between similar-looking cards. My first attempt at solving the remaining accuracy issues was to add another layer to the workflow by sending the detected cards to Anthropic&rsquo;s Claude API for additional OCR processing.
<a href=#lightbox-claude_vision_workflow_results-png-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/claude_vision_workflow_results.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/claude_vision_workflow_results.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/claude_vision_workflow_results.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/claude_vision_workflow_results.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/claude_vision_workflow_results.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/claude_vision_workflow_results.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/claude_vision_workflow_results.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/claude_vision_workflow_results.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/claude_vision_workflow_results.png" alt="Roboflow workflow with Claude API integration" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-claude_vision_workflow_results-png-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/claude_vision_workflow_results.png" alt="Roboflow workflow with Claude API integration">
</a>This hybrid approach was very effective - the combination of YOLO&rsquo;s object detection to dynamically crop down the Black Jack table to individual cards with Claude&rsquo;s advanced vision capabilities yielded 99.9% accuracy on the predicted cards. However, this solution came with a significant drawback: the additional API layer consumed valuable time and the large model&rsquo;s processing overhead, making it impractical for real-time gameplay.
Seeking a faster solution, I implemented the same workflow <a href=https://github.com/JaidedAI/EasyOCR>locally using easyOCR</a> instead. EasyOCR seems to be really good at extracting black text on white background but <a href=https://stackoverflow.com/questions/68261703/how-to-improve-accuracy-prediction-for-easyocr>might struggle with everything else</a>. While it was able to correctly identify the card numbers when it detected them, it struggled to recognize around half of the cards in the first place - even when fed pre-cropped card images directly from the YOLO model. This inconsistency made it unreliable for the application.
Rather than continue band-aid solutions, I decided to go back and improve my dataset. I doubled the training data by adding another 60 screenshots with the same train/test split as before. More importantly, I went through all the previous annotations and fixed many of the bounding polygons. I noticed that several misidentifications were caused by the model detecting face-down dealer cards as valid cards, which happened because some annotations for face-up cards inadvertently included parts of the card backs next to them. The improved dataset and cleaned annotations delivered what I was hoping for: The confusion matrix now shows a much cleaner diagonal pattern, indicating that the model now correctly identifies most cards without the cross-contamination issues we saw earlier.
<a href=#lightbox-run_best-png-4 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/run_best.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/run_best.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/run_best.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/run_best.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/run_best.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/run_best.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/run_best.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/run_best.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/run_best.png" alt="Final training results with improved dataset" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-run_best-png-4 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/run_best.png" alt="Final training results with improved dataset">
</a>Both the training and validation losses converge smoothly without signs of overfitting, while the precision and recall metrics climb steadily to plateau near perfect scores. The mAP@50 reaches an impressive 99.5%. Most significantly, the confusion matrix now shows that the model has virtually eliminated false positives with background elements. The &ldquo;background&rdquo; column (rightmost) in the confusion matrix is now much cleaner, with only minimal misclassifications of actual cards as background noise.
<a href=#lightbox-local_run_interference_visual-png-5 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/local_run_interference_visual.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/local_run_interference_visual.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/local_run_interference_visual.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/local_run_interference_visual.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/local_run_interference_visual.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/local_run_interference_visual.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/local_run_interference_visual.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/local_run_interference_visual.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/local_run_interference_visual.png" alt="Real-time blackjack card detection and odds calculation" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-local_run_interference_visual-png-5 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/local_run_interference_visual.png" alt="Real-time blackjack card detection and odds calculation">
</a>With the model trained and performing, it was time to deploy it and play some blackjack. Initially, I tested the system using <a href=https://docs.roboflow.com/deploy/serverless-hosted-api-v2>Roboflow&rsquo;s hosted API</a>, which took around 4 seconds per inference - far too slow for practical gameplay. However, running the model locally on my laptop dramatically improved performance, achieving inference times of less than 0.1 seconds per image (1.3ms preprocess, 45.5ms inference, 0.4ms postprocess per image). I then <a href=https://python-mss.readthedocs.io/>integrated the model with MSS</a> to capture a real-time feed of my browser window. The system automatically overlays the detected cards with their predicted values and confidence scores
<a href=#lightbox-black_jack_odds_demo-gif-6 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/black_jack_odds_demo.gif 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/black_jack_odds_demo.gif 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/black_jack_odds_demo.gif 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/black_jack_odds_demo.gif 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/black_jack_odds_demo.gif 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/black_jack_odds_demo.gif 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/black_jack_odds_demo.gif 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/black_jack_odds_demo.gif 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/black_jack_odds_demo.gif" alt="Overview of selected fitted curves" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-black_jack_odds_demo-gif-6 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/black_jack_odds_demo.gif" alt="Overview of selected fitted curves">
</a>The final implementation successfully combines the pieces: the computer vision model detects and identifies cards in real-time, feeds this information to the Monte Carlo simulation, and displays both the card recognition results and the calculated odds directly on screen - do not try this at your local (online) casino!</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-05-30T00:00:00Z>May 30, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/05/30/modeling-glycemic-response-with-xgboost/>Modeling Glycemic Response with XGBoost</a></h2></header><div class=post-content><p>Earlier this year I wrote how <a href=/2025/01/02/i-built-a-cgm-data-reader/>I built a CGM data reader</a> after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an <a href=https://ocw.mit.edu/courses/res-7-008-7-28x-molecular-biology/>MIT MOOC</a> I became curious if given a meal&rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Personalized Nutrition by Prediction of Glycemic Responses</a> which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my <em>own</em> glycemic response curve. So I decided to build my own model. In the process I wrote this <a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf>working paper</a>.
<a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf><a href=#lightbox-working_paper_overview-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/working_paper_overview.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/working_paper_overview.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/working_paper_overview.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/working_paper_overview.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/working_paper_overview.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/working_paper_overview.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/working_paper_overview.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/working_paper_overview.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/working_paper_overview.jpg" alt="Overview of Working Paper Pages" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-working_paper_overview-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/working_paper_overview.jpg" alt="Overview of Working Paper Pages">
</a></a>The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Zeevi et al.</a>&rsquo;s approach. I quickly realized that training a model on my own data <em>only</em> was not very promising if not impossible. To tackle this, I used the publicly available <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a> containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper).
<a href=#lightbox-cgm-workflow-graph-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-workflow-graph.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-workflow-graph.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-workflow-graph.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-workflow-graph.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-workflow-graph.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-workflow-graph.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-workflow-graph.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-workflow-graph.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-workflow-graph-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow">
</a>Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts).
<a href=#lightbox-cgm-fitted-curve-large1-jpg-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-fitted-curve-large1.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-fitted-curve-large1.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-fitted-curve-large1.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-fitted-curve-large1.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-fitted-curve-large1.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-fitted-curve-large1-jpg-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements">
</a>The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there&rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged.
<a href=#lightbox-example-fitted-cgm-measurements-jpg-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/example-fitted-cgm-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/example-fitted-cgm-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/example-fitted-cgm-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/example-fitted-cgm-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/example-fitted-cgm-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-example-fitted-cgm-measurements-jpg-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves">
</a>I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.</p><p>While the model achieved moderate success predicting amplitude (R² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (R² = -0.76), and curve width prediction was barely better (R² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of an R² > 0.7. Studies that have achieved better predictive performance typically used much larger datasets (>1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training datasets, would be necessary.</p><p>The complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my <a href=https://github.com/philippdubach/glucose-response-analysis>GitHub repository</a>.<br>_ _</p><p><em>(10/06/2025) Update: Today I came across Marcel Salathé&rsquo;s <a href="https://www.linkedin.com/posts/salathe_myfoodrepo-digitalhealth-precisionnutrition-activity-7337806988082393088-2Lsu?utm_source=share&amp;utm_medium=member_ios&amp;rcm=ACoAADeInT4BJMhtg5DSjxX1jVtIAs5w_KxZm-g">LinkedIn post</a> on a publication out of EPFL: <a href=https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2025.1539118/full>Personalized glucose prediction using in situ data only</a>.</em></p><blockquote><p><em>With data from over 1,000 participants of the Food & You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).</em></p></blockquote><p><em>As expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs R² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a>) represents a fundamental difference in statistical power and generalizability. They addressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the <a href=https://pubmed.ncbi.nlm.nih.gov/38033170/>&ldquo;Food & You&rdquo; study</a> (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).</em></p><p><em>Apart from that I am excited to - at a first glance - observe the following similarities:
(1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications.
(2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (R², RMSE, MAE, Pearson correlation).
(3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics.
(4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC).
(5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning.
(6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.</em><a id=update></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-02-20T00:00:00Z>February 20, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/02/20/trading-on-market-sentiment/>Trading on Market Sentiment</a></h2></header><div class=post-content><p><em>This post is based in part on a 2022 presentation I gave for the <a href=https://www.ft.com/content/3bd45acd-b323-3c6b-ba98-ac78b456f308>ICBS Student Investment Fund</a> and my seminar work at Imperial College London.</em></p><p>As we were looking for new investment strategies for our Macro Sentiment Trading team, OpenAI had just published their <a href=https://platform.openai.com/docs/models/gpt-3-5-turbo>GPT-3.5 Model</a>. After first experiments with the model, we asked ourselves: How would large language models like GPT-3.5 perform in predicting sentiment in financial markets, where the signal-to-noise ratio is notoriously low? And could they potentially even outperform industry benchmarks at interpreting market sentiment from news headlines? The idea wasn&rsquo;t entirely new. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3389884">Studies</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1702854">[2]</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=685145">[3]</a> have shown that investor sentiment, extracted from news and social media, can forecast market movements. But most approaches rely on traditional NLP models or proprietary systems like <a href=https://www.ravenpack.com>RavenPack</a>. With the recent advances in large language models, I wanted to test whether these more sophisticated models could provide a competitive edge in sentiment-based trading. Before looking at model selection, it&rsquo;s worth understanding what makes trading on sentiment so challenging. News headlines present two fundamental problems that any robust system must address.
<a href=#lightbox-news-relevance-timeline-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/news-relevance-timeline.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/news-relevance-timeline.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/news-relevance-timeline.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/news-relevance-timeline.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/news-relevance-timeline.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/news-relevance-timeline.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/news-relevance-timeline.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/news-relevance-timeline.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/news-relevance-timeline.jpg" alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-news-relevance-timeline-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/news-relevance-timeline.jpg" alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term.">
</a>First, headlines are inherently non-stationary. Unlike other data sources, news reflects the constantly shifting landscape of global events, political climates, economic trends, etc. A model trained on COVID-19 vaccine headlines from 2020 might struggle with geopolitical tensions in 2023. This temporal drift means algorithms must be adaptive to maintain relevance.
<a href=#lightbox-headline-market-impact-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/headline-market-impact.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/headline-market-impact.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/headline-market-impact.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/headline-market-impact.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/headline-market-impact.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/headline-market-impact.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/headline-market-impact.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/headline-market-impact.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/headline-market-impact.jpg" alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-headline-market-impact-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/headline-market-impact.jpg" alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)">
</a>Second, the relationship between headlines and market impact is far from obvious. Consider these actual headlines from November 2020: &ldquo;Pfizer Vaccine Prevents 90% of COVID Infections&rdquo; drove the S&amp;P 500 up 1.85%, while &ldquo;Pfizer Says Safety Milestone Achieved&rdquo; barely moved the market at -0.05%. The same company, similar positive news, dramatically different market reactions.</p><p>When developing a sentiment-based trading system, you essentially have two conceptual approaches: forward-looking and backward-looking.
Forward-looking models try to predict which news themes will drive markets, often working qualitatively by creating logical frameworks that capture market expectations. This approach is highly adaptable but requires deep domain knowledge and is time-consuming to maintain.
Backward-looking models analyze historical data to understand which headlines have moved markets in the past, then look for similarities in current news. This approach can leverage large datasets and scale efficiently, but suffers from low signal-to-noise ratios and the challenge that past relationships may not hold in the future.
For this project, I chose the backward-looking approach, primarily for its scalability and ability to work with existing datasets.</p><p>Rather than rely on traditional approaches like <a href=https://github.com/ProsusAI/finBERT>FinBERT</a> (which only provides discrete positive/neutral/negative classifications), I decided to test OpenAI&rsquo;s GPT-3.5 Turbo model. The key advantage was its ability to provide continuous sentiment scores from -1 to 1, giving much more nuanced signals for trading decisions. I used news headlines from the Dow Jones Newswire covering the 30 DJI companies from 2018-2022, filtering for quality sources like the Wall Street Journal and Bloomberg. After removing duplicates, this yielded 2,072 headlines. I then prompted GPT-3.5 to score sentiment with the instruction: <code>Rate the sentiment of the following news headlines from -1 (very bad) to 1 (very good), with two decimal precision</code>. To validate the approach, I compared GPT-3.5 scores against RavenPack—the industry&rsquo;s leading commercial sentiment provider.
<a href=#lightbox-score-comparison-openai-rpa-jpg-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/score-comparison-openai-rpa.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/score-comparison-openai-rpa.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/score-comparison-openai-rpa.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/score-comparison-openai-rpa.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/score-comparison-openai-rpa.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/score-comparison-openai-rpa.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/score-comparison-openai-rpa.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/score-comparison-openai-rpa.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/score-comparison-openai-rpa.jpg" alt="Sample entries of the combined data set." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-score-comparison-openai-rpa-jpg-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/score-comparison-openai-rpa.jpg" alt="Sample entries of the combined data set.">
</a>The correlation was 0.59, indicating the models generally agreed on sentiment direction while providing different granularities of scoring. More interesting was comparing the distribution of the sentiment ratings between the two models. This could have been approximated closer through some fine tuning of the (minimal) prompt used earlier.
<a href=#lightbox-distribution-of-sentiment-openai-rpa-jpg-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/distribution-of-sentiment-openai-rpa.jpg" alt="Comparing the distribution of the sentiment scores generated using the GPT-3.5 model with the benchmark scores from RavenPack." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-distribution-of-sentiment-openai-rpa-jpg-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/distribution-of-sentiment-openai-rpa.jpg" alt="Comparing the distribution of the sentiment scores generated using the GPT-3.5 model with the benchmark scores from RavenPack.">
</a>I implemented a simple strategy: go long when sentiment hits the top 5% of scores, close positions at 25% profit (to reduce transaction costs), and maintain a fully invested portfolio with 1% commission per trade.
The results were mixed but promising. Over the full 2018-2022 period, the GPT-3.5 strategy generated 41.02% returns compared to RavenPack&rsquo;s 40.99%—essentially matching the industry benchmark. However, both underperformed a simple buy-and-hold approach (58.13%) during this generally bullish period. Relying on market sentiment when news flow is low can be a tricky strategy. As can be seen from the example of the Salesforce stock performance**,** the strategy remained uninvested over a large period of time due to a (sometimes long-lasting) negative sentiment signal.
<a href=#lightbox-crm-stock-sentiment-jpg-4 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/crm-stock-sentiment.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/crm-stock-sentiment.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/crm-stock-sentiment.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/crm-stock-sentiment.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/crm-stock-sentiment.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/crm-stock-sentiment.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/crm-stock-sentiment.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/crm-stock-sentiment.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/crm-stock-sentiment.jpg" alt="Stock performance of Salesforce (CRM) for 5 years from 2018 with sentiment indicators overlayed." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-crm-stock-sentiment-jpg-4 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/crm-stock-sentiment.jpg" alt="Stock performance of Salesforce (CRM) for 5 years from 2018 with sentiment indicators overlayed.">
</a>When I tested different timeframes, the sentiment strategy showed its strength during volatile periods. From 2020-2022, it outperformed buy-and-hold (22.83% vs 21.00%). As expected, sentiment-based approaches work better when markets are less directional and more driven by news flow. To evaluate whether the scores generated by our GPT prompt were more accurate than those from the RavenPack benchmark, I calculated returns for different holding windows. The scores generated by our GPT prompt perform significantly better in the short term (1 and 10 days) for positive sentiment and in the long term (90 days) for negative sentiment.
<a href=#lightbox-sentiment-trading-results-jpg-5 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/sentiment-trading-results.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/sentiment-trading-results.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/sentiment-trading-results.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/sentiment-trading-results.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/sentiment-trading-results.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/sentiment-trading-results.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/sentiment-trading-results.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/sentiment-trading-results.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/sentiment-trading-results.jpg" alt="Average 1, 10, 30, and 90-day holding period return for both models." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-sentiment-trading-results-jpg-5 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/sentiment-trading-results.jpg" alt="Average 1, 10, 30, and 90-day holding period return for both models.">
</a><em>(Note: For lower sentiment, negative returns are desirable since the stock would be shorted)</em></p><p>While the model performed well technically, this project highlighted several practical challenges. First, data accessibility remains a major hurdle—getting real-time, high-quality news feeds is expensive and often restricted. Second, the strategy worked better in a more volatile environment, which prompted many individual trades, creating substantial transaction costs that significantly impact returns. Perhaps most importantly, any real-world implementation would need to compete with high-frequency traders who can act on news within milliseconds. The few seconds required for GPT-3.5 to process headlines and generate sentiment scores are far from being competitive. Despite these challenges, the project demonstrated that LLMs can match industry benchmarks for sentiment analysis—and this was using a general-purpose model, not one specifically fine-tuned for financial applications. OpenAI (and others) today offer more powerful models at very low cost as well as fine-tuning capabilities that could further improve performance. The bigger opportunity might be in combining sentiment signals with other factors, using sentiment as one input in a more sophisticated trading system rather than the sole decision criterion. There&rsquo;s also potential in expanding beyond simple long-only strategies to include short positions on negative sentiment, or developing &ldquo;sentiment indices&rdquo; that smooth out individual headline noise.
Market sentiment strategies may not be optimal for long-term investing, but they show clear promise for shorter-term trading in volatile environments. As LLMs continue to improve and become more accessible, this might offer an opportunity to revisit this project.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-01-02T00:00:00Z>January 2, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/01/02/i-built-a-cgm-data-reader/>I Built a CGM Data Reader</a></h2></header><div class=post-content><p>Last year I put a Continuous Glucose Monitor (CGM) sensor, specifically the <a href=https://www.freestyle.abbott>Abbott Freestyle Libre 3</a>, on my left arm. Why? I wanted to optimize my nutrition for endurance cycling competitions. Where I live, the sensor is easy to get—without any medical prescription—and even easier to use. Unfortunately, Abbott&rsquo;s <a href=https://apps.apple.com/us/app/freestyle-librelink-us/id1325992472>FreeStyle LibreLink</a> app is less than optimal (3,250 other people with an average rating of 2.9/5.0 seem to agree). In their defense, the web app LibreView does offer some nice reports which can be generated as PDFs—not very dynamic, but still something! What I had in mind was more in the fashion of the <a href=https://ultrahuman.com/m1>Ultrahuman M1 dashboard</a>. Unfortunately, I wasn&rsquo;t allowed to use my Libre sensor (EU firmware) with their app (yes, I spoke to customer service).</p><p>At that point, I wasn&rsquo;t left with much enthusiasm, only a coin-sized sensor in my arm. The LibreView website fortunately lets you download most of your (own) data in a CSV report (<em>there is also a <a href=https://github.com/FokkeZB/libreview-unofficial>reverse engineered API</a></em>), which is nice. So that&rsquo;s what I did: download the data, <code>pd.read_csv()</code> it into my notebook, calculate summary statistics, and plot the values.
<a href=#lightbox-libre-measurements-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/libre-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/libre-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/libre-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/libre-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/libre-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/libre-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/libre-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/libre-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/libre-measurements.jpg" alt="Visualized CGM Datapoints" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-libre-measurements-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/libre-measurements.jpg" alt="Visualized CGM Datapoints">
</a>After some interpolation, I now had the same view as the LibreLink app (which I had rejected earlier) provided. Yet, this setup allowed me to do further analysis and visualizations by adding other datapoints (workouts, sleep, nutrition) I was also collecting at that time:</p><ul><li>Blood sugar from <a href=https://www.libreview.com/>LibreView</a>: Measurement timestamps + glucose values</li><li>Nutrition from <a href=https://macrofactorapp.com/>MacroFactor</a>: Meal timestamps + macronutrients (carbs, protein, and fat)</li><li>Sleep data from <a href=https://sleepcycle.com/>Sleep Cycle</a>: Sleep start timestamp + time in bed + time asleep (+ sleep quality, which is a proprietary measure calculated by the app)</li><li>Cardio workouts from <a href=https://connect.garmin.com/>Garmin</a>: Workout start timestamp + workout duration</li><li>Strength workouts from <a href=https://www.hevyapp.com/>Hevy</a>: Workout start timestamp + workout duration</li></ul><p><a href=#lightbox-cgm-dashboard-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-dashboard.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-dashboard.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-dashboard.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-dashboard.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-dashboard.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-dashboard.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-dashboard.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-dashboard.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-dashboard.jpg" alt="Final Dashboard" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-dashboard-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-dashboard.jpg" alt="Final Dashboard">
</a>After structuring those datapoints in a dataframe and normalizing timestamps, I was able to quickly highlight sleep (blue boxes with callouts for time in bed, time asleep, and sleep quality) and workouts (red traces on glucose measurements for strength workouts, green traces for cardio workouts) by plotting highlighted traces on top of the historic glucose trail for a set period. Furthermore, I was able to add annotations for nutrition events with the respective macronutrients.</p><p>I asked Claude to create some sample data and streamline the functions to reduce dependencies on the specific data sources I used. The resulting notebook is a comprehensive CGM data analysis tool that loads and processes glucose readings alongside lifestyle data (nutrition, workouts, and sleep), then creates an integrated dashboard for visualization. The code handles data preprocessing including interpolation of missing glucose values, timeline synchronization across different data sources, and statistical analysis with key metrics like time-in-range and coefficient of variation. The main output is a day-by-day dashboard that overlays workout periods, nutrition events, and sleep phases onto continuous glucose monitoring data, enabling users to identify patterns and correlations between lifestyle factors and blood sugar responses.</p><p>You can find the complete <a href=https://github.com/philippdubach/glucose-tracker/blob/fd5992961cfb4630dad439c782430190937414a3/notebooks/data_exploration.ipynb>notebook</a> as well as the sample data in my <a href=https://github.com/philippdubach/glucose-tracker/>GitHub repository</a>.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2024-11-11T00:00:00Z>November 11, 2024
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2024/11/11/crypto-mean-reversion-trading/>Crypto Mean Reversion Trading</a></h2></header><div class=post-content><p>In late 2021, Lars Kaiser&rsquo;s paper on <a href=https://www.sciencedirect.com/science/article/abs/pii/S1544612318304513>seasonality in cryptocurrencies</a> inspired me to use my <a href=https://docs.kraken.com/api/>Kraken API Key</a> to try and make some money. A quick summary of the paper: (1) Kaiser analyzes seasonality patterns across 10 cryptocurrencies (Bitcoin, Ethereum, etc.), examining returns, volatility, trading volume, and spreads (2) Finds no consistent calendar effects in cryptocurrency returns, supporting weak-form market efficiency (3) Observes robust patterns in trading activity - lower volume, volatility, and spreads in January, weekends, and summer months (4) Documents significant impact of January 2018 market sell-off on seasonality patterns (5) Reports a &ldquo;reverse Monday effect&rdquo; for Bitcoin (positive Monday returns) and &ldquo;reverse January effect&rdquo; (negative January returns) (6) Trading activity patterns suggest crypto markets are dominated by retail rather than institutional investors.</p><p>The paper&rsquo;s main finding: crypto markets appear efficient in terms of returns but show behavioral patterns in trading.</p><blockquote><p>The efficient-market hypothesis (EMH) is a hypothesis in financial economics that states that asset prices reflect all available information. A direct implication is that it is impossible to &ldquo;beat the market&rdquo; consistently on a risk-adjusted basis since market prices should only react to new information.</p></blockquote><p>The EMH has interesting implications for cryptocurrency markets. While major cryptocurrencies like Bitcoin and Ethereum have gained significant institutional adoption and liquidity, they may still be less efficient than traditional markets due to their relative youth and large audience of retail traders (who might not act as rationally as larger, institutional traders). This inefficiency becomes even more pronounced with smaller altcoins, which often have: (1) Lower trading volumes and liquidity (2) Less institutional participation (3) Higher information asymmetries (and/or greater susceptibility to manipulation). These factors create opportunities for exploiting market inefficiencies, particularly in the short term when prices may overreact to news or technical signals before eventually correcting.</p><p>Unlike Kaiser&rsquo;s seasonality research, I didn&rsquo;t focus on calendar-based anomalies over longer time horizons. After reviewing further research on cryptocurrency market inefficiencies <a href=https://www.sciencedirect.com/science/article/abs/pii/S1544612319306415>[1]</a> <a href=https://academic.oup.com/jfec/article-abstract/18/2/233/5133597>[2]</a> <a href=https://www.sciencedirect.com/science/article/abs/pii/S1057521921001228>[3]</a> <a href=https://onlinelibrary.wiley.com/doi/10.1002/isaf.1488>[4]</a>, I was intrigued by predictable patterns in returns following large price movements. This led me to develop a classic mean reversion strategy instead (mean reversion suggests that asset prices tend to revert to their long-term average after extreme movements due to market overreactions and subsequent corrections).
<a href=#lightbox-crypto-changepoint-returns-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/crypto-changepoint-returns.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/crypto-changepoint-returns.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/crypto-changepoint-returns.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/crypto-changepoint-returns.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/crypto-changepoint-returns.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/crypto-changepoint-returns.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/crypto-changepoint-returns.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/crypto-changepoint-returns.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/crypto-changepoint-returns.jpg" alt="Scatter plot showing the relationship between return at time of jump (x-axis, ranging from -0.100 to 0.075) and return after jump (y-axis, ranging from -0.06 to 0.10), with red data points and a fitted regression line showing a slight negative correlation, r = -0.2142, p < 0.0" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-crypto-changepoint-returns-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/crypto-changepoint-returns.jpg" alt="Scatter plot showing the relationship between return at time of jump (x-axis, ranging from -0.100 to 0.075) and return after jump (y-axis, ranging from -0.06 to 0.10), with red data points and a fitted regression line showing a slight negative correlation, r = -0.2142, p < 0.0">
</a>First, I had to find &ldquo;change points.&rdquo; The PELT algorithm efficiently identifies points in ETH/EUR where the statistical properties of the time series change significantly. These changes could indicate market events, trend reversals, or volatility shifts in the cryptocurrency price.
<a href=#lightbox-ETHUSD-pelt-changepoint-png-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/ETHUSD-pelt-changepoint.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/ETHUSD-pelt-changepoint.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/ETHUSD-pelt-changepoint.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/ETHUSD-pelt-changepoint.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/ETHUSD-pelt-changepoint.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/ETHUSD-pelt-changepoint.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/ETHUSD-pelt-changepoint.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/ETHUSD-pelt-changepoint.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/ETHUSD-pelt-changepoint.png" alt="Structural break detection in financial time series using the PELT (Pruned Exact Linear Time) algorithm with RBF kernel. The analysis identifies 12 significant changepoints during June 15-29, 2021, using a penalty parameter of 35. Vertical dashed lines indicate detected regime changes in the price dynamics." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-ETHUSD-pelt-changepoint-png-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/ETHUSD-pelt-changepoint.png" alt="Structural break detection in financial time series using the PELT (Pruned Exact Linear Time) algorithm with RBF kernel. The analysis identifies 12 significant changepoints during June 15-29, 2021, using a penalty parameter of 35. Vertical dashed lines indicate detected regime changes in the price dynamics.">
</a>I then implemented an automated mean reversion trading strategy following this logical flow: <em>Continuous monitoring → Signal detection → Buy execution → Hold period → Sell execution</em>. The script continuously monitored prices for certain cryptocurrencies on Kraken exchange. It executed buy orders when the price moved more than four standard deviations over a 2-hour period, then automatically sold after exactly 2 hours regardless of price movement. The strategy used fixed position sizes and limit orders to minimize fees. It assumed that large price drops represent temporary market overreactions that will reverse within the holding period.</p><p>This little script earned some good change—but then again, it was 2021.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2024-03-15T00:00:00Z>March 15, 2024
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2024/03/15/my-first-optimal-portfolio/>My First 'Optimal' Portfolio</a></h2></header><div class=post-content><p>My introduction to quantitative portfolio optimization happened during my undergraduate years, inspired by Attilio Meucci&rsquo;s <a href=https://link.springer.com/book/10.1007/978-3-540-27904-4>Risk and Asset Allocation</a> and the convex optimization <a href=https://web.stanford.edu/~boyd/teaching.html>teachings of Diamond and Boyd at Stanford</a>. With enthusiasm and perhaps more confidence than expertise, I created my first &ldquo;optimal&rdquo; portfolio. What struck me most was the disconnect between theory and accessibility. Modern Portfolio Theory had been established since 1990, yet the optimization tools remained largely locked behind proprietary software.</p><blockquote><p>Nevertheless, only a few comprehensive software models are available publicly to use, study, or modify. We tackle this issue by engineering practical tools for asset allocation and implementing them in the Python programming language.</p></blockquote><p>This gap inspired what would eventually be published as: <a href=https://digitalcollection.zhaw.ch/handle/11475/24351>A Python integration of practical asset allocation based on modern portfolio theory and its advancements</a>.</p><p>My approach centered on a simple philosophy:</p><blockquote><p>The focus is to keep the tools simple enough for interested practitioners to understand the underlying theory yet provide adequate numerical solutions.</p></blockquote><p>Today, the landscape has evolved dramatically. Projects like <a href=https://github.com/robertmartin8/PyPortfolioOpt>PyPortfolioOpt</a> and <a href=https://github.com/dcajasn/Riskfolio-Lib>Riskfolio-Lib</a> have established themselves as sophisticated open-source alternatives, far surpassing my early efforts in both scope and sophistication. Despite its limitations, the project yielded several meaningful insights:
<a href=#lightbox-efficient-frontier-jpg-0 style="display:block;width:70%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/efficient-frontier.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/efficient-frontier.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/efficient-frontier.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/efficient-frontier.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/efficient-frontier.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/efficient-frontier.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/efficient-frontier.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/efficient-frontier.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/efficient-frontier.jpg" alt="Efficient Frontier Visualization" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-efficient-frontier-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/efficient-frontier.jpg" alt="Efficient Frontier Visualization">
</a>First, I set out to visualize Modern Portfolio Theory&rsquo;s fundamental principle—the risk-return tradeoff that drives optimization decisions. This scatter plot showing the efficient frontier demonstrates this core concept.
<a href=#lightbox-results-vs-benchmark-table-jpg-1 style="display:block;width:70%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/results-vs-benchmark-table.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/results-vs-benchmark-table.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/results-vs-benchmark-table.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/results-vs-benchmark-table.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/results-vs-benchmark-table.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/results-vs-benchmark-table.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/results-vs-benchmark-table.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/results-vs-benchmark-table.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/results-vs-benchmark-table.jpg" alt="Benchmark vs Optimized Results" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-results-vs-benchmark-table-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/results-vs-benchmark-table.jpg" alt="Benchmark vs Optimized Results">
</a>The results of my first optimization: maintaining a 9.386% return while reducing volatility from 14.445% to 5.574%, effectively tripling the Sharpe ratio from 0.650 to 1.684.
<a href=#lightbox-risk-aversion-parameters-jpg-2 style="display:block;width:70%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/risk-aversion-parameters.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/risk-aversion-parameters.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/risk-aversion-parameters.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/risk-aversion-parameters.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/risk-aversion-parameters.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/risk-aversion-parameters.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/risk-aversion-parameters.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/risk-aversion-parameters.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/risk-aversion-parameters.jpg" alt="Risk Aversion Parameter Effects" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-risk-aversion-parameters-jpg-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/risk-aversion-parameters.jpg" alt="Risk Aversion Parameter Effects">
</a>By varying the risk aversion parameter (gamma), the framework successfully adapted to different investor profiles, showcasing the flexibility of the optimization approach. This efficient frontier plot with different gamma values illustrates how the optimization framework adapts to different investor risk preferences.
<a href=#lightbox-oos-performance-table-jpg-3 style="display:block;width:70%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/oos-performance-table.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/oos-performance-table.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/oos-performance-table.jpg 640w" sizes=70%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/oos-performance-table.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/oos-performance-table.jpg 1024w" sizes=70%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/oos-performance-table.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/oos-performance-table.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/oos-performance-table.jpg 2000w" sizes=70%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/oos-performance-table.jpg" alt="Out-of-Sample Performance" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-oos-performance-table-jpg-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/oos-performance-table.jpg" alt="Out-of-Sample Performance">
</a>Perhaps most importantly, out-of-sample testing across diverse market conditions—including the 2018 bear market and 2019 bull market—demonstrated consistent CVaR reduction and improved risk-adjusted returns.</p><blockquote><p>We demonstrate how even in an environment with high correlation, achieving a competitive return with a lower expected shortfall and lower excess risk than the given benchmark over multiple periods is possible.</p></blockquote><p>Looking back, the project feels embarrassingly naive—and surprisingly foundational. While it earned some recognition at the time, it now serves as a valuable reminder: sometimes the best foundation is built before you know enough to doubt yourself.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2024-01-15T00:00:00Z>January 15, 2024
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2024/01/15/the-tech-behind-this-site/>The Tech behind this Site</a></h2></header><div class=post-content><p>Similar to how Simon Willison describes his difficulties managing images for his <a href=https://simonwillison.net/2024/Dec/22/link-blog/>approach to running a link blog</a> I found it hard to remain true to pure markdown syntax but have images embedded in a responsive way on this site.</p><p>My current pipeline is as follows: I host my all my images in a R2 bucket and serve them from <code>static.philippdubach.com</code>. I use Cloudflares&rsquo;s image resizing CDN do I never have to worry about serving images in appropriate size or format. I basically just upload them with the highes possible quality and Cloudflare takes care of the rest.</p><p>Since the site runs on Hugo, I needed a solution that would work within this static site generation workflow. Pure markdown syntax like <code>![alt](url)</code> is clean and portable, but it doesn&rsquo;t give me the responsive image capabilities I was looking for.</p><p>The solution I settled on was creating a <a href=https://gist.github.com/philippdubach/167189c7090c6813c5110c467cb5ebe9>Hugo shortcode</a> that leverages Cloudflare&rsquo;s image transformations while maintaining a simple, markdown-like syntax.
The shortcode generates a <code>&lt;picture></code> element with multiple <code>&lt;source></code> tags, each targeting different screen sizes and serving WebP format. Here&rsquo;s how it works: instead of writing standard markdown image syntax, I use <code>{{ img src="image.jpg" alt="Description" }}</code> in my posts. Behind the scenes, the shortcode constructs URLs for different breakpoints. This means I upload one high-quality image, but users receive perfectly sized versions - a 320px wide WebP for mobile users, a 1600px version for desktop, and everything in between. The shortcode defaults to displaying images at 80% width and centered, but I can override this with a width parameter when needed. It&rsquo;s a nice compromise between the simplicity of markdown and the power of modern responsive image techniques. The syntax remains clean and the performance benefits are substantial - especially important since images are often the heaviest assets on any webpage.</p><p><em>(May 2025) Update:</em>
Completed migration to a fully custom Hugo build. Originally started with a fork of <a href=https://github.com/hugo-sid/hugo-blog-awesome>hugo-blog-awesome</a>, but I&rsquo;ve since rebuilt it from scratch.</p><p><em>(June 2025) Update:</em>
Added LaTeX math rendering using <a href=https://github.com/mathjax/MathJax-src>MathJax 3</a>. Created a <a href=https://gist.github.com/philippdubach/42ef6e05f5c44b76ef3f66f27a17c41e>minimal partial template</a> that only loads the MathJax library on pages that actually contain LaTeX expressions.</p><p><em>(June 2025) Update II:</em>
Enhanced SEO capabilities with comprehensive metadata support. Built custom <a href=https://gist.github.com/philippdubach/39838f8e9e1b9fb085947a6b92062e0a>Open Graph integration</a> that automatically generates social media previews, plus added per-post keyword management.</p><p><em>(November 2025) Update:</em>
Added new <a href=https://gist.github.com/philippdubach/b703005536d6030c87e17d21cb0d430b>shortcode to embedd html tables</a> as well as updated my <a href=https://gist.github.com/philippdubach/167189c7090c6813c5110c467cb5ebe9>image shortcode</a> to add lightbox support on images.</p></div></article></div></main></div></body></html>