<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://gc.zgo.at; frame-ancestors 'self'; base-uri 'self';"><link rel=preconnect href=https://gc.zgo.at crossorigin><link rel=preconnect href=https://static.philippdubach.com crossorigin><link rel=dns-prefetch href=https://gc.zgo.at><link rel=dns-prefetch href=https://static.philippdubach.com><meta name=robots content="index, follow"><title>Home - philippdubach.com</title><meta name=description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=keywords content="Finance,Economics,Technology,Data,Machine Learning"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/><link href=/index.xml rel=alternate type=application/rss+xml title=philippdubach><link href=/index.xml rel=feed type=application/rss+xml title=philippdubach><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#ffff}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#ffff;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;padding-bottom:3rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem;line-height:1.3}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600;line-height:1.3}.post-title a:hover{color:#007acc}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.post-meta a{color:#007acc;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content p:last-child{margin-bottom:.5rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}@supports(text-wrap:balance){.archive-title{text-wrap:balance}}.single .post-title{font-size:1.5rem;margin-bottom:1rem;line-height:1.3}.pagination{margin-top:2rem;margin-bottom:1rem;text-align:center;padding-top:2rem;padding-bottom:1rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}.img-lightbox{cursor:pointer;transition:opacity .2s}.img-lightbox:hover{opacity:.9}.lightbox-overlay{display:none;position:fixed;top:0;left:0;width:100%;height:100%;background:#f8f9fa;z-index:9999;cursor:pointer;align-items:center;justify-content:center;padding:2rem;box-sizing:border-box}.lightbox-overlay:target{display:flex}.lightbox-overlay img{max-width:95%;max-height:95%;object-fit:contain;background:#f8f9fa}.feedback-footer{margin-top:.75rem;padding-top:.75rem;border-top:1px solid #e9ecef;text-align:center;color:#666;font-size:.9rem;margin-bottom:2rem}.feedback-footer p{margin:0;line-height:1.6}.feedback-footer a{color:#007acc;text-decoration:none}.feedback-footer a:hover{text-decoration:underline}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important;padding-bottom:.5rem !important}.pagination{margin-bottom:1.5rem !important;padding-bottom:1.5rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}.post-title,.post-title a,.single .post-title{line-height:1.2 !important}.post-content p:last-child{margin-bottom:.25rem !important}.feedback-footer{margin-top:.5rem !important;padding-top:.5rem !important;margin-bottom:1rem !important}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="philippdubach"><meta property="og:description" content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="og:image:type" content="image/jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="philippdubach"><meta name=twitter:description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-post.jpg"></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><div class=site-title><a href=http://localhost:1313/>philippdubach</a></div><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/posts/>Archive</a></li><li><a href=/about/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><div class=posts><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/05/30/modeling-glycemic-response-with-xgboost/>Modeling Glycemic Response with XGBoost
</a><span class=project-tag>PROJECT</span></h2><div class=post-meta><time datetime=2025-05-30T00:00:00Z>May 30, 2025</time></div></header><div class=post-content><p>Earlier this year I wrote how <a href=/2025/01/02/i-built-a-cgm-data-reader/>I built a CGM data reader</a> after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an <a href=https://ocw.mit.edu/courses/res-7-008-7-28x-molecular-biology/>MIT MOOC</a> I became curious if given a meal&rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Personalized Nutrition by Prediction of Glycemic Responses</a> which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my <em>own</em> glycemic response curve. So I decided to build my own model. In the process I wrote this <a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf>working paper</a>.
<a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf><a href=#lightbox-working_paper_overview-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/working_paper_overview.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/working_paper_overview.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/working_paper_overview.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/working_paper_overview.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/working_paper_overview.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/working_paper_overview.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/working_paper_overview.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/working_paper_overview.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/working_paper_overview.jpg" alt="Overview of Working Paper Pages" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-working_paper_overview-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/working_paper_overview.jpg" alt="Overview of Working Paper Pages">
</a></a>The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Zeevi et al.</a>&rsquo;s approach. I quickly realized that training a model on my own data <em>only</em> was not very promising if not impossible. To tackle this, I used the publicly available <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a> containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper).
<a href=#lightbox-cgm-workflow-graph-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-workflow-graph.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-workflow-graph.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-workflow-graph.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-workflow-graph.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-workflow-graph.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-workflow-graph.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-workflow-graph.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-workflow-graph.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-workflow-graph-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow">
</a>Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts).
<a href=#lightbox-cgm-fitted-curve-large1-jpg-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-fitted-curve-large1.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-fitted-curve-large1.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-fitted-curve-large1.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-fitted-curve-large1.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-fitted-curve-large1.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-fitted-curve-large1-jpg-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements">
</a>The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there&rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged.
<a href=#lightbox-example-fitted-cgm-measurements-jpg-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/example-fitted-cgm-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/example-fitted-cgm-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/example-fitted-cgm-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/example-fitted-cgm-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/example-fitted-cgm-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-example-fitted-cgm-measurements-jpg-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves">
</a>I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.</p><p>While the model achieved moderate success predicting amplitude (R² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (R² = -0.76), and curve width prediction was barely better (R² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of an R² > 0.7. Studies that have achieved better predictive performance typically used much larger datasets (>1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training datasets, would be necessary.</p><p>The complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my <a href=https://github.com/philippdubach/glucose-response-analysis>GitHub repository</a>.<br>_ _</p><p><em>(10/06/2025) Update: Today I came across Marcel Salathé&rsquo;s <a href="https://www.linkedin.com/posts/salathe_myfoodrepo-digitalhealth-precisionnutrition-activity-7337806988082393088-2Lsu?utm_source=share&amp;utm_medium=member_ios&amp;rcm=ACoAADeInT4BJMhtg5DSjxX1jVtIAs5w_KxZm-g">LinkedIn post</a> on a publication out of EPFL: <a href=https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2025.1539118/full>Personalized glucose prediction using in situ data only</a>.</em></p><blockquote><p><em>With data from over 1,000 participants of the Food & You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).</em></p></blockquote><p><em>As expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs R² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a>) represents a fundamental difference in statistical power and generalizability. They addressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the <a href=https://pubmed.ncbi.nlm.nih.gov/38033170/>&ldquo;Food & You&rdquo; study</a> (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).</em></p><p><em>Apart from that I am excited to - at a first glance - observe the following similarities:
(1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications.
(2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (R², RMSE, MAE, Pearson correlation).
(3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics.
(4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC).
(5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning.
(6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.</em><a id=update></p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/05/30/gambling-vs.-investing/>Gambling vs. Investing</a></h2><div class=post-meta><time datetime=2025-05-30T00:00:00Z>May 30, 2025
</time>· <a href=https://www.bloomberg.com/news/features/2025-05-30/kalshi-pushes-sports-betting-as-trump-deregulation-boosts-prediction-market target=_blank rel=noopener>via</a></div></header><div class=post-content><p><a href=https://kalshi.com/>Kalshi</a>, a prediction market startup, is using its federal financial license to offer sports betting nationwide, even in states where it&rsquo;s not legal. The move has earned them cease-and-desist letters from state gaming regulators, but CEO Tarek Mansour isn&rsquo;t backing down:</p><blockquote><p>We can go one by one for every financial market and it would fall under the definition of gambling. So what&rsquo;s the difference?</p></blockquote><p>It&rsquo;s a question that cuts to the heart of modern finance. The founders argue that Wall Street blurred the line between investing and gambling long ago, and casting Kalshi as the latter is inconsistent at best. They have a point—if you can bet on oil futures, Nvidia&rsquo;s stock price, or interest rate movements, why is wagering on NFL touchdowns more objectionable?</p><p>Benefiting from the Trump administration&rsquo;s hands-off regulatory approach, with the CFTC dropping its legal challenge to their election contracts, the odds might be in their favor. Even better, a Kalshi board member is awaiting confirmation to lead the very agency that was previously their biggest antagonist.</p><p>The technical distinction matters: Kalshi operates as an exchange between traders rather than a house taking bets against customers. But functionally, with 79% of their recent trading volume being sports-related, they&rsquo;re forcing us to confront an uncomfortable reality about risk, speculation, and what we choose to call &ldquo;investing.&rdquo;</p><p>Whether you call it innovation or regulatory arbitrage, Kalshi is exposing the arbitrary nature of the lines we&rsquo;ve drawn around acceptable financial speculation.<br>_ _</p><p><em>(17/06/2025) Update: Matt Levine - one of the finance columnists I enjoy reading most - just published a long piece <a href=https://www.bloomberg.com/opinion/newsletters/2025-06-17/it-s-not-gambling-it-s-predicting>&ldquo;It&rsquo;s Not Gambling, It&rsquo;s Predicting&rdquo;</a> in his newsletter on exactly this issue:</em></p><blockquote><p><em>Kalshi offers a prediction market where you can bet on sports. No! Sorry! Wrong! It offers a prediction market where you can predict which team will win a sports game, and if you predict correctly you make money, and if you predict incorrectly you lose money. Not &ldquo;bet on sports.&rdquo; &ldquo;Predict sports outcomes for money.&rdquo; Completely different.</em></p></blockquote></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/05/28/the-model-said-so/>The Model Said So</a></h2><div class=post-meta><time datetime=2025-05-28T00:00:00Z>May 28, 2025
</time>· <a href=https://arxiv.org/abs/2505.24650 target=_blank rel=noopener>via</a></div></header><div class=post-content><p>LLMs make your life easier until they don&rsquo;t.</p><blockquote><p>Their intrinsic complexity and lack of transparency pose significant challenges, especially in the highly regulated financial sector</p></blockquote><p>Unlike other industries where &ldquo;the model said so&rdquo; might suffice, finance demands audit trails, bias detection,
and explainable decision-making—requirements that sit uncomfortably with neural networks containing billions of parameters.
The research highlights a fundamental tension that&rsquo;s about to reshape fintech:
the same complexity that makes LLMs powerful at parsing market sentiment or generating investment reports also makes them regulatory nightmares
in a sector where you need to explain every decision to examiners.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/05/21/dual-mandate-tensions/>Dual Mandate Tensions</a></h2><div class=post-meta><time datetime=2025-05-21T00:00:00Z>May 21, 2025
</time>· <a href=https://www.nber.org/system/files/working_papers/w33772/w33772.pdf target=_blank rel=noopener>via</a></div></header><div class=post-content><p>Something interesting just happened at the National Bureau of Economic Research NBER</p><blockquote><p>We study the optimal monetary policy response to the imposition of tariffs in a model
with imported intermediate inputs. In a simple open-economy framework, we show
that a tariff maps exactly into a cost-push shock in the standard closed-economy New
Keynesian model, shifting the Phillips curve upward. We then characterize optimal
monetary policy, showing that it partially accommodates the shock to smooth the
transition to a more distorted long-run equilibrium—at the cost of higher short-run
inflation.</p></blockquote><p>Here&rsquo;s where it gets interesting for current policy: Werning et. al.
show that &ldquo;optimal&rdquo; monetary policy would actually calls for partial accommodation
of tariff shocks—essentially allowing some inflation to persist to smooth the transition
to what they euphemistically call &ldquo;a more distorted long-run equilibrium.&rdquo;
With core PCE still running above the Fed&rsquo;s 2% target and renewed tariff threats on the horizon,
this research suggests Powell may need to abandon his recent dovish pivot and prepare
for rate hikes that prioritize price stability over employment concerns.
The dual mandate was never meant to be dual when the two mandates point in opposite directions.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/05/11/beyond-monte-carlo-tensor-based-market-modeling/>Beyond Monte Carlo: Tensor-Based Market Modeling</a></h2><div class=post-meta><time datetime=2025-05-11T00:00:00Z>May 11, 2025
</time>· <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5212863" target=_blank rel=noopener>via</a></div></header><div class=post-content><p>A fascinating new paper from Stefano Iabichino at UBS Investment Bank explores what happens when you take the attention mechanisms powering modern AI and apply them to Wall Street&rsquo;s most fundamental pricing problems, tackling what might be quantitative finance&rsquo;s most intractable challenge.</p><p>The problem is elegantly simple yet profound: machine learning models are great at finding patterns in historical data, but financial theory demands that arbitrage-free prices be independent of past information. As the authors put it:</p><blockquote><p>We contend that a fundamental tension exists between the usage of ML methodologies in risk and pricing and the First Fundamental Theorem of Finance (FFTF). While ML models rely on historical data to identify recurring patterns, the FFTF posits that arbitrage-free market prices are independent of past information.</p></blockquote><p>Their solution? Transition Probability Tensors (TPTs) that function like attention mechanisms in neural networks, dynamically weighting relationships between risk factors while maintaining mathematical rigor. Instead of learning from history, these tensors capture &ldquo;dynamic, context-aware relationships across dimensions&rdquo; in real-time.</p><p>The practical results are impressive: simulating 210 quantitative investment strategies across 100,000 market scenarios in just 70 seconds, while identifying optimal hedging strategies and stress-testing future market conditions. The framework even adapts to different volatility regimes, shifting focus toward tail events during high-volatility periods—exactly like attention mechanisms focusing on relevant context. Whether it scales beyond this impressive proof-of-concept remains to be seen, but it&rsquo;s seems to be a genuine attempt to resolve the fundamental tension between AI&rsquo;s pattern-seeking nature and finance&rsquo;s requirement for arbitrage-free pricing.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/04/25/defis-42-billion-maturity-story/>DeFi's $42 Billion Maturity Story</a></h2><div class=post-meta><time datetime=2025-04-25T00:00:00Z>April 25, 2025
</time>· <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5216091" target=_blank rel=noopener>via</a></div></header><div class=post-content><p>A new academic review by Ali Farhani reveals that institutional Total Value Locked in DeFi protocols hit $42 billion in 2024, with BlackRock leading the charge by launching a $250 million tokenized fund on Centrifuge.</p><p>The numbers tell a remarkable story of maturation. Layer 2 solutions like Optimism and Arbitrum now dominate the scaling landscape, while zero-knowledge proofs have reduced compliance costs by 30%. Even the terminology is evolving—researchers now discuss &ldquo;Total Value Redeemable&rdquo; instead of the traditional TVL metric, acknowledging that not all locked value is immediately liquid. Despite technological advances, security incidents persist with painful regularity: $350 million lost in the Wormhole bridge exploit, $81 million in Orbit Chain&rsquo;s multi-signature failure. Cross-chain bridges remain &ldquo;high-risk attack targets,&rdquo; a sobering reminder that connecting different blockchains is still more art than science. The regulatory landscape is complicated as well. Europe&rsquo;s MiCA regulation provides clear frameworks, while the SEC maintains its enforcement-first approach. Hong Kong&rsquo;s innovation sandbox offers a third path, balancing experimentation with oversight.</p><blockquote><p>DeFi is transitioning from a disruptive experiment to an integrated component of the global financial system</p></blockquote><p>That transition isn&rsquo;t complete—Layer 2 solutions are projected to host over 70% of DeFi TVL by mid-2025—but the direction is clear.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/02/20/trading-on-market-sentiment/>Trading on Market Sentiment
</a><span class=project-tag>PROJECT</span></h2><div class=post-meta><time datetime=2025-02-20T00:00:00Z>February 20, 2025</time></div></header><div class=post-content><p><em>This post is based in part on a 2022 presentation I gave for the <a href=https://www.ft.com/content/3bd45acd-b323-3c6b-ba98-ac78b456f308>ICBS Student Investment Fund</a> and my seminar work at Imperial College London.</em></p><p>As we were looking for new investment strategies for our Macro Sentiment Trading team, OpenAI had just published their <a href=https://platform.openai.com/docs/models/gpt-3-5-turbo>GPT-3.5 Model</a>. After first experiments with the model, we asked ourselves: How would large language models like GPT-3.5 perform in predicting sentiment in financial markets, where the signal-to-noise ratio is notoriously low? And could they potentially even outperform industry benchmarks at interpreting market sentiment from news headlines? The idea wasn&rsquo;t entirely new. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3389884">Studies</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1702854">[2]</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=685145">[3]</a> have shown that investor sentiment, extracted from news and social media, can forecast market movements. But most approaches rely on traditional NLP models or proprietary systems like <a href=https://www.ravenpack.com>RavenPack</a>. With the recent advances in large language models, I wanted to test whether these more sophisticated models could provide a competitive edge in sentiment-based trading. Before looking at model selection, it&rsquo;s worth understanding what makes trading on sentiment so challenging. News headlines present two fundamental problems that any robust system must address.
<a href=#lightbox-news-relevance-timeline-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/news-relevance-timeline.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/news-relevance-timeline.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/news-relevance-timeline.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/news-relevance-timeline.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/news-relevance-timeline.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/news-relevance-timeline.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/news-relevance-timeline.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/news-relevance-timeline.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/news-relevance-timeline.jpg" alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-news-relevance-timeline-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/news-relevance-timeline.jpg" alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term.">
</a>First, headlines are inherently non-stationary. Unlike other data sources, news reflects the constantly shifting landscape of global events, political climates, economic trends, etc. A model trained on COVID-19 vaccine headlines from 2020 might struggle with geopolitical tensions in 2023. This temporal drift means algorithms must be adaptive to maintain relevance.
<a href=#lightbox-headline-market-impact-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/headline-market-impact.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/headline-market-impact.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/headline-market-impact.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/headline-market-impact.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/headline-market-impact.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/headline-market-impact.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/headline-market-impact.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/headline-market-impact.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/headline-market-impact.jpg" alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-headline-market-impact-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/headline-market-impact.jpg" alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)">
</a>Second, the relationship between headlines and market impact is far from obvious. Consider these actual headlines from November 2020: &ldquo;Pfizer Vaccine Prevents 90% of COVID Infections&rdquo; drove the S&amp;P 500 up 1.85%, while &ldquo;Pfizer Says Safety Milestone Achieved&rdquo; barely moved the market at -0.05%. The same company, similar positive news, dramatically different market reactions.</p><p>When developing a sentiment-based trading system, you essentially have two conceptual approaches: forward-looking and backward-looking.
Forward-looking models try to predict which news themes will drive markets, often working qualitatively by creating logical frameworks that capture market expectations. This approach is highly adaptable but requires deep domain knowledge and is time-consuming to maintain.
Backward-looking models analyze historical data to understand which headlines have moved markets in the past, then look for similarities in current news. This approach can leverage large datasets and scale efficiently, but suffers from low signal-to-noise ratios and the challenge that past relationships may not hold in the future.
For this project, I chose the backward-looking approach, primarily for its scalability and ability to work with existing datasets.</p><p>Rather than rely on traditional approaches like <a href=https://github.com/ProsusAI/finBERT>FinBERT</a> (which only provides discrete positive/neutral/negative classifications), I decided to test OpenAI&rsquo;s GPT-3.5 Turbo model. The key advantage was its ability to provide continuous sentiment scores from -1 to 1, giving much more nuanced signals for trading decisions. I used news headlines from the Dow Jones Newswire covering the 30 DJI companies from 2018-2022, filtering for quality sources like the Wall Street Journal and Bloomberg. After removing duplicates, this yielded 2,072 headlines. I then prompted GPT-3.5 to score sentiment with the instruction: <code>Rate the sentiment of the following news headlines from -1 (very bad) to 1 (very good), with two decimal precision</code>. To validate the approach, I compared GPT-3.5 scores against RavenPack—the industry&rsquo;s leading commercial sentiment provider.
<a href=#lightbox-score-comparison-openai-rpa-jpg-2 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/score-comparison-openai-rpa.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/score-comparison-openai-rpa.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/score-comparison-openai-rpa.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/score-comparison-openai-rpa.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/score-comparison-openai-rpa.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/score-comparison-openai-rpa.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/score-comparison-openai-rpa.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/score-comparison-openai-rpa.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/score-comparison-openai-rpa.jpg" alt="Sample entries of the combined data set." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-score-comparison-openai-rpa-jpg-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/score-comparison-openai-rpa.jpg" alt="Sample entries of the combined data set.">
</a>The correlation was 0.59, indicating the models generally agreed on sentiment direction while providing different granularities of scoring. More interesting was comparing the distribution of the sentiment ratings between the two models. This could have been approximated closer through some fine tuning of the (minimal) prompt used earlier.
<a href=#lightbox-distribution-of-sentiment-openai-rpa-jpg-3 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/distribution-of-sentiment-openai-rpa.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/distribution-of-sentiment-openai-rpa.jpg" alt="Comparing the distribution of the sentiment scores generated using the GPT-3.5 model with the benchmark scores from RavenPack." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-distribution-of-sentiment-openai-rpa-jpg-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/distribution-of-sentiment-openai-rpa.jpg" alt="Comparing the distribution of the sentiment scores generated using the GPT-3.5 model with the benchmark scores from RavenPack.">
</a>I implemented a simple strategy: go long when sentiment hits the top 5% of scores, close positions at 25% profit (to reduce transaction costs), and maintain a fully invested portfolio with 1% commission per trade.
The results were mixed but promising. Over the full 2018-2022 period, the GPT-3.5 strategy generated 41.02% returns compared to RavenPack&rsquo;s 40.99%—essentially matching the industry benchmark. However, both underperformed a simple buy-and-hold approach (58.13%) during this generally bullish period. Relying on market sentiment when news flow is low can be a tricky strategy. As can be seen from the example of the Salesforce stock performance**,** the strategy remained uninvested over a large period of time due to a (sometimes long-lasting) negative sentiment signal.
<a href=#lightbox-crm-stock-sentiment-jpg-4 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/crm-stock-sentiment.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/crm-stock-sentiment.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/crm-stock-sentiment.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/crm-stock-sentiment.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/crm-stock-sentiment.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/crm-stock-sentiment.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/crm-stock-sentiment.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/crm-stock-sentiment.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/crm-stock-sentiment.jpg" alt="Stock performance of Salesforce (CRM) for 5 years from 2018 with sentiment indicators overlayed." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-crm-stock-sentiment-jpg-4 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/crm-stock-sentiment.jpg" alt="Stock performance of Salesforce (CRM) for 5 years from 2018 with sentiment indicators overlayed.">
</a>When I tested different timeframes, the sentiment strategy showed its strength during volatile periods. From 2020-2022, it outperformed buy-and-hold (22.83% vs 21.00%). As expected, sentiment-based approaches work better when markets are less directional and more driven by news flow. To evaluate whether the scores generated by our GPT prompt were more accurate than those from the RavenPack benchmark, I calculated returns for different holding windows. The scores generated by our GPT prompt perform significantly better in the short term (1 and 10 days) for positive sentiment and in the long term (90 days) for negative sentiment.
<a href=#lightbox-sentiment-trading-results-jpg-5 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/sentiment-trading-results.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/sentiment-trading-results.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/sentiment-trading-results.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/sentiment-trading-results.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/sentiment-trading-results.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/sentiment-trading-results.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/sentiment-trading-results.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/sentiment-trading-results.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/sentiment-trading-results.jpg" alt="Average 1, 10, 30, and 90-day holding period return for both models." loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-sentiment-trading-results-jpg-5 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/sentiment-trading-results.jpg" alt="Average 1, 10, 30, and 90-day holding period return for both models.">
</a><em>(Note: For lower sentiment, negative returns are desirable since the stock would be shorted)</em></p><p>While the model performed well technically, this project highlighted several practical challenges. First, data accessibility remains a major hurdle—getting real-time, high-quality news feeds is expensive and often restricted. Second, the strategy worked better in a more volatile environment, which prompted many individual trades, creating substantial transaction costs that significantly impact returns. Perhaps most importantly, any real-world implementation would need to compete with high-frequency traders who can act on news within milliseconds. The few seconds required for GPT-3.5 to process headlines and generate sentiment scores are far from being competitive. Despite these challenges, the project demonstrated that LLMs can match industry benchmarks for sentiment analysis—and this was using a general-purpose model, not one specifically fine-tuned for financial applications. OpenAI (and others) today offer more powerful models at very low cost as well as fine-tuning capabilities that could further improve performance. The bigger opportunity might be in combining sentiment signals with other factors, using sentiment as one input in a more sophisticated trading system rather than the sole decision criterion. There&rsquo;s also potential in expanding beyond simple long-only strategies to include short positions on negative sentiment, or developing &ldquo;sentiment indices&rdquo; that smooth out individual headline noise.
Market sentiment strategies may not be optimal for long-term investing, but they show clear promise for shorter-term trading in volatile environments. As LLMs continue to improve and become more accessible, this might offer an opportunity to revisit this project.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/02/15/passive-investings-active-problem/>Passive Investing's Active Problem</a></h2><div class=post-meta><time datetime=2025-02-15T00:00:00Z>February 15, 2025
</time>· <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3821263" target=_blank rel=noopener>via</a></div></header><div class=post-content><p>(1) A new academic paper suggests the rise of passive investing may be fueling fragile market moves.
(2) According to a study to be published in the American Economic Review, evidence is building that active managers are slow to scoop up stocks en masse when prices move away from their intrinsic worth.
(3) Thanks to this lethargic trading behavior and the relentless boom in benchmark-tracking index funds, the impact of each trade on prices gets amplified, explaining how sell orders can induce broader equity gyrations</p><p>Passive investing, the supposedly boring strategy of buying and holding index funds, might actually be making markets more volatile. A new study set to be published in the American Economic Review finds that active managers are slow to scoop up stocks when prices move away from their intrinsic worth. Meanwhile, the relentless boom in benchmark-tracking index funds means that each trade gets amplified, explaining how sell orders can induce broader equity gyrations.
Justina Lee for Bloomberg writes that this week&rsquo;s AI-fueled market swings perfectly illustrate the phenomenon. Big equity gauges plunged on Monday over fears about an AI model, before swiftly rebounding.</p><blockquote><p>Thanks to this lethargic trading behavior and the relentless boom in benchmark-tracking index funds, the impact of each trade on prices gets amplified.</p></blockquote><p>The researchers from UCLA, Stockholm School of Economics, and University of Minnesota have identified what they call &ldquo;Big Passive&rdquo;—a financial landscape that&rsquo;s proving less dynamic and more volatile. When most investors are on autopilot, the few remaining active traders have disproportionate influence.
This doesn&rsquo;t invalidate passive investing&rsquo;s core benefits—lower costs and better long-term returns for most investors remain compelling. But it does suggest that our increasingly passive financial system has some unintended consequences.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2025/01/02/i-built-a-cgm-data-reader/>I Built a CGM Data Reader
</a><span class=project-tag>PROJECT</span></h2><div class=post-meta><time datetime=2025-01-02T00:00:00Z>January 2, 2025</time></div></header><div class=post-content><blockquote><p><em>If you&rsquo;re reading this, you might also be interested in: <a href=/2025/05/30/modeling-glycemic-response-with-xgboost/>Modeling Glycemic Response with XGBoost</a></em></p></blockquote><p>Last year I put a Continuous Glucose Monitor (CGM) sensor, specifically the <a href=https://www.freestyle.abbott>Abbott Freestyle Libre 3</a>, on my left arm. Why? I wanted to optimize my nutrition for endurance cycling competitions. Where I live, the sensor is easy to get—without any medical prescription—and even easier to use. Unfortunately, Abbott&rsquo;s <a href=https://apps.apple.com/us/app/freestyle-librelink-us/id1325992472>FreeStyle LibreLink</a> app is less than optimal (3,250 other people with an average rating of 2.9/5.0 seem to agree). In their defense, the web app LibreView does offer some nice reports which can be generated as PDFs—not very dynamic, but still something! What I had in mind was more in the fashion of the <a href=https://ultrahuman.com/m1>Ultrahuman M1 dashboard</a>. Unfortunately, I wasn&rsquo;t allowed to use my Libre sensor (EU firmware) with their app (yes, I spoke to customer service).</p><p>At that point, I wasn&rsquo;t left with much enthusiasm, only a coin-sized sensor in my arm. The LibreView website fortunately lets you download most of your (own) data in a CSV report (<em>there is also a <a href=https://github.com/FokkeZB/libreview-unofficial>reverse engineered API</a></em>), which is nice. So that&rsquo;s what I did: download the data, <code>pd.read_csv()</code> it into my notebook, calculate summary statistics, and plot the values.
<a href=#lightbox-libre-measurements-jpg-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/libre-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/libre-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/libre-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/libre-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/libre-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/libre-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/libre-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/libre-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/libre-measurements.jpg" alt="Visualized CGM Datapoints" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-libre-measurements-jpg-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/libre-measurements.jpg" alt="Visualized CGM Datapoints">
</a>After some interpolation, I now had the same view as the LibreLink app (which I had rejected earlier) provided. Yet, this setup allowed me to do further analysis and visualizations by adding other datapoints (workouts, sleep, nutrition) I was also collecting at that time:</p><ul><li>Blood sugar from <a href=https://www.libreview.com/>LibreView</a>: Measurement timestamps + glucose values</li><li>Nutrition from <a href=https://macrofactorapp.com/>MacroFactor</a>: Meal timestamps + macronutrients (carbs, protein, and fat)</li><li>Sleep data from <a href=https://sleepcycle.com/>Sleep Cycle</a>: Sleep start timestamp + time in bed + time asleep (+ sleep quality, which is a proprietary measure calculated by the app)</li><li>Cardio workouts from <a href=https://connect.garmin.com/>Garmin</a>: Workout start timestamp + workout duration</li><li>Strength workouts from <a href=https://www.hevyapp.com/>Hevy</a>: Workout start timestamp + workout duration</li></ul><p><a href=#lightbox-cgm-dashboard-jpg-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-dashboard.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-dashboard.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-dashboard.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-dashboard.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-dashboard.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-dashboard.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-dashboard.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-dashboard.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-dashboard.jpg" alt="Final Dashboard" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-cgm-dashboard-jpg-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-dashboard.jpg" alt="Final Dashboard">
</a>After structuring those datapoints in a dataframe and normalizing timestamps, I was able to quickly highlight sleep (blue boxes with callouts for time in bed, time asleep, and sleep quality) and workouts (red traces on glucose measurements for strength workouts, green traces for cardio workouts) by plotting highlighted traces on top of the historic glucose trail for a set period. Furthermore, I was able to add annotations for nutrition events with the respective macronutrients.</p><p>I asked Claude to create some sample data and streamline the functions to reduce dependencies on the specific data sources I used. The resulting notebook is a comprehensive CGM data analysis tool that loads and processes glucose readings alongside lifestyle data (nutrition, workouts, and sleep), then creates an integrated dashboard for visualization. The code handles data preprocessing including interpolation of missing glucose values, timeline synchronization across different data sources, and statistical analysis with key metrics like time-in-range and coefficient of variation. The main output is a day-by-day dashboard that overlays workout periods, nutrition events, and sleep phases onto continuous glucose monitoring data, enabling users to identify patterns and correlations between lifestyle factors and blood sugar responses.</p><p>You can find the complete <a href=https://github.com/philippdubach/glucose-tracker/blob/fd5992961cfb4630dad439c782430190937414a3/notebooks/data_exploration.ipynb>notebook</a> as well as the sample data in my <a href=https://github.com/philippdubach/glucose-tracker/>GitHub repository</a>.</p></div></article><article class=post><header class=post-header><h2 class=post-title><a href=http://localhost:1313/2024/12/31/the-green-bond-commitment-premium/>The Green Bond Commitment Premium</a></h2><div class=post-meta><time datetime=2024-12-31T00:00:00Z>December 31, 2024
</time>· <a href=https://www.nature.com/articles/s41599-024-04318-1 target=_blank rel=noopener>via</a></div></header><div class=post-content><p>The difference between green finance that works and green finance that doesn&rsquo;t work seems to be commitment: Using a Difference-in-Differences model analyzing 2013-2023 bond data, researchers found no significant correlation between green bond issuance and CO2 emissions after net-zero policies were adopted. That&rsquo;s the disappointing part. On the upside: companies issuing only green bonds showed higher ESG ratings, lower CO2 emissions, and lower financing costs, achieving substantial environmental benefits and economic advantages. Meanwhile, entities issuing both conventional and green bonds showed no environmental benefits, raising concerns about potential greenwashing.</p><blockquote><p>Those issuing only green bonds tend to have higher ESG ratings, lower CO2 emissions, and lower financing costs.</p></blockquote><p>This could be called the commitment premium: Companies that go all-in on green finance see real results – both environmental and financial. Those trying to have it both ways? They&rsquo;re essentially paying green bond premiums for conventional bond performance while fooling nobody about their environmental impact.
What are the implications for investors? We should favor pure-play green issuers, and regulators need standards that discourage this mixed-portfolio greenwashing. The study suggests current carbon reduction policies haven&rsquo;t created sufficient pressure on bond issuers, but perhaps the market is already creating its own incentives.</p></div></article><nav class=pagination><a href=/page/3/ class=prev>← Newer Posts</a>
<a href=/page/5/ class=next>Older Posts →</a></nav></div></main></div></body></html>