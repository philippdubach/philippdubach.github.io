<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.147.8"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Braindump - Braindump</title>
<meta name="description" content="Curated Articles and Papers on Economics, Finance and Technology">


<meta name="keywords" content="Finance,Economics,Technology,Data,Machine Learning">


<link rel="canonical" href="http://localhost:1313/">
<link rel="alternate" type="application/rss+xml" title="Braindump" href="http://localhost:1313//index.xml">

<link rel="stylesheet" href="/css/custom.css">  
</head>
<body class="linkblog">
    <div class="container">
        <aside class="sidebar">
    <div class="sidebar-content">
        <div class="site-header">
            <h1 class="site-title">
                <a href="http://localhost:1313/">Braindump</a>
            </h1>
            <p class="site-description">Curated Articles and Papers on Economics, Finance and Technology</p>
        </div>
        
        <nav class="navigation">
            <ul>
                
                <li><a href="/">Home</a></li>
                
                <li><a href="/projects/">Projects</a></li>
                
                <li><a href="/about/">About</a></li>
                
                <li><a href="/posts/">Archive</a></li>
                
                <li><a href="/index.xml">RSS</a></li>
                
            </ul>
        </nav>
        
        
        <div class="social-links">
            
            
            <a href="https://github.com/philippdubach" target="_blank" rel="noopener">GitHub</a>
            
            
            <a href="mailto:info@philippdubach.com">Email</a>
            
        </div>
        
    </div>
</aside>
        <main class="content">
            
            
<div class="posts">
    
    
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-11-01T00:00:00Z">
                    November 1, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/11/01/ai-learns-economics-like-undergrads/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://arxiv.org/abs/2411.00782" target="_blank" rel="noopener">
                        AI Learns Economics Like Undergrads
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>This cuts to the heart of how LLMs actually work: Testing Large Language Models on economics problems reveals that these supposedly sophisticated systems don&rsquo;t just learn correct reasoning—they absorb our misconceptions too. The study found LLMs performing reasonably well on undergraduate economics questions (around 65% accuracy) but falling flat on graduate-level problems (35% accuracy). More tellingly, the specific errors weren&rsquo;t random failures but systematic mistakes that mirror exactly what human students get wrong.</p>
<blockquote>
<p>&ldquo;Interestingly, the errors made by LLMs often mirror those made by human students, suggesting that these models may have learned not just correct economic reasoning but also common misconceptions.&rdquo;</p></blockquote>
<p>Which kind of makes sense when we understand how language models actually work: They&rsquo;re not reasoning through economic principles—they&rsquo;re pattern-matching against their training data, which includes millions of wrong answers, confused explanations, and half-understood concepts scattered across the internet.</p>
<p>What are the practical implications? If you&rsquo;re using AI for financial analysis or economic modeling, you&rsquo;re essentially getting a very confident undergraduate who&rsquo;s memorized a lot of material but fundamentally doesn&rsquo;t understand when to apply which concepts. The models particularly struggled with dynamic optimization and game theory—exactly the areas where getting it wrong costs real money. Perhaps most unsettling: chain-of-thought prompting barely helped. Even when asked to show their work, the models maintained their confident confusion, just with more elaborate explanations of why 2+2 equals 5.</p>
<p><em>Note: From the paper: &ldquo;testing set: January 1, 2023, to December 31, 2023&rdquo;</em></p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-09-28T00:00:00Z">
                    September 28, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/09/28/metas-edge-ai-gambit/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" rel="noopener">
                        Meta&#39;s Edge AI Gambit
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>While the AI industry obsesses over ever-larger cloud models, Meta just made a somewhat contrarian bet with Llama 3.2. Instead of chasing GPT-4 with another massive, they&rsquo;re going small and local — releasing lightweight AI models designed to run entirely on your phone. The technical achievement is genuinely impressive: vision-capable models that can analyze images and text, plus compact versions that &ldquo;fit in as little as 1GB of memory.&rdquo; But the real story might be more strategic. Meta is essentially arguing that the future of AI isn&rsquo;t in OpenAI&rsquo;s cloud-centric paradigm, but in edge computing where your data never leaves your device.</p>
<blockquote>
<p>&ldquo;The on-device models are designed to enable developers to build personalized experiences that don&rsquo;t require an internet connection and keep your data private.&rdquo;</p></blockquote>
<p>There&rsquo;s some irony here: Meta — a company built on harvesting user data — suddenly championing privacy. Besides the marketing speak,  this makes perfect business sense. Edge AI could democratize access to AI capabilities, reduce infrastructure costs, and conveniently sidestep the regulatory scrutiny facing cloud AI providers. By giving away competitive AI models, Meta simultaneously weakens competitors&rsquo; moats while positioning themselves as the champion of AI democratization. It&rsquo;s the classic platform play: make the complementary technology free to increase demand for your scarce resource—in this case, developer mindshare and ecosystem control.</p>
<p>Whether on-device models can match cloud performance remains to be seen. But Meta is betting that &ldquo;good enough&rdquo; plus privacy plus offline capability beats &ldquo;perfect&rdquo; in the cloud. In a world increasingly skeptical of Big Tech data practices, that might just be a winning hand.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-06-21T00:00:00Z">
                    June 21, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/06/21/how-some-active-funds-create-their-own-returns/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://arxiv.org/abs/2405.12768" target="_blank" rel="noopener">
                        How Some Active Funds Create Their Own Returns
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>(1) Many active funds hold concentrated portfolios. Flow-driven trading in these securities causes price pressure, which pushes up the funds&rsquo; existing positions resulting in realized returns.
(2) The researchers decomposes fund returns into a price pressure (self-inflated) and a fundamental component and show that when allocating capital across funds, investors are unable to identify whether realized returns are self-inflated or fundamental.
(3) Because investors chase self-inflated fund returns at a high frequency, even short-lived impact meaningfully affects fund flows at longer time scales.
(4) The combination of price impact and return chasing causes an endogenous feedback loop and a reallocation of wealth to early fund investors, which unravels once the price pressure reverts.
(5) The researchers find that flows chasing self-inflated returns predict bubbles in ETFs and their subsequent crashes, and lead to a daily wealth reallocation of 500 Million from ETFs alone.
(6) Around 2% of all daily flows and 8-12% of flows in the top decile of illiquid funds can be attributed to &ldquo;Ponzi flows&rdquo;. The researcher estimate that every day around $500 Million of investor wealth is reallocated because of the price impact of Ponzi flows.</p>
<p>In active funds  investors are unable to identify whether realized returns are self-inflated or fundamental. Here&rsquo;s how the magic trick works: Many active funds hold concentrated portfolios. Flow-driven trading in these securities causes price pressure, which pushes up the funds&rsquo; existing positions resulting in realized returns.
The mechanism is as follows: Fund managers pick concentrated positions, new money flows in, that money pushes up prices of the fund&rsquo;s existing holdings, creating impressive returns that attract more money, which pushes prices higher still. As the researchers put it:</p>
<blockquote>
<p>Via their own price impact, active funds effectively reallocate capital from late to early investors.</p></blockquote>
<p>The numbers are staggering. Around 2% of all daily flows and 8-12% of flows in the top decile of illiquid funds can be attributed to Ponzi flows, with around $500 Million of investor wealth reallocated daily because of this price impact. Even more striking: funds with high Ponzi flows experience subsequent drawdowns of over 200%.
This isn&rsquo;t just academic theorizing—flows chasing self-inflated returns predict bubbles in ETFs and their subsequent crashes. The researchers propose a simple fix: a fund illiquidity measure that captures a fund&rsquo;s potential for self-inflated returns.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-05-20T00:00:00Z">
                    May 20, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/05/20/openai-cuts-prices-raises-stakes/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://openai.com/index/hello-gpt-4o/" target="_blank" rel="noopener">
                        OpenAI Cuts Prices, Raises Stakes
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>OpenAI&rsquo;s GPT-4o launch is a classic Silicon Valley competitive strategy disguised as a product announcement.</p>
<blockquote>
<p>GPT-4o is 2x faster, half the price, and has 5x higher rate limits compared to GPT-4 Turbo</p></blockquote>
<p>The real headline isn&rsquo;t the multimodal wizardry — though watching an AI tutor walk through math problems or harmonize in real-time is genuinely impressive. It&rsquo;s the economics. OpenAI is essentially paying developers to build on their platform while making it prohibitively expensive for competitors to match these specs profitably.</p>
<p>The free tier expansion is equally calculated. By giving ChatGPT&rsquo;s 100+ million users access to frontier AI capabilities, OpenAI creates a consumer expectation that every other AI assistant will struggle to meet. It&rsquo;s the Amazon playbook: lose money on the product, make it back on the ecosystem.</p>
<p>That being said, the technical achievement shouldn&rsquo;t be understated—training a single model end-to-end across text, vision, and audio represents a genuine breakthrough in multimodal AI. Real-time voice conversation with natural interruptions moves us from &ldquo;chatbot&rdquo; to something approaching actual dialogue. Strip away the demos and you&rsquo;re left with a company making an aggressive bet that they can outspend the competition into submission. Whether that works depends on how quickly Google, Anthropic, and others can respond—and whether OpenAI&rsquo;s cash reserves outlast their patience. The AI wars just got expensive. For everyone except OpenAI&rsquo;s customers.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-05-12T00:00:00Z">
                    May 12, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/05/12/alphafold-3-free-for-science/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/" target="_blank" rel="noopener">
                        AlphaFold 3: Free for Science
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>Nothing says &ldquo;we&rsquo;re serious about dominating a market&rdquo; quite like giving away breakthrough technology for free. Google&rsquo;s latest move with AlphaFold 3 might be their most audacious version of this strategy yet.</p>
<blockquote>
<p>&ldquo;AlphaFold 3 can predict the structure and interactions of all of life&rsquo;s molecules with unprecedented accuracy&rdquo;</p></blockquote>
<p>This isn&rsquo;t just an incremental improvement - While previous versions of AlphaFold could predict protein structures, AlphaFold 3 models the interactions between proteins, DNA, RNA, and small molecules. It&rsquo;s the difference between having a parts catalog and understanding how the entire machine works.</p>
<p>Drug discovery typically costs billions and takes decades. If AlphaFold 3 can meaningfully accelerate that process - even by modest percentages—the value creation is staggering. Yet Google is handing it to researchers for free through the AlphaFold Server, with the predictable caveat of commercial restrictions. Is this Google&rsquo;s cloud strategy playing out in life sciences? Establish the platform, get everyone dependent on your infrastructure, then monetize the ecosystem. The pharmaceutical industry, already grappling with AI disruption, now faces a world where molecular interactions can be predicted with &ldquo;50% better accuracy&rdquo; than existing methods.The real question isn&rsquo;t whether AI will transform drug discovery - it&rsquo;s whether Google will own that transformation.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-02-15T00:00:00Z">
                    February 15, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/02/15/zochi-ai-passes-academic-peer-review/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://www.intology.ai/blog/zochi-acl" target="_blank" rel="noopener">
                        Zochi AI Passes Academic Peer Review
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>Somewhere, a peer reviewer just realized they may have been outsmarted by a machine.</p>
<p>Intology&rsquo;s Zochi has achieved something unprecedented: becoming the first AI system to independently pass peer review at an A* scientific conference. Not just any conference—ACL, one of the most prestigious venues in computational linguistics.</p>
<blockquote>
<p>&ldquo;Zochi represents a significant step forward in AI-assisted research, demonstrating the ability to comprehend and analyze complex academic literature with remarkable accuracy.&rdquo;</p></blockquote>
<p>But that undersells what actually happened. This is academia&rsquo;s Turing Test: when AI crossed the threshold from research tool to research colleague. If human experts can&rsquo;t distinguish AI-generated research from human work, we&rsquo;re facing fundamental questions about authorship, originality, and what constitutes scientific contribution. What are the implications. Will conferences soon be flooded with AI submissions? How do we handle attribution when an algorithm is the primary investigator? Could this democratize research globally, or will it devalue human scholarly work?</p>

        </div>
    </article>
    
    
    
    <nav class="pagination">
        
            <a href="/" class="prev">← Newer Posts</a>
        
        
    </nav>
    
</div>

        </main>
    </div>
    



</body>
</html>