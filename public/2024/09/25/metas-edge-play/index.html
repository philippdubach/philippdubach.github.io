<!DOCTYPE html>
<html lang="en-us">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Meta&#39;s Edge Play - Braindump</title>
<meta name="description" content="Curated Articles and Papers on Economics, Finance and Technology">


<meta name="keywords" content="links,web,technology">


<link rel="canonical" href="http://localhost:1313/2024/09/25/metas-edge-play/">
<link rel="alternate" type="application/rss+xml" title="Braindump" href="http://localhost:1313//index.xml">

<link rel="stylesheet" href="/css/custom.css">  
</head>
<body class="linkblog">
    <div class="container">
        <aside class="sidebar">
    <div class="sidebar-content">
        <div class="site-header">
            <h1 class="site-title">
                <a href="http://localhost:1313/">Braindump</a>
            </h1>
            <p class="site-description">Curated Articles and Papers on Economics, Finance and Technology</p>
        </div>
        
        <nav class="navigation">
            <ul>
                
                <li><a href="/">Home</a></li>
                
                <li><a href="/projects/">Projects</a></li>
                
                <li><a href="/about/">About</a></li>
                
                <li><a href="/posts/">Archive</a></li>
                
                <li><a href="/index.xml">RSS</a></li>
                
            </ul>
        </nav>
        
        
        <div class="social-links">
            
            
            <a href="https://github.com/philippdubach" target="_blank" rel="noopener">GitHub</a>
            
            
            <a href="mailto:info@philippdubach.com">Email</a>
            
        </div>
        
    </div>
</aside>
        <main class="content">
            
            
<article class="post single">
    <header class="post-header">
        <h1 class="post-title">
            
                <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" rel="noopener">
                    Meta&#39;s Edge Play
                    <span class="external-link">→</span>
                </a>
            
        </h1>
        
        <div class="post-meta">
            <time datetime="2024-09-25T00:00:00Z">
                September 25, 2024 at 12:00 AM
            </time>
            
                • <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" rel="noopener">Original Link</a>
            
        </div>
        
    </header>
    <div class="post-content">
        <p>Meta&rsquo;s latest Llama 3.2 release is less about raw capability and more about strategic positioning. While everyone else is racing to build bigger, more expensive cloud models, Meta is zigging: they&rsquo;re shipping models small enough to run on your phone.</p>
<p>The standout here isn&rsquo;t the 90B parameter multimodal model—that&rsquo;s table stakes at this point. It&rsquo;s the 1B and 3B parameter models that Meta claims can deliver meaningful AI capabilities while running locally on mobile devices. As they put it: &ldquo;We&rsquo;re making it easier to build, experiment, and scale AI experiences everywhere — from the cloud to the edge to your phone.&rdquo;</p>
<p>This is a genuinely different bet than what OpenAI or Anthropic are making. While those companies optimize for maximum capability at maximum cost, Meta is optimizing for ubiquity. They&rsquo;re partnering with Qualcomm and MediaTek to get these models running efficiently on mobile processors, which suggests they&rsquo;re serious about this not being just a research exercise.</p>
<p>The economics make sense if you squint. Every API call to GPT-4 costs money; a model running locally on someone&rsquo;s phone costs Meta nothing after deployment. Scale that across billions of devices and the unit economics start to look very different from the current cloud-inference model.</p>
<p>Of course, there&rsquo;s the usual Meta sleight of hand with &ldquo;open source&rdquo;—the models are freely available for commercial use, but under Meta&rsquo;s custom license, not a true open source license. It&rsquo;s open enough to build an ecosystem, closed enough to maintain control.</p>
<p>The real test won&rsquo;t be the benchmarks Meta publishes today. It&rsquo;ll be whether a 1B parameter model running on a phone can actually deliver experiences that feel meaningfully intelligent to users, rather than just technically impressive to engineers.</p>

    </div>
</article>

        </main>
    </div>
    



</body>
</html>