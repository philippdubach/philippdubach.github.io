<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI Learns Economics Like Undergrads - philippdubach.com</title><meta name=description content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><meta name=keywords content="Finance,Economics,Technology,Data,Machine Learning"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.147.8"><link rel=canonical href=http://localhost:1313/2024/11/01/ai-learns-economics-like-undergrads/><link rel=stylesheet href=/css/custom.css><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="AI Learns Economics Like Undergrads"><meta property="og:description" content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2024/11/01/ai-learns-economics-like-undergrads/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta property="article:published_time" content="2024-11-01T00:00:00Z"><meta property="article:modified_time" content="2024-11-01T00:00:00Z"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="AI Learns Economics Like Undergrads"><meta name=twitter:description content="Personal Projects, Curated Articles and Papers on Economics, Finance and Technology"><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-post.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"http:\/\/localhost:1313\/posts/"},{"@type":"ListItem","position":3,"name":"AI Learns Economics Like Undergrads","item":"http:\/\/localhost:1313\/2024\/11\/01\/ai-learns-economics-like-undergrads\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"AI Learns Economics Like Undergrads","name":"AI Learns Economics Like Undergrads","description":"This cuts to the heart of how LLMs actually work: Testing Large Language Models on economics problems reveals that these supposedly sophisticated systems …","articleBody":"\"This cuts to the heart of how LLMs actually work: Testing Large Language Models on economics problems reveals that these supposedly sophisticated systems don\\u0026rsquo;t just learn correct reasoning—they absorb our misconceptions too. The study found LLMs performing reasonably well on undergraduate economics questions (around 65% accuracy) but falling flat on graduate-level problems (35% accuracy). More tellingly, the specific errors weren\\u0026rsquo;t random failures but systematic mistakes that mirror exactly what human students get wrong.\\n\\u0026ldquo;Interestingly, the errors made by LLMs often mirror those made by human students, suggesting that these models may have learned not just correct economic reasoning but also common misconceptions.\\u0026rdquo;\\nWhich kind of makes sense when we understand how language models actually work: They\\u0026rsquo;re not reasoning through economic principles—they\\u0026rsquo;re pattern-matching against their training data, which includes millions of wrong answers, confused explanations, and half-understood concepts scattered across the internet.\\nWhat are the practical implications? If you\\u0026rsquo;re using AI for financial analysis or economic modeling, you\\u0026rsquo;re essentially getting a very confident undergraduate who\\u0026rsquo;s memorized a lot of material but fundamentally doesn\\u0026rsquo;t understand when to apply which concepts. The models particularly struggled with dynamic optimization and game theory—exactly the areas where getting it wrong costs real money. Perhaps most unsettling: chain-of-thought prompting barely helped. Even when asked to show their work, the models maintained their confident confusion, just with more elaborate explanations of why 2+2 equals 5.\\nNote: From the paper: \\u0026ldquo;testing set: January 1, 2023, to December 31, 2023\\u0026rdquo;\\n\"","wordCount":240,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-post.jpg","datePublished":"2024-11-01T00:00:00Z","dateModified":"2024-11-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/2024\/11\/01\/ai-learns-economics-like-undergrads\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><h1 class=site-title><a href=http://localhost:1313/>philippdubach</a></h1><p class=site-description>Personal Projects, Curated Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Archive</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title><a href=https://arxiv.org/abs/2411.00782 target=_blank rel=noopener>AI Learns Economics Like Undergrads
<span class=external-link>→</span></a></h1><div class=post-meta><time datetime=2024-11-01T00>November 1, 2024
</time>• <a href=https://arxiv.org/abs/2411.00782 target=_blank rel=noopener>Original Link</a></div></header><div class=post-content><p>This cuts to the heart of how LLMs actually work: Testing Large Language Models on economics problems reveals that these supposedly sophisticated systems don&rsquo;t just learn correct reasoning—they absorb our misconceptions too. The study found LLMs performing reasonably well on undergraduate economics questions (around 65% accuracy) but falling flat on graduate-level problems (35% accuracy). More tellingly, the specific errors weren&rsquo;t random failures but systematic mistakes that mirror exactly what human students get wrong.</p><blockquote><p>&ldquo;Interestingly, the errors made by LLMs often mirror those made by human students, suggesting that these models may have learned not just correct economic reasoning but also common misconceptions.&rdquo;</p></blockquote><p>Which kind of makes sense when we understand how language models actually work: They&rsquo;re not reasoning through economic principles—they&rsquo;re pattern-matching against their training data, which includes millions of wrong answers, confused explanations, and half-understood concepts scattered across the internet.</p><p>What are the practical implications? If you&rsquo;re using AI for financial analysis or economic modeling, you&rsquo;re essentially getting a very confident undergraduate who&rsquo;s memorized a lot of material but fundamentally doesn&rsquo;t understand when to apply which concepts. The models particularly struggled with dynamic optimization and game theory—exactly the areas where getting it wrong costs real money. Perhaps most unsettling: chain-of-thought prompting barely helped. Even when asked to show their work, the models maintained their confident confusion, just with more elaborate explanations of why 2+2 equals 5.</p><p><em>Note: From the paper: &ldquo;testing set: January 1, 2023, to December 31, 2023&rdquo;</em></p></div></article></main></div></body></html>