<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Philipp D. Dubach | Quantitative Finance &amp; AI Strategy</title><link>https://philippdubach.com/</link><description>Recent content on Philipp D. Dubach | Quantitative Finance &amp; AI Strategy</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 05 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://philippdubach.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Bitcoin Security</title><link>https://philippdubach.com/posts/bitcoin-security/</link><pubDate>Fri, 02 Jan 2026 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/bitcoin-security/</guid><description>&lt;p&gt;Bitcoin&amp;rsquo;s security model rests on one assumption: attacking the network costs more than any attacker could gain. A &lt;a href="https://hal.science/hal-04616643v1"&gt;2024 paper by Farokhnia and Goharshady&lt;/a&gt; does the math on this assumption and finds it wanting.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For roughly $6.77 billion in hardware, an attacker could control over 50% of Bitcoin&amp;rsquo;s hash rate. With 30% of hash power, success probability exceeds 95% within 34 days at a cost of about $2.9 billion.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;These are large absolute numbers, but relatively small: Bitcoin&amp;rsquo;s $1.78 trillion market cap and the monthly derivatives volume that now regularly exceeds $2 trillion on unregulated exchanges alone. The attack pays for itself if you short Bitcoin before crashing its price.
&lt;a href="#lightbox-bitcoin_attack_cost1-png-0" style="display: block; width: 100%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/bitcoin_attack_cost1.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/bitcoin_attack_cost1.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/bitcoin_attack_cost1.png 640w"
sizes="100%"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/bitcoin_attack_cost1.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/bitcoin_attack_cost1.png 1024w"
sizes="100%"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/bitcoin_attack_cost1.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/bitcoin_attack_cost1.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/bitcoin_attack_cost1.png 2000w"
sizes="100%"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/bitcoin_attack_cost1.png"
alt="Bar chart showing cost to acquire Bitcoin hash power by percentage, from $0.75B for 10% to $6.77B for 51%"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-bitcoin_attack_cost1-png-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/bitcoin_attack_cost1.png"
alt="Bar chart showing cost to acquire Bitcoin hash power by percentage, from $0.75B for 10% to $6.77B for 51%"
loading="lazy"&gt;
&lt;/a&gt;
The paper challenges three assumptions the crypto community has treated as fact. (1) That you need 51% of hash power to attack successfully. Not true. With 30%, you have high probability of reverting six blocks, enough to shatter the six-confirmation finality standard most practitioners rely on. (2) Acquiring majority hash power is prohibitively expensive. It is expensive but represents less than 0.5% of Bitcoin&amp;rsquo;s market cap. (3) miners have no incentive to attack since they depend on BTC-denominated rewards. This ignores derivatives entirely.&lt;/p&gt;</description></item><item><title>Apple's AI Bet: Playing the Long Game or Missing the Moment?</title><link>https://philippdubach.com/posts/apples-ai-bet-playing-the-long-game-or-missing-the-moment/</link><pubDate>Tue, 30 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/apples-ai-bet-playing-the-long-game-or-missing-the-moment/</guid><description>&lt;p&gt;&lt;a href="https://www.theinformation.com/articles/2026-predictions-apple-will-reverse-ai-slump"&gt;The Information&lt;/a&gt; published a piece today arguing that Apple&amp;rsquo;s restrained AI approach may finally pay off in 2026. The thesis: while OpenAI, Google, and Meta pour hundreds of billions into data centers and model training, Apple has kept its powder dry, sitting on &lt;a href="https://www.apple.com/newsroom/2025/10/apple-reports-fourth-quarter-results/"&gt;$157 billion in cash and marketable securities&lt;/a&gt; as of Q4 2025. If the AI spending bubble deflates, Apple&amp;rsquo;s position looks rather clever. This piqued my interest, from a strategy point of view: Apple hasn&amp;rsquo;t been absent from AI. They&amp;rsquo;ve been making a specific bet that large language models will commoditize, and that value will flow to distribution and customer relationships rather than to whoever has the best model. The revamped Siri expected in spring 2026 will reportedly be powered by &lt;a href="https://www.bloomberg.com/news/articles/2025-11-05/apple-plans-to-use-1-2-trillion-parameter-google-gemini-model-to-power-new-siri"&gt;Google&amp;rsquo;s Gemini through a deal worth $1 billion annually&lt;/a&gt;. The custom Gemini model will run on Apple&amp;rsquo;s Private Cloud Compute servers.
&lt;a href="#lightbox-ai_capex_comparison-png-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/ai_capex_comparison.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/ai_capex_comparison.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/ai_capex_comparison.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/ai_capex_comparison.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/ai_capex_comparison.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/ai_capex_comparison.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/ai_capex_comparison.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/ai_capex_comparison.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/ai_capex_comparison.png"
alt="Big Tech AI Capital Expenditure 2023-2025"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-ai_capex_comparison-png-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/ai_capex_comparison.png"
alt="Big Tech AI Capital Expenditure 2023-2025"
loading="lazy"&gt;
&lt;/a&gt;
This is consistent with Apple&amp;rsquo;s history. They didn&amp;rsquo;t build their own search engine. They took Google&amp;rsquo;s money to be the default on Safari. &lt;a href="https://www.apple.com/newsroom/2025/12/john-giannandrea-to-retire-from-apple/"&gt;John Giannandrea&amp;rsquo;s retirement&lt;/a&gt; earlier this month, with Siri now under Mike Rockwell, signals internal recognition that something had to change.&lt;/p&gt;</description></item><item><title>Book Review: Why Machines Learn</title><link>https://philippdubach.com/posts/book-review-why-machines-learn/</link><pubDate>Sat, 27 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/book-review-why-machines-learn/</guid><description>&lt;blockquote&gt;
&lt;p&gt;We cannot leave decisions about how AI will be built and deployed solely to its practitioners. If we are to effectively regulate this technology, another layer of society, educators, politicians, policymakers [&amp;hellip;], must come to grips with the basics of the mathematics of machine learning.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I read a book that is sort of related to my recent writing on AI: &lt;em&gt;Why Machines Learn: The Elegant Math Behind Modern AI&lt;/em&gt; by &lt;a href="https://www.anilananthaswamy.com/"&gt;Anil Ananthaswamy&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Building a No-Tracking Newsletter from Markdown to Distribution</title><link>https://philippdubach.com/posts/building-a-no-tracking-newsletter-from-markdown-to-distribution/</link><pubDate>Wed, 24 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/building-a-no-tracking-newsletter-from-markdown-to-distribution/</guid><description>&lt;p&gt;&lt;a href="#lightbox-Newsletter_Overview2-jpg-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/Newsletter_Overview2.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/Newsletter_Overview2.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/Newsletter_Overview2.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/Newsletter_Overview2.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/Newsletter_Overview2.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/Newsletter_Overview2.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/Newsletter_Overview2.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/Newsletter_Overview2.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/Newsletter_Overview2.jpg"
alt="Screenshot of rendered newsletter showing article preview cards with images and descriptions"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-Newsletter_Overview2-jpg-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/Newsletter_Overview2.jpg"
alt="Screenshot of rendered newsletter showing article preview cards with images and descriptions"
loading="lazy"&gt;
&lt;/a&gt;
Friends have been asking how they can stay up to date with what I&amp;rsquo;m working on and keep track of the things I read, write, and share. RSS feeds don&amp;rsquo;t seem to be en vogue anymore, apparently. So I built a mailing list. What else would you do over the Christmas break?&lt;/p&gt;</description></item><item><title>How AI is Shaping My Investment Portfolio for 2026</title><link>https://philippdubach.com/posts/how-ai-is-shaping-my-investment-portfolio-for-2026/</link><pubDate>Fri, 12 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/how-ai-is-shaping-my-investment-portfolio-for-2026/</guid><description>&lt;p&gt;I have two portfolios: (a) long-term, diversified, low-cost ETFs, and (b) collecting diamonds in front of bulldozers, short-term option plays, and some individual stocks I find interesting. Here, we will only look at (a). This essay is structured along five themes I believe to be true for 2026:&lt;/p&gt;
&lt;p&gt;&lt;a href="#section1"&gt;(1)&lt;/a&gt; Market Concentration and High Valuations&lt;br&gt;
&lt;a href="#section2"&gt;(2)&lt;/a&gt; US Dollar Depreciation Expected Despite Continued Dominance&lt;br&gt;
&lt;a href="#section3"&gt;(3)&lt;/a&gt; AI Investment Remains Central But Requires Scrutiny&lt;br&gt;
&lt;a href="#section4"&gt;(4)&lt;/a&gt; European Fiscal Revolution Creates Investment Opportunities&lt;br&gt;
&lt;a href="#section5"&gt;(5) &lt;/a&gt;Fixed Income Offers Best Prospects Since Global Financial Crisis&lt;/p&gt;</description></item><item><title>Not Logan Roy: Netflix vs. Paramount's Bidding War</title><link>https://philippdubach.com/posts/not-logan-roy-netflix-vs.-paramounts-bidding-war/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/not-logan-roy-netflix-vs.-paramounts-bidding-war/</guid><description>&lt;p&gt;In the &lt;a href="https://en.wikipedia.org/wiki/Succession_(TV_series)"&gt;HBO series Succession&lt;/a&gt;, billionaire Logan Roy&amp;rsquo;s children spent four seasons scheming, backstabbing, and making offers to inherit a media empire. This week, the real version played out with more zeros and a $252 billion Oracle stake. Time for a closer look:&lt;/p&gt;
&lt;p&gt;On Friday, Warner Bros. Discovery&amp;rsquo;s board agreed to sell the company to &lt;a href="https://ir.netflix.net/investor-news-and-events/financial-releases/press-release-details/2025/NETFLIX-TO-ACQUIRE-WARNER-BROS--FOLLOWING-THE-SEPARATION-OF-DISCOVERY-GLOBAL-FOR-A-TOTAL-ENTERPRISE-VALUE-OF-82-7-BILLION-Equity-Value-of-72-0-Billion/default.aspx"&gt;Netflix for $72 billion&lt;/a&gt;. By Monday, &lt;a href="https://ir.paramount.com/news-releases/news-release-details/paramount-launches-all-cash-tender-offer-acquire-warner-bros"&gt;Paramount had launched a hostile tender offer&lt;/a&gt; directly to shareholders at $30 per share, all cash. In this post I will be going into the gap between those two numbers, streaming economics, aggregator theory, and hostile deal mechanics.
&lt;a href="#lightbox-wbd_offer_comparison2-png-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/wbd_offer_comparison2.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/wbd_offer_comparison2.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/wbd_offer_comparison2.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/wbd_offer_comparison2.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/wbd_offer_comparison2.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/wbd_offer_comparison2.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/wbd_offer_comparison2.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/wbd_offer_comparison2.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/wbd_offer_comparison2.png"
alt="Comparison of Netflix vs Paramount offers for Warner Bros Discovery"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-wbd_offer_comparison2-png-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/wbd_offer_comparison2.png"
alt="Comparison of Netflix vs Paramount offers for Warner Bros Discovery"
loading="lazy"&gt;
&lt;/a&gt;
The Netflix offer breaks down into three pieces: $23.25 per share in cash, $4.50 per share in Netflix stock subject to a collar, and shares in a spun-off entity called Discovery Global containing CNN and the cable networks that Netflix doesn&amp;rsquo;t want. Analysts value that stub somewhere between $2 and $5 per share, which puts the total package at roughly $29.75 to $32.75. Paramount is offering $30 per share in cash for the entire company, including the cable assets. Warner&amp;rsquo;s stock closed Friday at $26.08 and opened Monday around $27.64, which tells you the market expects a bidding war but isn&amp;rsquo;t fully convinced either deal closes.&lt;/p&gt;</description></item><item><title>Nike's Crisis and the Economics of Brand Decay</title><link>https://philippdubach.com/posts/nikes-crisis-and-the-economics-of-brand-decay/</link><pubDate>Tue, 02 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/nikes-crisis-and-the-economics-of-brand-decay/</guid><description>&lt;blockquote&gt;
&lt;p&gt;What it sounds like is that the CEO has the wrong people making the wrong decisions across the strongest brand or one of the strongest brands in consumer history.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This quote by &lt;a href="https://www.youtube.com/watch?v=vRNe_aJEUqA"&gt;Scott Galloway on his podcast&lt;/a&gt; is from July 2024. In March 2025, Nike reported its worst revenue decline in nearly five years: an &lt;a href="https://www.reuters.com/business/retail-consumer/nike-post-worst-revenue-fall-5-years-stagnant-demand-2025-03-19/"&gt;11.5% drop to $11.01 billion. Digital sales fell 20%, app downloads decreased 35%, and store foot traffic declined 11%&lt;/a&gt;. The company that once captured roughly half of the US athletic footwear market now faces a crisis that reveals how competitive advantages work, and how quickly they can disappear.&lt;/p&gt;</description></item><item><title>Gratitude</title><link>https://philippdubach.com/posts/gratitude/</link><pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/gratitude/</guid><description>&lt;p&gt;Thoughts on gratitude by &lt;a href="https://en.wikipedia.org/wiki/Sam_Harris"&gt;Sam Harris&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;d like to talk for a few minutes about gratitude. There&amp;rsquo;s now a lot of research that suggests that gratitude is good for us. No surprise there. And as an emotion, it is very easy to invoke, unless you&amp;rsquo;re living the worst possible life. It should be easy to find something for which you&amp;rsquo;re grateful. And it can be very skillful and wise to do this. Now, one reflection I find myself doing when I&amp;rsquo;m in some ordinary contracted state of mind. Let&amp;rsquo;s say I&amp;rsquo;m stressed out by something not going well. I&amp;rsquo;m reacting to some hassle. I could be caught in traffic and late for an appointment. I sometimes think of bad things that haven&amp;rsquo;t happened to me. I might think that I haven&amp;rsquo;t been diagnosed with a fatal illness. I&amp;rsquo;m not caught in a war zone, and I think of all the people on Earth in that moment who are suffering those sorts of dislocations in their lives. And then I reflect that if I were in their shoes, I would be desperate to get back to precisely the situation I&amp;rsquo;m now in. Just stuck in traffic and late for an appointment, but without any real care in the world. I noticed this at dinner the other night with my family. Everyone seemed to be in a fairly mediocre frame of mind. We were all in some way disgruntled or stressed out. I had a million things I was thinking about, and I suddenly noticed how little joy we were all taking in one another&amp;rsquo;s company. And then I thought, if I had died yesterday and could have the opportunity to be back with my family, I thought of how much I would savor this moment right now. And it totally transformed my mood. It gave me instantaneous access to my best self and to a feeling of pure gratitude for the people in my life. Just think of what it would be like to lose everything and then be restored to the moment you&amp;rsquo;re now in, however ordinary. You can reboot your mind in this way, and it need not take any time. The truth is, you know exactly what it&amp;rsquo;s like to feel overwhelming gratitude for your life. And if you have the freedom and the free attention to listen to this lesson right now, you are in an unusual situation. There are at least a billion people on Earth at this moment who would consider their prayers answered if they could trade places with you. There are at least a billion people who are suffering debilitating pain or political oppression, or the acute stages of bereavement. To have your health, even just sort of, to have friends, even only a few, to have hobbies or interests, and the freedom to pursue them, to have spent this day free from some terrifying encounter with chaos is to be lucky. Just look around you and take a moment to feel how lucky you are. You get another day to live on this earth. Enjoy it.&lt;/p&gt;</description></item><item><title>Deploying to Production with AI Agents: Testing Cursor on Azure</title><link>https://philippdubach.com/posts/deploying-to-production-with-ai-agents-testing-cursor-on-azure/</link><pubDate>Sun, 30 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/deploying-to-production-with-ai-agents-testing-cursor-on-azure/</guid><description>&lt;p&gt;I&amp;rsquo;ve been curious about &lt;a href="https://cursor.com/features"&gt;Cursor&amp;rsquo;s capabilities&lt;/a&gt; for a while, but never had a good reason to try it. This weekend I decided to host my own URL shortener and deployed &lt;a href="https://yourls.org"&gt;YOURLS&lt;/a&gt;, a free and open-source link shortener, on a fresh Azure VM. It seemed like a solid test case since it involves SSH access, server configuration, database setup, and SSL certificates. If an AI assistant could handle that end-to-end, it would be genuinely useful.&lt;/p&gt;</description></item><item><title>Michael Burry's $379 Newsletter</title><link>https://philippdubach.com/posts/michael-burrys-379-newsletter/</link><pubDate>Fri, 28 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/michael-burrys-379-newsletter/</guid><description>&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Michael_Burry"&gt;Michael Burry&lt;/a&gt; (who in your head probably looks like &lt;a href="https://www.historyvshollywood.com/reelfaces/big-short/"&gt;Christian Bale thanks to The Big Short&lt;/a&gt;), the investor who famously predicted the 2008 housing crash, has launched a Substack newsletter after &lt;a href="https://www.bloomberg.com/news/articles/2025-11-18/burry-says-he-s-active-in-markets-after-fund-is-deregistered"&gt;deregistering his hedge fund&lt;/a&gt;. The $379 annual subscription capitalizes on the 1.6 million followers he&amp;rsquo;s built on &lt;a href="https://twitter.com/michaeljburry"&gt;X&lt;/a&gt;, offering what he describes as his &amp;ldquo;sole focus&amp;rdquo; going forward.&lt;/p&gt;
&lt;p&gt;The newsletter&amp;rsquo;s &lt;a href="https://michaeljburry.substack.com/p/foundations-my-1999-and-part-of-2000"&gt;inaugural post takes&lt;/a&gt; (which he kindly enough made accessible for free as a Thanksgiving gift today) readers back to 1999, when Burry was a 27-year-old neurology resident at Stanford making $33'000 annually while carrying $150'000 in medical school debt. There he wrote his &lt;a href="https://michaeljburry.substack.com/api/v1/file/a7e6acc6-aeac-460a-a26a-5fbe43e50d19.pdf"&gt;Valuestocks.net article &amp;ldquo;Buffett Revisited&amp;rdquo;&lt;/a&gt;. A fellow resident casually mentioned making $1.5 million on Polycom stock. Physicians crowded around terminals checking stocks while patients waited. In that environment, Burry was writing investment analysis late at night, getting paid $1 per word by MSN Money under the pen name &amp;ldquo;Value Doc.&amp;rdquo; His VSN Fund returned 68.1% in 1999, and by February 2000, the &lt;a href="https://michaeljburry.substack.com/api/v1/file/7e7cf8c7-2cd5-4bc1-8e36-0f7354ae04d6.pdf"&gt;San Francisco Chronicle&lt;/a&gt; noted he had shorted Amazon. Fourteen days after that article appeared, the NASDAQ topped. It was a peak it wouldn&amp;rsquo;t revisit for 15 years.&lt;/p&gt;</description></item><item><title>Is AI Really Eating the World? AGI, Networks, Value [2/2]</title><link>https://philippdubach.com/posts/is-ai-really-eating-the-world-agi-networks-value-2/2/</link><pubDate>Mon, 24 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/is-ai-really-eating-the-world-agi-networks-value-2/2/</guid><description>&lt;p&gt;&lt;em&gt;Start by reading &lt;a href="https://philippdubach.com/posts/is-ai-really-eating-the-world-1/2/"&gt;Is AI Really Eating the World? What we&amp;rsquo;ve Learned [1/2]&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;All current &lt;a href="https://en.wikipedia.org/wiki/Recommender_system"&gt;recommendation systems&lt;/a&gt; work by capturing and analyzing user behavior at scale. Netflix needs millions of users watching millions of hours to train its recommendation algorithm. Amazon needs billions of purchases. The &lt;a href="https://en.wikipedia.org/wiki/Network_effect"&gt;network effect&lt;/a&gt; comes from data scale. What if LLMs can bypass this? What if an LLM can provide useful recommendations by reasoning about conceptual relationships rather than requiring massive behavioral datasets? If I ask for &amp;ldquo;books like Pirsig&amp;rsquo;s Zen and the Art of Motorcycle Maintenance but more focused on Eastern philosophy,&amp;rdquo; a sufficiently capable LLM might answer well without needing to observe 100 million readers. It understands (or appears to understand) the conceptual space. I&amp;rsquo;m uncertain whether LLMs can do this reliably by the end of 2025. The fundamental question is whether they reason or pattern-match at a very sophisticated level. &lt;a href="https://arxiv.org/abs/2308.03762"&gt;Recent research suggests LLMs may rely more on statistical correlations than true reasoning&lt;/a&gt;. If it&amp;rsquo;s mostly pattern-matching, they still need the massive datasets and we&amp;rsquo;re back to conventional network effects. If they can actually reason over conceptual spaces, that&amp;rsquo;s different. That would unbundle data network effects from recommendation quality. Recommendation quality would depend on model capability, not data scale. And if model capability is commoditizing, then the value in recommendations flows to whoever owns customer relationships and distribution, not to whoever has the most data or the best model. I lean toward thinking LLMs are sophisticated pattern-matchers rather than reasoners, which means traditional network effects still apply. But this is one area where I&amp;rsquo;m genuinely waiting to see more evidence.&lt;/p&gt;</description></item><item><title>Is AI Really Eating the World? [1/2]</title><link>https://philippdubach.com/posts/is-ai-really-eating-the-world-1/2/</link><pubDate>Sun, 23 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/is-ai-really-eating-the-world-1/2/</guid><description>&lt;p&gt;In August 2011, Marc Andreessen wrote &lt;a href="https://a16z.com/why-software-is-eating-the-world/"&gt;&amp;ldquo;Why Software Is Eating the World&amp;rdquo;&lt;/a&gt;, an essay about how software was transforming industries, disrupting traditional businesses, and revolutionizing the global economy. Recently, &lt;a href="https://www.ben-evans.com/benedictevans/2014/1/18/a16z"&gt;Benedict Evans&lt;/a&gt;, a former a16z partner, gave a presentation on generative AI three years after ChatGPT&amp;rsquo;s launch. His argument in short:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;we know this matters, but we don&amp;rsquo;t know how.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In this article I will try to explain why I find his framing fascinating but incomplete. Evans structures technology history in cycles. Every 10-15 years, the industry reorganizes around a new platform: &lt;a href="https://en.wikipedia.org/wiki/Mainframe_computer"&gt;mainframes&lt;/a&gt; (1960s-70s), PCs (1980s), web (1990s), smartphones (2000s-2010s). Each shift pulls all innovation, investment, and company creation into its orbit. Generative AI appears to be the next platform shift, or it could break the cycle entirely. The range of outcomes spans from &amp;ldquo;just more software&amp;rdquo; to a single unified intelligence that handles everything. The pattern recognition is smart, but I think the current evidence points more clearly toward commoditization than Evans suggests, with value flowing up the stack rather than to model providers.&lt;/p&gt;</description></item><item><title>Weather Forecasts Have Improved a Lot</title><link>https://philippdubach.com/posts/weather-forecasts-have-improved-a-lot/</link><pubDate>Sat, 22 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/weather-forecasts-have-improved-a-lot/</guid><description>&lt;p&gt;Reading the press release for Google DeepMind&amp;rsquo;s &lt;a href="https://deepmind.google/discover/blog/weathernext-2-our-most-advanced-weather-forecasting-model/"&gt;WeatherNext 2&lt;/a&gt;, I wondered: have weather forecasts actually improved over the past years?&lt;/p&gt;
&lt;p&gt;Turns out they have, dramatically. &lt;a href="https://ourworldindata.org/weather-forecasts"&gt;A four-day forecast today matches the accuracy of a one-day forecast from 30 years ago&lt;/a&gt;. Hurricane track errors that once exceeded 400 nautical miles for 72-hour forecasts now sit below 80 miles. The &lt;a href="https://charts.ecmwf.int"&gt;European Centre for Medium-Range Weather Forecasts reports three-day forecasts now reach 97% accuracy&lt;/a&gt;, with seven-day forecasts approaching that threshold.&lt;/p&gt;</description></item><item><title>GLP-1 Receptor Agonists in ASUD Treatment</title><link>https://philippdubach.com/posts/glp-1-receptor-agonists-in-asud-treatment/</link><pubDate>Fri, 21 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/glp-1-receptor-agonists-in-asud-treatment/</guid><description>&lt;blockquote&gt;
&lt;p&gt;Alcohol and other substance use disorders (ASUDs) are complex, multifaceted, but treatable medical conditions with widespread medical, psychological, and societal consequences. However, treatment options remain limited, therefore the discovery and development of new treatments for ASUDs is critical. Glucagon-like peptide-1 receptor agonists (GLP-1RAs), currently approved for the treatment of type 2 diabetes mellitus, obesity, and obstructive sleep apnea, have recently emerged as potential new pharmacotherapies for ASUDs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This development matters most for people struggling with substance use disorders who have few effective treatment options. It also matters for manufacturers like Novo Nordisk facing &lt;a href="https://philippdubach.com/posts/novo-nordisks-post-patent-strategy/"&gt;patent expiration pressures on Ozempic&lt;/a&gt;. The research into GLP-1RAs for addiction treatment is early but notable given the limited pharmacotherapy options currently available for ASUDs. In February 2025, researchers at UNC published results from the first randomized controlled trial of semaglutide for ASUD treatment. The phase 2 trial enrolled 48 non-treatment-seeking adults with AUD and administered low-dose semaglutide &lt;a href="https://jamanetwork.com/journals/jamapsychiatry/fullarticle/2829811"&gt;(0.25 mg/week for 4 weeks, 0.5 mg/week for 4 weeks - standard dosing for weight loss reaches 2.4 mg per week)&lt;/a&gt; over 9 weeks. Participants on semaglutide consumed less alcohol in controlled laboratory settings and reported fewer drinks per drinking day in their normal lives. They also reported less craving for alcohol. Heavy drinking episodes declined more sharply in the semaglutide group compared to placebo over the nine-week trial. Despite the low doses, effect sizes for some drinking outcomes exceeded those typically seen with naltrexone, one of the few FDA-approved medications for alcohol use disorder. While larger trials are needed to confirm these results, the early evidence suggests GLP-1 may offer a meaningful treatment option for a condition where new therapies have been approved at a rate of roughly one every 25 years.&lt;/p&gt;</description></item><item><title>Damodaran on Gold's 2025 Surge</title><link>https://philippdubach.com/posts/damodaran-on-golds-2025-surge/</link><pubDate>Sun, 16 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/damodaran-on-golds-2025-surge/</guid><description>&lt;p&gt;&lt;a href="https://pages.stern.nyu.edu/~adamodar/"&gt;Aswath Damodaran&amp;rsquo;s&lt;/a&gt; latest analysis into gold&amp;rsquo;s 2025 surge walks through gold&amp;rsquo;s contradictory nature as a collectible rather than an asset with cash flows, showing why it&amp;rsquo;s impossible to &amp;ldquo;value&amp;rdquo; gold in the traditional sense, yet entirely possible to understand what drives its pricing.&lt;/p&gt;
&lt;p&gt;Even though gold is outperforming almost all other assets in my portfolio this year I fundamentally don&amp;rsquo;t like holding it. I&amp;rsquo;m a &lt;a href="https://buffett.cnbc.com/2011-berkshire-hathaway-annual-meeting/"&gt;Buffett disciple&lt;/a&gt;: gold is an unproductive asset that generates no earnings, pays no dividends.&lt;/p&gt;</description></item><item><title>The Bicycle Needs Riding to be Understood</title><link>https://philippdubach.com/posts/the-bicycle-needs-riding-to-be-understood/</link><pubDate>Fri, 14 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/the-bicycle-needs-riding-to-be-understood/</guid><description>&lt;blockquote&gt;
&lt;p&gt;Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You should write an LLM agent—not because they&amp;rsquo;re revolutionary, but because the bicycle needs riding to be understood. Having built agents myself, Ptacek&amp;rsquo;s central insight resonates: the behavior surprises in specific ways, particularly around how models scale effort with complexity before inexplicably retreating.&lt;/p&gt;</description></item><item><title>AI Models as Standalone P&amp;Ls</title><link>https://philippdubach.com/posts/ai-models-as-standalone-pls/</link><pubDate>Sun, 09 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/ai-models-as-standalone-pls/</guid><description>&lt;blockquote&gt;
&lt;p&gt;Microsoft reported earnings for the quarter ended Sept. [&amp;hellip;] buried in its financial filings were a couple of passages suggesting that OpenAI suffered a net loss of $11.5 billion or more during the quarter.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;For every dollar of revenue, they&amp;rsquo;re allegedly spending roughly $5 to deliver the product. What initially sounds like a joke about &amp;ldquo;making it up on volume&amp;rdquo; points to a more fundamental problem facing OpenAI and its competitors. AI companies are locked into continuously releasing more powerful (and expensive) models. If they stop, &lt;a href="https://arxiv.org/abs/2311.16989"&gt;open-source alternatives will catch up&lt;/a&gt; and offer equivalent capabilities at substantially lower costs. This creates an uncomfortable dynamic. If your current model requires spending more than you earn just to fund the next generation, the path to profitability becomes unclear—perhaps impossible.&lt;/p&gt;</description></item><item><title>Working with Models</title><link>https://philippdubach.com/posts/working-with-models/</link><pubDate>Sat, 08 Nov 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/working-with-models/</guid><description>&lt;p&gt;There was this &amp;ldquo;&lt;a href="https://us1.discourse-cdn.com/flex001/uploads/ultralytics1/original/1X/45c604467b6f4212858281cf28f71a77083fb45e.jpeg"&gt;I work with Models&lt;/a&gt;&amp;rdquo; joke which I first heard years ago from an analyst working on a valuation model (&lt;a href="https://philippdubach.com/posts/everything-is-a-dcf-model/"&gt;see my previous post&lt;/a&gt;). I guess it has become more relevant than ever:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions.&lt;/p&gt;</description></item><item><title>Pozsar's Bretton Woods III: Three Years Later [2/2]</title><link>https://philippdubach.com/posts/pozsars-bretton-woods-iii-three-years-later-2/2/</link><pubDate>Sun, 26 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/pozsars-bretton-woods-iii-three-years-later-2/2/</guid><description>&lt;p&gt;&lt;em&gt;Start by reading &lt;a href="https://philippdubach.com/posts/pozsars-bretton-woods-iii-the-framework-1/2/"&gt;Pozsar&amp;rsquo;s Bretton Woods III: The Framework [1/2]&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now, what actually happened in the three years since Pozsar published this framework? (1) Dollar reserve diversification is happening, but gradual: &lt;a href="https://www.morganstanley.com/insights/articles/us-dollar-declines"&gt;Foreign central bank Treasury holdings declined from peaks exceeding $7.5 trillion to levels below $7 trillion&lt;/a&gt;. This represents steady diversification away from dollar-denominated assets, though not a dramatic collapse. (2) Gold has performed strongly: From roughly $1'900/oz when Pozsar published his dispatches to peaks above $4'000/oz today, gold has appreciated substantially, consistent with increased demand for &amp;ldquo;outside money.&amp;rdquo; (3) Alternative payment systems are developing: Various nations continue building infrastructure for non-dollar trade settlement. While these systems remain in preliminary stages rather than fully operational alternatives to SWIFT, development timelines could speed up following specific triggering events. (4) The dollar itself has remained strong: Perhaps surprisingly given predictions of dollar weakness, the dollar achieved its best performance against a basket of major currencies since 2015 in 2024. The DXY index (which tracks the dollar against major trading partners) &lt;a href="https://www.morningstar.com/markets/will-dollar-keep-falling#:~:text=In%20the%20first%20half%20of,delivered%20nearly%2040%25%20cumulative%20gains"&gt;fell about 11% this year&lt;/a&gt;, marking the end of this decade-long rally. (5) Commodity collateral is increasingly important: &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2355674"&gt;Research on commodities as collateral&lt;/a&gt; shows that under capital controls and collateral constraints, investors import commodities and pledge them as collateral. Higher collateral demands increase commodity prices and affect the inventory-convenience yield relationship.&lt;/p&gt;</description></item><item><title>Pozsar's Bretton Woods III: The Framework [1/2]</title><link>https://philippdubach.com/posts/pozsars-bretton-woods-iii-the-framework-1/2/</link><pubDate>Sat, 25 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/pozsars-bretton-woods-iii-the-framework-1/2/</guid><description>&lt;p&gt;In March 2022, as Western nations imposed unprecedented sanctions following Russia&amp;rsquo;s invasion of Ukraine, &lt;a href="https://exunoplures.hu/people"&gt;Zoltan Pozsar&lt;/a&gt; published a series of dispatches that would become some of the most discussed pieces in financial markets that year. The core thesis was stark: we were witnessing the birth of &amp;ldquo;Bretton Woods III,&amp;rdquo; a fundamental shift in how the global monetary system operates. Nearly three years later, with more data on de-dollarization trends, commodity market dynamics, and structural changes in global trade, it&amp;rsquo;s worth revisiting this framework.&lt;/p&gt;</description></item><item><title>Everything is a DCF Model</title><link>https://philippdubach.com/posts/everything-is-a-dcf-model/</link><pubDate>Sun, 19 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/everything-is-a-dcf-model/</guid><description>&lt;p&gt;A brilliant piece of writing from &lt;a href="https://www.morganstanley.com/im/en-us/individual-investor/about-us/people-and-teams/investment-professionals/michael-mauboussin.html"&gt;Michael Mauboussin&lt;/a&gt; and &lt;a href="https://www.morganstanley.com/im/en-us/individual-investor/about-us/people-and-teams/investment-professionals/dan-callahan.html"&gt;Dan Callahan&lt;/a&gt; at Morgan Stanley that was formative in what I personally believe when it comes to valuation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[…] we want to suggest the mantra &amp;ldquo;everything is a DCF model.&amp;rdquo; The point is that whenever investors value a stake in a cash-generating asset, they should recognize that they are using a discounted cash flow (DCF) model. […] The value of those businesses is the present value of the cash they can distribute to their owners. This suggests a mindset that is very different from that of a speculator, who buys a stock in anticipation that it will go up without reference to its value. Investors and speculators have always coexisted in markets, and the behavior of many market participants is a blend of the two.&lt;/p&gt;</description></item><item><title>Google Discovers New Cancer Therapy Pathway</title><link>https://philippdubach.com/posts/google-discovers-new-cancer-therapy-pathway/</link><pubDate>Sat, 18 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/google-discovers-new-cancer-therapy-pathway/</guid><description>&lt;p&gt;Google gets a lot of scrutiny for some of their work in other domains; nevertheless, it&amp;rsquo;s fair to appreciate that they continue to put major resources behind using AI to accelerate therapeutic discovery. The &lt;a href="https://huggingface.co/vandijklab/C2S-Scale-Gemma-2-27B"&gt;model&lt;/a&gt; and &lt;a href="https://github.com/vandijklab/cell2sentence"&gt;resources&lt;/a&gt; are open access and available to the research community.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How C2S-Scale 27B works: A major challenge in cancer immunotherapy is that many tumors are &amp;ldquo;cold&amp;rdquo; — invisible to the body&amp;rsquo;s immune system. A key strategy to make them &amp;ldquo;hot&amp;rdquo; is to force them to display immune-triggering signals through a process called antigen presentation. We gave our new C2S-Scale 27B model a task: Find a drug that acts as a conditional amplifier, one that would boost the immune signal only in a specific &amp;ldquo;immune-context-positive&amp;rdquo; environment where low levels of interferon (a key immune-signaling protein) were already present, but inadequate to induce antigen presentation on their own.&lt;/p&gt;</description></item><item><title>The State of AI Report 2025</title><link>https://philippdubach.com/posts/the-state-of-ai-report-2025/</link><pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/the-state-of-ai-report-2025/</guid><description>&lt;p&gt;This year&amp;rsquo;s rendition of &lt;a href="https://www.stateof.ai"&gt;The State of AI Report&lt;/a&gt; is making rounds on LinkedIn (yes, LinkedIn the place where the great &lt;a href="https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fy9dk1prvwf2b1.jpg"&gt;E = MC2 + AI&lt;/a&gt; equation was &amp;ldquo;discovered&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;Worth keeping in mind this is made by &lt;a href="https://www.nathanbenaich.com"&gt;Nathan Benaich&lt;/a&gt; the Founder of Air Street Capital, a venture capital firm investing in &amp;ldquo;AI-first companies&amp;rdquo;, so obviously comes with a lot of bias. It&amp;rsquo;s also a relatively small, open survey, with 1'200 &amp;ldquo;AI practitioners&amp;rdquo; surveyed.
An example of the bias:&lt;/p&gt;</description></item><item><title>Popular Science Nobel Prize</title><link>https://philippdubach.com/posts/popular-science-nobel-prize/</link><pubDate>Sat, 11 Oct 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/popular-science-nobel-prize/</guid><description>&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Mary_E._Brunkow"&gt;Mary E. Brunkow&lt;/a&gt; just won the Nobel Prize in Physiology or Medicine 2025 for their (she was jointly awarded) discoveries concerning &lt;a href="https://en.wikipedia.org/wiki/Peripheral_tolerance"&gt;peripheral immune tolerance&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Brunkow, meanwhile, got the news of her prize from an AP photographer who came to her Seattle home in the early hours of the morning. She said she had ignored the earlier call from the Nobel Committee. &amp;ldquo;My phone rang and I saw a number from Sweden and thought: &amp;lsquo;That&amp;rsquo;s just, that&amp;rsquo;s spam of some sort.&amp;rsquo;&amp;rdquo;&lt;/p&gt;</description></item><item><title>Agent-based Systems for Modeling Wealth Distribution</title><link>https://philippdubach.com/posts/agent-based-systems-for-modeling-wealth-distribution/</link><pubDate>Sat, 30 Aug 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/agent-based-systems-for-modeling-wealth-distribution/</guid><description>&lt;p&gt;A question &lt;a href="https://www.youtube.com/garyseconomics"&gt;Gary Stevenson&lt;/a&gt;, the self-proclaimed &lt;a href="https://on.ft.com/4n7z5jD"&gt;best trader in the world&lt;/a&gt;, has been asking for some time is &lt;a href="https://uclrethinkingeconomics.com/2025/06/25/gary-stevenson-can-a-wealth-tax-fix-britains-economy/"&gt;if a wealth tax can fix Britain&amp;rsquo;s economy&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] he believed the continued parlous state of the economy would halt any interest rate hikes. The reason? Because when ordinary people receive money, they spend it, stimulating the economy, while the wealthy tend to save it. But our economic model promotes the concentration of wealth among a select few at the expense of everybody else&amp;rsquo;s living standards.&lt;/p&gt;</description></item><item><title>Visualizing Gradients with PyTorch</title><link>https://philippdubach.com/posts/visualizing-gradients-with-pytorch/</link><pubDate>Sat, 23 Aug 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/visualizing-gradients-with-pytorch/</guid><description>&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Gradient"&gt;Gradients&lt;/a&gt; are one of the most important concepts in calculus and machine learning, but it&amp;rsquo;s often poorly understood. Trying to understand them better myself, I wanted to build a visualization tool that helps me develop the correct mental picture of what the gradient of a function is. I came across &lt;a href="https://github.com/GistNoesis/VisualizeGradient"&gt;GistNoesis/VisualizeGradient&lt;/a&gt;, so I went on from there to write my own iteration. This mental model generalizes beautifully to higher dimensions and is crucial for understanding optimization algorithms.
&lt;a href="#lightbox-torch-gradients_Figure_2-png-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/torch-gradients_Figure_2.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/torch-gradients_Figure_2.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/torch-gradients_Figure_2.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/torch-gradients_Figure_2.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/torch-gradients_Figure_2.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/torch-gradients_Figure_2.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/torch-gradients_Figure_2.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/torch-gradients_Figure_2.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/torch-gradients_Figure_2.png"
alt="2D Gradient Plot: The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent."
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-torch-gradients_Figure_2-png-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/torch-gradients_Figure_2.png"
alt="2D Gradient Plot: The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent."
loading="lazy"&gt;
&lt;/a&gt;
&lt;em&gt;The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent.&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Sentiment Trading Revisited</title><link>https://philippdubach.com/posts/sentiment-trading-revisited/</link><pubDate>Mon, 07 Jul 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/sentiment-trading-revisited/</guid><description>&lt;p&gt;Interesting new paper that builds on many of the ideas &lt;a href="https://philippdubach.com/posts/trading-on-market-sentiment/"&gt;I explored in this project&lt;/a&gt;. The research, by Ayaan Qayyum, an &lt;a href="https://soe.rutgers.edu/news/ayaan-qayyum-electrical-and-computer-engineering"&gt;Undergraduate Research Scholar at Rutgers&lt;/a&gt;, shows that the core concept of using advanced language models for sentiment trading is not only viable but highly effective. The study takes a similar but more advanced approach. Instead of using a model like GPT-3.5 to generate a simple sentiment score, it uses &lt;a href="https://platform.openai.com/docs/guides/embeddings/embedding-models"&gt;OpenAI&amp;rsquo;s embedding models&lt;/a&gt; to convert news headlines into rich, high-dimensional vectors. By training a &lt;a href="https://arxiv.org/html/2507.01970v1/extracted/6556003/diagrams/model_comb_diagram.png"&gt;battery of neural networks&lt;/a&gt; including&lt;/p&gt;</description></item><item><title>Counting Cards with Computer Vision</title><link>https://philippdubach.com/posts/counting-cards-with-computer-vision/</link><pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/counting-cards-with-computer-vision/</guid><description>&lt;p&gt;After installing &lt;a href="https://www.anthropic.com/claude-code"&gt;Claude Code&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster through natural language commands&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was looking for a task to test its abilities. Fairly quickly we wrote &lt;a href="https://gist.github.com/philippdubach/741cbd56498e43375892966ca691b9c2"&gt;less than 200 lines of python code predicting black jack odds&lt;/a&gt; using Monte Carlo Simulation. When I went on to test this little tool on &lt;a href="https://games.washingtonpost.com/games/blackjack"&gt;Washington Post&amp;rsquo;s&lt;/a&gt; online Black Jack (I also didn&amp;rsquo;t know that existed!) I quickly noticed how impractical it was to manually input all the card values on the table manually. What if the tool would also automatically recognize the cards that are on the table and calculate the odds from it? I have never done anything with computer vision so this seemed like a good challenge.
&lt;a href="#lightbox-classification-gif-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/classification.gif 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/classification.gif 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/classification.gif 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/classification.gif 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/classification.gif 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/classification.gif 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/classification.gif 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/classification.gif 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/classification.gif"
alt="alt text here"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-classification-gif-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/classification.gif"
alt="alt text here"
loading="lazy"&gt;
&lt;/a&gt;
To get to any reasonable result we have to start with classification where we &amp;ldquo;teach&amp;rdquo; the model to categorize data by showing them lots of examples with correct labels. But where do the labels come from? I manually annotated &lt;a href="https://universe.roboflow.com/cards-agurd/playing_card_classification"&gt;409 playing cards across 117 images&lt;/a&gt; using Roboflow Annotate (at first I only did half as much - why this wasn&amp;rsquo;t a good idea we&amp;rsquo;ll see in a minute). Once enough screenshots of cards were annotated we can train the model to recognize the cards and predict card values on tables it has never seen before. I was able to use a &lt;a href="https://www.nvidia.com/en-us/data-center/tesla-t4/"&gt;NVIDIA T4 GPU&lt;/a&gt; inside Google Colab which offers some GPU time for free when capacity is available.
&lt;a href="#lightbox-gpu_setup_colab-png-1" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/gpu_setup_colab.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/gpu_setup_colab.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/gpu_setup_colab.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/gpu_setup_colab.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/gpu_setup_colab.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/gpu_setup_colab.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/gpu_setup_colab.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/gpu_setup_colab.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/gpu_setup_colab.png"
alt="alt text here"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-gpu_setup_colab-png-1" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/gpu_setup_colab.png"
alt="alt text here"
loading="lazy"&gt;
&lt;/a&gt;
During training, the algorithm learns patterns from this example data, adjusting its internal parameters millions of times until it gets really good at recognizing the differences between categories (in this case different cards). Once trained, the model can then make predictions on new, unseen data by applying the patterns it learned. With the annotated dataset ready, it was time to implement the actual computer vision model. I chose to run inference on &lt;a href="https://docs.ultralytics.com/de/models/yolo11/"&gt;Ultralytics&amp;rsquo; YOLOv11&lt;/a&gt; pre-trained model, a state-of-the-art object detection algorithm. I set up the environment in Google Colab following the &lt;a href="https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolo11-object-detection-on-custom-dataset.ipynb"&gt;&amp;ldquo;How to Train YOLO11 Object Detection on a Custom Dataset&amp;rdquo;&lt;/a&gt; notebook. After extracting the annotated dataset from Roboflow, I began training the model using the pre-trained YOLOv11s weights as a starting point. This approach, called &lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;transfer learning&lt;/a&gt;, allows the model to leverage patterns already learned from millions of general images and adapt them to this specific task.
I initially set it up to &lt;a href="https://docs.ultralytics.com/guides/model-training-tips/#other-techniques-to-consider-when-handling-a-large-dataset"&gt;run for 350 epochs&lt;/a&gt;, though the model&amp;rsquo;s built-in early stopping mechanism kicked in after 242 epochs when no improvement was observed for 100 consecutive epochs. The best results were achieved at epoch 142, taking around 13 minutes to complete on the Tesla T4 GPU.
The initial results were quite promising, with an overall mean Average Precision (mAP) of 80.5% at IoU threshold 0.5. Most individual card classes achieved good precision and recall scores, with only a few cards like the 6 and Queen showing slightly lower precision values.
&lt;a href="#lightbox-run1_results-png-2" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/run1_results.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/run1_results.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/run1_results.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/run1_results.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/run1_results.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/run1_results.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/run1_results.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/run1_results.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/run1_results.png"
alt="Training results showing confusion matrix and loss curves"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-run1_results-png-2" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/run1_results.png"
alt="Training results showing confusion matrix and loss curves"
loading="lazy"&gt;
&lt;/a&gt;
However, looking at the confusion matrix and loss curves revealed some interesting patterns. While the model was learning effectively (as shown by the steadily decreasing loss), there were still some misclassifications between similar cards, particularly among the numbered cards. This highlighted exactly why I mentioned earlier that annotating only half the amount of data initially &amp;ldquo;wasn&amp;rsquo;t a good idea&amp;rdquo; - more training examples would likely improve these edge cases and reduce confusion between similar-looking cards. My first attempt at solving the remaining accuracy issues was to add another layer to the workflow by sending the detected cards to Anthropic&amp;rsquo;s Claude API for additional OCR processing.
&lt;a href="#lightbox-claude_vision_workflow_results-png-3" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/claude_vision_workflow_results.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/claude_vision_workflow_results.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/claude_vision_workflow_results.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/claude_vision_workflow_results.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/claude_vision_workflow_results.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/claude_vision_workflow_results.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/claude_vision_workflow_results.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/claude_vision_workflow_results.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/claude_vision_workflow_results.png"
alt="Roboflow workflow with Claude API integration"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-claude_vision_workflow_results-png-3" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/claude_vision_workflow_results.png"
alt="Roboflow workflow with Claude API integration"
loading="lazy"&gt;
&lt;/a&gt;
This hybrid approach was very effective - the combination of YOLO&amp;rsquo;s object detection to dynamically crop down the Black Jack table to individual cards with Claude&amp;rsquo;s advanced vision capabilities yielded 99.9% accuracy on the predicted cards. However, this solution came with a significant drawback: the additional API layer consumed valuable time and the large model&amp;rsquo;s processing overhead, making it impractical for real-time gameplay.
Seeking a faster solution, I implemented the same workflow &lt;a href="https://github.com/JaidedAI/EasyOCR"&gt;locally using easyOCR&lt;/a&gt; instead. EasyOCR seems to be really good at extracting black text on white background but &lt;a href="https://stackoverflow.com/questions/68261703/how-to-improve-accuracy-prediction-for-easyocr"&gt;might struggle with everything else&lt;/a&gt;. While it was able to correctly identify the card numbers when it detected them, it struggled to recognize around half of the cards in the first place - even when fed pre-cropped card images directly from the YOLO model. This inconsistency made it unreliable for the application.
Rather than continue band-aid solutions, I decided to go back and improve my dataset. I doubled the training data by adding another 60 screenshots with the same train/test split as before. More importantly, I went through all the previous annotations and fixed many of the bounding polygons. I noticed that several misidentifications were caused by the model detecting face-down dealer cards as valid cards, which happened because some annotations for face-up cards inadvertently included parts of the card backs next to them. The improved dataset and cleaned annotations delivered what I was hoping for: The confusion matrix now shows a much cleaner diagonal pattern, indicating that the model now correctly identifies most cards without the cross-contamination issues we saw earlier.
&lt;a href="#lightbox-run_best-png-4" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/run_best.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/run_best.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/run_best.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/run_best.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/run_best.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/run_best.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/run_best.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/run_best.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/run_best.png"
alt="Final training results with improved dataset"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-run_best-png-4" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/run_best.png"
alt="Final training results with improved dataset"
loading="lazy"&gt;
&lt;/a&gt;
Both the training and validation losses converge smoothly without signs of overfitting, while the precision and recall metrics climb steadily to plateau near perfect scores. The mAP@50 reaches an impressive 99.5%. Most significantly, the confusion matrix now shows that the model has virtually eliminated false positives with background elements. The &amp;ldquo;background&amp;rdquo; column (rightmost) in the confusion matrix is now much cleaner, with only minimal misclassifications of actual cards as background noise.
&lt;a href="#lightbox-local_run_interference_visual-png-5" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/local_run_interference_visual.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/local_run_interference_visual.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/local_run_interference_visual.png 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/local_run_interference_visual.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/local_run_interference_visual.png 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/local_run_interference_visual.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/local_run_interference_visual.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/local_run_interference_visual.png 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/local_run_interference_visual.png"
alt="Real-time blackjack card detection and odds calculation"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-local_run_interference_visual-png-5" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/local_run_interference_visual.png"
alt="Real-time blackjack card detection and odds calculation"
loading="lazy"&gt;
&lt;/a&gt;
With the model trained and performing, it was time to deploy it and play some blackjack. Initially, I tested the system using &lt;a href="https://docs.roboflow.com/deploy/serverless-hosted-api-v2"&gt;Roboflow&amp;rsquo;s hosted API&lt;/a&gt;, which took around 4 seconds per inference - far too slow for practical gameplay. However, running the model locally on my laptop dramatically improved performance, achieving inference times of less than 0.1 seconds per image (1.3ms preprocess, 45.5ms inference, 0.4ms postprocess per image). I then &lt;a href="https://python-mss.readthedocs.io/"&gt;integrated the model with MSS&lt;/a&gt; to capture a real-time feed of my browser window. The system automatically overlays the detected cards with their predicted values and confidence scores
&lt;a href="#lightbox-black_jack_odds_demo-gif-6" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/black_jack_odds_demo.gif 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/black_jack_odds_demo.gif 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/black_jack_odds_demo.gif 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/black_jack_odds_demo.gif 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/black_jack_odds_demo.gif 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/black_jack_odds_demo.gif 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/black_jack_odds_demo.gif 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/black_jack_odds_demo.gif 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/black_jack_odds_demo.gif"
alt="Overview of selected fitted curves"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-black_jack_odds_demo-gif-6" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/black_jack_odds_demo.gif"
alt="Overview of selected fitted curves"
loading="lazy"&gt;
&lt;/a&gt;
The final implementation successfully combines the pieces: the computer vision model detects and identifies cards in real-time, feeds this information to the Monte Carlo simulation, and displays both the card recognition results and the calculated odds directly on screen - do not try this at your local (online) casino!&lt;/p&gt;</description></item><item><title>NVIDIA Likes Small Language Models</title><link>https://philippdubach.com/posts/nvidia-likes-small-language-models/</link><pubDate>Fri, 04 Jul 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/nvidia-likes-small-language-models/</guid><description>&lt;blockquote&gt;
&lt;p&gt;A Small Language Model (SLM) is a LM that can fit onto a common consumer electronic device and perform inference with latency sufficiently low to be practical when serving the agentic requests of one user. [&amp;hellip;] We note that as of 2025, we would be comfortable with considering most models below 10bn parameters in size to be SLMs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href="https://research.nvidia.com/labs/lpr/slm-agents/"&gt;(NVIDIA) researchers&lt;/a&gt; argue that most agentic applications perform repetitive, specialized tasks that don&amp;rsquo;t require the full generalist capabilities of LLMs. They propose heterogeneous agentic systems where SLMs handle most tasks while LLMs are used selectively for complex reasoning. They present three main arguments: (1) SLMs are sufficiently powerful for agentic tasks, as demonstrated by recent models like &lt;a href="https://azure.microsoft.com/en-us/products/phi"&gt;Microsoft&amp;rsquo;s Phi series&lt;/a&gt;, &lt;a href="https://research.nvidia.com/labs/adlr/nemotronh/"&gt;NVIDIA&amp;rsquo;s Nemotron-H family&lt;/a&gt;, and &lt;a href="https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9"&gt;Hugging Face&amp;rsquo;s SmolLM2 series&lt;/a&gt;, which achieve comparable performance to much larger models &lt;a href="https://arxiv.org/abs/2501.05465"&gt;while being 10-30x more efficient&lt;/a&gt;. (2) SLMs are inherently more operationally suitable for agentic systems due to their faster inference, lower latency, and ability to run on edge devices. (3) SLMs are necessarily more economical, offering significant cost savings in inference, fine-tuning, and deployment.&lt;/p&gt;</description></item><item><title>Novo Nordisk's Post-Patent Strategy</title><link>https://philippdubach.com/posts/novo-nordisks-post-patent-strategy/</link><pubDate>Sun, 29 Jun 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/novo-nordisks-post-patent-strategy/</guid><description>&lt;p&gt;Novo Nordisk, a long time member of my &amp;ldquo;regrets&amp;rdquo; stock list, has become &lt;a href="https://finance.yahoo.com/quote/NVO/chart/"&gt;reasonably affordable lately (-48% yoy)&lt;/a&gt;. Part of the reason being that they currently sit atop a ~$20 billion Ozempic/Wegovy franchise that faces &lt;a href="https://journals.library.columbia.edu/index.php/stlr/blog/view/653"&gt;patent expiration in 2031&lt;/a&gt;. That&amp;rsquo;s roughly seven years to replace their blockbuster drug. We revisit them today, since per &lt;a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(25)01185-7/fulltext"&gt;newly published Lancet data&lt;/a&gt;, Novo&amp;rsquo;s lead replacement candidate—amycretin—just posted some genuinely impressive Phase 1 results. The injectable version delivered &lt;a href="https://www.thelancet.com/cms/10.1016/S0140-6736(25)01185-7/asset/6f4ec048-c12e-4185-a860-a2dc988746c4/main.assets/gr3_lrg.jpg"&gt;24.3% average weight loss versus 1.1% for placebo&lt;/a&gt;, beating both current market leaders (Wegovy at 15% and Lilly&amp;rsquo;s Zepbound at 22.5%). Even the oral version hit 13.1% weight loss in just 12 weeks, with patients still losing weight when the trial ended.&lt;/p&gt;</description></item><item><title>Behavioral Economics &amp; Transit Policy</title><link>https://philippdubach.com/posts/behavioral-economics-transit-policy/</link><pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/behavioral-economics-transit-policy/</guid><description>&lt;p&gt;Over the weekend a &lt;a href="https://www.wsj.com/opinion/new-yorks-choice-cuomo-or-socialism-election-mayor-race-vote-mamdani-ede84c75"&gt;WSJ editorial on the 2025 New York City mayoral election&lt;/a&gt; called one of the potential Democratic candidates Zohran Mamdani &amp;ldquo;a literal socialist&amp;rdquo; for - among other things - running on the promise of &lt;a href="https://www.thenation.com/article/society/new-york-city-bus-free-fare/"&gt;free bus rides for all&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Zohran won New York&amp;rsquo;s first fare-free bus pilot on five lines across the city. As Mayor, he&amp;rsquo;ll permanently eliminate the fare on every city bus [&amp;hellip;] Fast and free buses will not only make buses reliable and accessible but will improve safety for riders and operators – creating the world-class service New Yorkers deserve.&lt;/p&gt;</description></item><item><title>It Just Ain’t So</title><link>https://philippdubach.com/posts/it-just-aint-so/</link><pubDate>Sun, 15 Jun 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/it-just-aint-so/</guid><description>&lt;blockquote&gt;
&lt;p&gt;It ain&amp;rsquo;t what you don&amp;rsquo;t know that gets you into trouble. It&amp;rsquo;s what you know for sure that just ain&amp;rsquo;t so.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This (not actually) Mark Twain quote from &lt;a href="https://en.wikipedia.org/wiki/The_Big_Short_(film)"&gt;The Big Short&lt;/a&gt; captures the sentiment of realizing that some foundational assumptions might be empirically wrong.&lt;/p&gt;
&lt;p&gt;A recent article by &lt;a href="https://antonvorobets.substack.com"&gt;Anton Vorobets&lt;/a&gt; that I came across in &lt;a href="https://www.bloomberg.com/authors/AQ0Te4IePFE/justina-lee"&gt;Justina Lee&lt;/a&gt;&amp;rsquo;s Quant Newsletter presents compelling evidence that challenges one of the field&amp;rsquo;s fundamental statistical assumptions, that asset returns follow normal distributions. Using 26 years of data from 10 US equity indices, he ran formal normality tests (Shapiro-Wilk, D&amp;rsquo;Agostino&amp;rsquo;s K², Anderson-Darling) and found that the normal distribution hypothesis gets rejected in most cases. The supposed &amp;ldquo;Aggregational Gaussianity&amp;rdquo; that academics invoke through Central Limit Theorem arguments? It&amp;rsquo;s mostly wishful thinking enabled by small sample sizes. As Vorobets observes:&lt;/p&gt;</description></item><item><title>Not All AI Skeptics Think Alike</title><link>https://philippdubach.com/posts/not-all-ai-skeptics-think-alike/</link><pubDate>Thu, 12 Jun 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/not-all-ai-skeptics-think-alike/</guid><description>&lt;p&gt;Apple&amp;rsquo;s recent paper &amp;ldquo;The Illusion of Thinking&amp;rdquo; has been widely understood to demonstrate that reasoning models don&amp;rsquo;t &amp;lsquo;actually&amp;rsquo; reason. Using controllable puzzle environments instead of contaminated math benchmarks, they discovered something fascinating: there are three distinct performance regimes when it comes to AI reasoning complexity. For simple problems, standard models actually outperform reasoning models while being more token-efficient. At medium complexity, reasoning models show their advantage. But at high complexity? Both collapse completely.
Here&amp;rsquo;s the kicker: reasoning models exhibit counterintuitive scaling behavior—their thinking effort increases with problem complexity up to a point, then declines despite having adequate token budget. It&amp;rsquo;s like watching a student give up mid-exam when the questions get too hard, even though they have plenty of time left.&lt;/p&gt;</description></item><item><title>Your AI Assistant Might Rat You Out</title><link>https://philippdubach.com/posts/your-ai-assistant-might-rat-you-out/</link><pubDate>Sat, 31 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/your-ai-assistant-might-rat-you-out/</guid><description>&lt;p&gt;There was this story going around the past few days&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Anthropic researchers found if Claude Opus 4 thinks you&amp;rsquo;re doing something immoral, it might &amp;ldquo;contact the press, contact regulators, try to lock you out of the system&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Mostly driven by a &lt;a href="https://x.com/sleepinyourhat/status/1925593359374328272"&gt;Sam Bowman tweet&lt;/a&gt; referring to the &lt;a href="https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf"&gt;Claude 4 System Card&lt;/a&gt; section 4.1.9 on high-agency behavior. The outrage was mostly by people misunderstanding the prerequisites necessary for such a scenario. Nevertheless, an interesting question emerged: What happens when you feed an AI model evidence of fraud and give it an email tool? According to Simon Willison&amp;rsquo;s latest experiment, &amp;ldquo;they pretty much all will&amp;rdquo; snitch on you to the authorities.&lt;/p&gt;</description></item><item><title>Gambling vs. Investing</title><link>https://philippdubach.com/posts/gambling-vs.-investing/</link><pubDate>Fri, 30 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/gambling-vs.-investing/</guid><description>&lt;p&gt;&lt;a href="https://kalshi.com/"&gt;Kalshi&lt;/a&gt;, a prediction market startup, is using its federal financial license to offer sports betting nationwide, even in states where it&amp;rsquo;s not legal. The move has earned them cease-and-desist letters from state gaming regulators, but CEO Tarek Mansour isn&amp;rsquo;t backing down:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We can go one by one for every financial market and it would fall under the definition of gambling. So what&amp;rsquo;s the difference?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It&amp;rsquo;s a question that cuts to the heart of modern finance. The founders argue that Wall Street blurred the line between investing and gambling long ago, and casting Kalshi as the latter is inconsistent at best. They have a point—if you can bet on oil futures, Nvidia&amp;rsquo;s stock price, or interest rate movements, why is wagering on NFL touchdowns more objectionable?&lt;/p&gt;</description></item><item><title>Modeling Glycemic Response with XGBoost</title><link>https://philippdubach.com/posts/modeling-glycemic-response-with-xgboost/</link><pubDate>Fri, 30 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/modeling-glycemic-response-with-xgboost/</guid><description>&lt;p&gt;Earlier this year I wrote how &lt;a href="https://philippdubach.com/posts/i-built-a-cgm-data-reader/"&gt;I built a CGM data reader&lt;/a&gt; after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an &lt;a href="https://ocw.mit.edu/courses/res-7-008-7-28x-molecular-biology/"&gt;MIT MOOC&lt;/a&gt; I became curious if given a meal&amp;rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on &lt;a href="https://pdub.click/2512231c"&gt;Personalized Nutrition by Prediction of Glycemic Responses&lt;/a&gt; which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my &lt;em&gt;own&lt;/em&gt; glycemic response curve. So I decided to build my own model. In the process I wrote this &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5914902"&gt;working paper&lt;/a&gt;.
&lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5914902"&gt;
&lt;a href="#lightbox-working_paper_overview-jpg-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/working_paper_overview.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/working_paper_overview.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/working_paper_overview.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/working_paper_overview.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/working_paper_overview.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/working_paper_overview.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/working_paper_overview.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/working_paper_overview.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/working_paper_overview.jpg"
alt="Overview of Working Paper Pages"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-working_paper_overview-jpg-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/working_paper_overview.jpg"
alt="Overview of Working Paper Pages"
loading="lazy"&gt;
&lt;/a&gt;&lt;/a&gt;
The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by &lt;a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue"&gt;Zeevi et al.&lt;/a&gt;&amp;rsquo;s approach. I quickly realized that training a model on my own data &lt;em&gt;only&lt;/em&gt; was not very promising if not impossible. To tackle this, I used the publicly available &lt;a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143"&gt;Hall dataset&lt;/a&gt; containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper).
&lt;a href="#lightbox-cgm-workflow-graph-jpg-1" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-workflow-graph.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-workflow-graph.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-workflow-graph.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-workflow-graph.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-workflow-graph.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-workflow-graph.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-workflow-graph.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-workflow-graph.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-workflow-graph.jpg"
alt="Overview of the CGM pipeline workflow"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-cgm-workflow-graph-jpg-1" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-workflow-graph.jpg"
alt="Overview of the CGM pipeline workflow"
loading="lazy"&gt;
&lt;/a&gt;
Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts).
&lt;a href="#lightbox-cgm-fitted-curve-large1-jpg-2" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-fitted-curve-large1.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-fitted-curve-large1.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-fitted-curve-large1.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-fitted-curve-large1.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-fitted-curve-large1.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-fitted-curve-large1.jpg"
alt="Overview of single fitted curve of cgm measurements"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-cgm-fitted-curve-large1-jpg-2" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/cgm-fitted-curve-large1.jpg"
alt="Overview of single fitted curve of cgm measurements"
loading="lazy"&gt;
&lt;/a&gt;
The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there&amp;rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged.
&lt;a href="#lightbox-example-fitted-cgm-measurements-jpg-3" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/example-fitted-cgm-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/example-fitted-cgm-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/example-fitted-cgm-measurements.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/example-fitted-cgm-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/example-fitted-cgm-measurements.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/example-fitted-cgm-measurements.jpg"
alt="Overview of selected fitted curves"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-example-fitted-cgm-measurements-jpg-3" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/example-fitted-cgm-measurements.jpg"
alt="Overview of selected fitted curves"
loading="lazy"&gt;
&lt;/a&gt;
I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.&lt;/p&gt;</description></item><item><title>The Model Said So</title><link>https://philippdubach.com/posts/the-model-said-so/</link><pubDate>Wed, 28 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/the-model-said-so/</guid><description>&lt;p&gt;LLMs make your life easier until they don&amp;rsquo;t.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Their intrinsic complexity and lack of transparency pose significant challenges, especially in the highly regulated financial sector&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Unlike other industries where &amp;ldquo;the model said so&amp;rdquo; might suffice, finance demands audit trails, bias detection,
and explainable decision-making—requirements that sit uncomfortably with neural networks containing billions of parameters.
The research highlights a fundamental tension that&amp;rsquo;s about to reshape fintech:
the same complexity that makes LLMs powerful at parsing market sentiment or generating investment reports also makes them regulatory nightmares
in a sector where you need to explain every decision to examiners.&lt;/p&gt;</description></item><item><title>Dual Mandate Tensions</title><link>https://philippdubach.com/posts/dual-mandate-tensions/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/dual-mandate-tensions/</guid><description>&lt;p&gt;Something interesting just happened at the National Bureau of Economic Research NBER&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We study the optimal monetary policy response to the imposition of tariffs in a model
with imported intermediate inputs. In a simple open-economy framework, we show
that a tariff maps exactly into a cost-push shock in the standard closed-economy New
Keynesian model, shifting the Phillips curve upward. We then characterize optimal
monetary policy, showing that it partially accommodates the shock to smooth the
transition to a more distorted long-run equilibrium—at the cost of higher short-run
inflation.&lt;/p&gt;</description></item><item><title>Beyond Monte Carlo: Tensor-Based Market Modeling</title><link>https://philippdubach.com/posts/beyond-monte-carlo-tensor-based-market-modeling/</link><pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/beyond-monte-carlo-tensor-based-market-modeling/</guid><description>&lt;p&gt;A fascinating new paper from Stefano Iabichino at UBS Investment Bank explores what happens when you take the attention mechanisms powering modern AI and apply them to Wall Street&amp;rsquo;s most fundamental pricing problems, tackling what might be quantitative finance&amp;rsquo;s most intractable challenge.&lt;/p&gt;
&lt;p&gt;The problem is elegantly simple yet profound: machine learning models are great at finding patterns in historical data, but financial theory demands that arbitrage-free prices be independent of past information. As the authors put it:&lt;/p&gt;</description></item><item><title>DeFi's $42 Billion Maturity Story</title><link>https://philippdubach.com/posts/defis-42-billion-maturity-story/</link><pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/defis-42-billion-maturity-story/</guid><description>&lt;p&gt;A new academic review by Ali Farhani reveals that institutional Total Value Locked in DeFi protocols hit $42 billion in 2024, with BlackRock leading the charge by launching a $250 million tokenized fund on Centrifuge.&lt;/p&gt;
&lt;p&gt;The numbers tell a remarkable story of maturation. Layer 2 solutions like Optimism and Arbitrum now dominate the scaling landscape, while zero-knowledge proofs have reduced compliance costs by 30%. Even the terminology is evolving—researchers now discuss &amp;ldquo;Total Value Redeemable&amp;rdquo; instead of the traditional TVL metric, acknowledging that not all locked value is immediately liquid. Despite technological advances, security incidents persist with painful regularity: $350 million lost in the Wormhole bridge exploit, $81 million in Orbit Chain&amp;rsquo;s multi-signature failure. Cross-chain bridges remain &amp;ldquo;high-risk attack targets,&amp;rdquo; a sobering reminder that connecting different blockchains is still more art than science. The regulatory landscape is complicated as well. Europe&amp;rsquo;s MiCA regulation provides clear frameworks, while the SEC maintains its enforcement-first approach. Hong Kong&amp;rsquo;s innovation sandbox offers a third path, balancing experimentation with oversight.&lt;/p&gt;</description></item><item><title>Trading on Market Sentiment</title><link>https://philippdubach.com/posts/trading-on-market-sentiment/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/trading-on-market-sentiment/</guid><description>&lt;p&gt;&lt;em&gt;This post is based in part on a 2022 presentation I gave for the &lt;a href="https://www.ft.com/content/3bd45acd-b323-3c6b-ba98-ac78b456f308"&gt;ICBS Student Investment Fund&lt;/a&gt; and my seminar work at Imperial College London.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As we were looking for new investment strategies for our Macro Sentiment Trading team, OpenAI had just published their &lt;a href="https://platform.openai.com/docs/models/gpt-3-5-turbo"&gt;GPT-3.5 Model&lt;/a&gt;. After first experiments with the model, we asked ourselves: How would large language models like GPT-3.5 perform in predicting sentiment in financial markets, where the signal-to-noise ratio is notoriously low? And could they potentially even outperform industry benchmarks at interpreting market sentiment from news headlines? The idea wasn&amp;rsquo;t entirely new. &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3389884"&gt;Studies&lt;/a&gt; &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1702854"&gt;[2]&lt;/a&gt; &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=685145"&gt;[3]&lt;/a&gt; have shown that investor sentiment, extracted from news and social media, can forecast market movements. But most approaches rely on traditional NLP models or proprietary systems like &lt;a href="https://www.ravenpack.com"&gt;RavenPack&lt;/a&gt;. With the recent advances in large language models, I wanted to test whether these more sophisticated models could provide a competitive edge in sentiment-based trading. Before looking at model selection, it&amp;rsquo;s worth understanding what makes trading on sentiment so challenging. News headlines present two fundamental problems that any robust system must address.
&lt;a href="#lightbox-news-relevance-timeline-jpg-0" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/news-relevance-timeline.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/news-relevance-timeline.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/news-relevance-timeline.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/news-relevance-timeline.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/news-relevance-timeline.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/news-relevance-timeline.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/news-relevance-timeline.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/news-relevance-timeline.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/news-relevance-timeline.jpg"
alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term."
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-news-relevance-timeline-jpg-0" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/news-relevance-timeline.jpg"
alt="Relative frequency of monthly Google News Search terms over 5 years. Numbers represent search interest relative to highest point. A value of 100 is the peak popularity for the term."
loading="lazy"&gt;
&lt;/a&gt;
First, headlines are inherently non-stationary. Unlike other data sources, news reflects the constantly shifting landscape of global events, political climates, economic trends, etc. A model trained on COVID-19 vaccine headlines from 2020 might struggle with geopolitical tensions in 2023. This temporal drift means algorithms must be adaptive to maintain relevance.
&lt;a href="#lightbox-headline-market-impact-jpg-1" style="display: block; width: 80%; margin: 0 auto; padding: 1rem 0; text-decoration: none;"&gt;
&lt;picture class="img-lightbox"&gt;
&lt;source media="(max-width: 768px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/headline-market-impact.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/headline-market-impact.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/headline-market-impact.jpg 640w"
sizes="80vw"&gt;
&lt;source media="(max-width: 1024px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/headline-market-impact.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/headline-market-impact.jpg 1024w"
sizes="80vw"&gt;
&lt;source media="(min-width: 1025px)"
srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/headline-market-impact.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/headline-market-impact.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/headline-market-impact.jpg 2000w"
sizes="80vw"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/headline-market-impact.jpg"
alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)"
class=""
width="1200"
loading="lazy"
style="width: 100%; height: auto; display: block;"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;a href="#_" id="lightbox-headline-market-impact-jpg-1" class="lightbox-overlay"&gt;
&lt;img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/headline-market-impact.jpg"
alt="Impact of headlines measured by subsequent index move (Data Source: Bloomberg)"
loading="lazy"&gt;
&lt;/a&gt;
Second, the relationship between headlines and market impact is far from obvious. Consider these actual headlines from November 2020: &amp;ldquo;Pfizer Vaccine Prevents 90% of COVID Infections&amp;rdquo; drove the S&amp;amp;P 500 up 1.85%, while &amp;ldquo;Pfizer Says Safety Milestone Achieved&amp;rdquo; barely moved the market at -0.05%. The same company, similar positive news, dramatically different market reactions.&lt;/p&gt;</description></item><item><title>Passive Investing's Active Problem</title><link>https://philippdubach.com/posts/passive-investings-active-problem/</link><pubDate>Sat, 15 Feb 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/passive-investings-active-problem/</guid><description>&lt;p&gt;(1) A new academic paper suggests the rise of passive investing may be fueling fragile market moves.
(2) According to a study to be published in the American Economic Review, evidence is building that active managers are slow to scoop up stocks en masse when prices move away from their intrinsic worth.
(3) Thanks to this lethargic trading behavior and the relentless boom in benchmark-tracking index funds, the impact of each trade on prices gets amplified, explaining how sell orders can induce broader equity gyrations&lt;/p&gt;</description></item><item><title>I Built a CGM Data Reader</title><link>https://philippdubach.com/posts/i-built-a-cgm-data-reader/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/i-built-a-cgm-data-reader/</guid><description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;If you&amp;rsquo;re reading this, you might also be interested in: &lt;a href="https://philippdubach.com/posts/modeling-glycemic-response-with-xgboost/"&gt;Modeling Glycemic Response with XGBoost&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Last year I put a Continuous Glucose Monitor (CGM) sensor, specifically the &lt;a href="https://www.freestyle.abbott"&gt;Abbott Freestyle Libre 3&lt;/a&gt;, on my left arm. Why? I wanted to optimize my nutrition for endurance cycling competitions. Where I live, the sensor is easy to get—without any medical prescription—and even easier to use. Unfortunately, Abbott&amp;rsquo;s &lt;a href="https://apps.apple.com/us/app/freestyle-librelink-us/id1325992472"&gt;FreeStyle LibreLink&lt;/a&gt; app is less than optimal (3,250 other people with an average rating of 2.9/5.0 seem to agree). In their defense, the web app LibreView does offer some nice reports which can be generated as PDFs—not very dynamic, but still something! What I had in mind was more in the fashion of the &lt;a href="https://ultrahuman.com/m1"&gt;Ultrahuman M1 dashboard&lt;/a&gt;. Unfortunately, I wasn&amp;rsquo;t allowed to use my Libre sensor (EU firmware) with their app (yes, I spoke to customer service).&lt;/p&gt;</description></item><item><title>The Green Bond Commitment Premium</title><link>https://philippdubach.com/posts/the-green-bond-commitment-premium/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/the-green-bond-commitment-premium/</guid><description>&lt;p&gt;The difference between green finance that works and green finance that doesn&amp;rsquo;t work seems to be commitment: Using a Difference-in-Differences model analyzing 2013-2023 bond data, researchers found no significant correlation between green bond issuance and CO2 emissions after net-zero policies were adopted. That&amp;rsquo;s the disappointing part. On the upside: companies issuing only green bonds showed higher ESG ratings, lower CO2 emissions, and lower financing costs, achieving substantial environmental benefits and economic advantages. Meanwhile, entities issuing both conventional and green bonds showed no environmental benefits, raising concerns about potential greenwashing.&lt;/p&gt;</description></item><item><title>Crypto Mean Reversion Trading</title><link>https://philippdubach.com/posts/crypto-mean-reversion-trading/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/crypto-mean-reversion-trading/</guid><description>&lt;p&gt;In late 2021, Lars Kaiser&amp;rsquo;s paper on &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S1544612318304513"&gt;seasonality in cryptocurrencies&lt;/a&gt; inspired me to use my &lt;a href="https://docs.kraken.com/api/"&gt;Kraken API Key&lt;/a&gt; to try and make some money. A quick summary of the paper: (1) Kaiser analyzes seasonality patterns across 10 cryptocurrencies (Bitcoin, Ethereum, etc.), examining returns, volatility, trading volume, and spreads (2) Finds no consistent calendar effects in cryptocurrency returns, supporting weak-form market efficiency (3) Observes robust patterns in trading activity - lower volume, volatility, and spreads in January, weekends, and summer months (4) Documents significant impact of January 2018 market sell-off on seasonality patterns (5) Reports a &amp;ldquo;reverse Monday effect&amp;rdquo; for Bitcoin (positive Monday returns) and &amp;ldquo;reverse January effect&amp;rdquo; (negative January returns) (6) Trading activity patterns suggest crypto markets are dominated by retail rather than institutional investors.&lt;/p&gt;</description></item><item><title>Meta's Edge AI Gambit</title><link>https://philippdubach.com/posts/metas-edge-ai-gambit/</link><pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/metas-edge-ai-gambit/</guid><description>&lt;p&gt;While the AI industry obsesses over ever-larger cloud models, Meta just made a somewhat contrarian bet with Llama 3.2. Instead of chasing GPT-4 with another massive, they&amp;rsquo;re going small and local — releasing lightweight AI models designed to run entirely on your phone. The technical achievement is genuinely impressive: vision-capable models that can analyze images and text, plus compact versions that &amp;ldquo;fit in as little as 1GB of memory.&amp;rdquo; But the real story might be more strategic. Meta is essentially arguing that the future of AI isn&amp;rsquo;t in OpenAI&amp;rsquo;s cloud-centric paradigm, but in edge computing where your data never leaves your device.&lt;/p&gt;</description></item><item><title>How Some Active Funds Create Their Own Returns</title><link>https://philippdubach.com/posts/how-some-active-funds-create-their-own-returns/</link><pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/how-some-active-funds-create-their-own-returns/</guid><description>&lt;p&gt;(1) Many active funds hold concentrated portfolios. Flow-driven trading in these securities causes price pressure, which pushes up the funds&amp;rsquo; existing positions resulting in realized returns.
(2) The researchers decomposes fund returns into a price pressure (self-inflated) and a fundamental component and show that when allocating capital across funds, investors are unable to identify whether realized returns are self-inflated or fundamental.
(3) Because investors chase self-inflated fund returns at a high frequency, even short-lived impact meaningfully affects fund flows at longer time scales.
(4) The combination of price impact and return chasing causes an endogenous feedback loop and a reallocation of wealth to early fund investors, which unravels once the price pressure reverts.
(5) The researchers find that flows chasing self-inflated returns predict bubbles in ETFs and their subsequent crashes, and lead to a daily wealth reallocation of 500 Million from ETFs alone.
(6) Around 2% of all daily flows and 8-12% of flows in the top decile of illiquid funds can be attributed to &amp;ldquo;Ponzi flows&amp;rdquo;. The researcher estimate that every day around $500 Million of investor wealth is reallocated because of the price impact of Ponzi flows.&lt;/p&gt;</description></item><item><title>OpenAI Cuts Prices, Raises Stakes</title><link>https://philippdubach.com/posts/openai-cuts-prices-raises-stakes/</link><pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/openai-cuts-prices-raises-stakes/</guid><description>&lt;p&gt;OpenAI&amp;rsquo;s GPT-4o launch is a classic Silicon Valley competitive strategy disguised as a product announcement.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GPT-4o is 2x faster, half the price, and has 5x higher rate limits compared to GPT-4 Turbo&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The real headline isn&amp;rsquo;t the multimodal wizardry — though watching an AI tutor walk through math problems or harmonize in real-time is genuinely impressive. It&amp;rsquo;s the economics. OpenAI is essentially paying developers to build on their platform while making it prohibitively expensive for competitors to match these specs profitably.&lt;/p&gt;</description></item><item><title>AlphaFold 3: Free for Science</title><link>https://philippdubach.com/posts/alphafold-3-free-for-science/</link><pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/alphafold-3-free-for-science/</guid><description>&lt;p&gt;Nothing says &amp;ldquo;we&amp;rsquo;re serious about dominating a market&amp;rdquo; quite like giving away breakthrough technology for free. Google&amp;rsquo;s latest move with AlphaFold 3 might be their most audacious version of this strategy yet.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;AlphaFold 3 can predict the structure and interactions of all of life&amp;rsquo;s molecules with unprecedented accuracy&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This isn&amp;rsquo;t just an incremental improvement - While previous versions of AlphaFold could predict protein structures, AlphaFold 3 models the interactions between proteins, DNA, RNA, and small molecules. It&amp;rsquo;s the difference between having a parts catalog and understanding how the entire machine works.&lt;/p&gt;</description></item><item><title>My First 'Optimal' Portfolio</title><link>https://philippdubach.com/posts/my-first-optimal-portfolio/</link><pubDate>Fri, 15 Mar 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/my-first-optimal-portfolio/</guid><description>&lt;p&gt;My introduction to quantitative portfolio optimization happened during my undergraduate years, inspired by Attilio Meucci&amp;rsquo;s &lt;a href="https://link.springer.com/book/10.1007/978-3-540-27904-4"&gt;Risk and Asset Allocation&lt;/a&gt; and the convex optimization &lt;a href="https://web.stanford.edu/~boyd/teaching.html"&gt;teachings of Diamond and Boyd at Stanford&lt;/a&gt;. With enthusiasm and perhaps more confidence than expertise, I created my first &amp;ldquo;optimal&amp;rdquo; portfolio. What struck me most was the disconnect between theory and accessibility. Modern Portfolio Theory had been established since 1990, yet the optimization tools remained largely locked behind proprietary software.&lt;/p&gt;</description></item><item><title>Zochi AI Passes Academic Peer Review</title><link>https://philippdubach.com/posts/zochi-ai-passes-academic-peer-review/</link><pubDate>Thu, 15 Feb 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/zochi-ai-passes-academic-peer-review/</guid><description>&lt;p&gt;Somewhere, a peer reviewer just realized they may have been outsmarted by a machine.&lt;/p&gt;
&lt;p&gt;Intology&amp;rsquo;s Zochi has achieved something unprecedented: becoming the first AI system to independently pass peer review at an A* scientific conference. Not just any conference—ACL, one of the most prestigious venues in computational linguistics.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Zochi represents a significant step forward in AI-assisted research, demonstrating the ability to comprehend and analyze complex academic literature with remarkable accuracy.&amp;rdquo;&lt;/p&gt;</description></item><item><title>The Tech behind this Site</title><link>https://philippdubach.com/posts/the-tech-behind-this-site/</link><pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate><guid>https://philippdubach.com/posts/the-tech-behind-this-site/</guid><description>&lt;p&gt;Similar to how Simon Willison describes his difficulties managing images for his &lt;a href="https://simonwillison.net/2024/Dec/22/link-blog/"&gt;approach to running a link blog&lt;/a&gt; I found it hard to remain true to pure markdown syntax but have images embedded in a responsive way on this site.&lt;/p&gt;
&lt;p&gt;My current pipeline is as follows: I host my all my images in a R2 bucket and serve them from &lt;code&gt;static.philippdubach.com&lt;/code&gt;. I use Cloudflares&amp;rsquo;s image resizing CDN do I never have to worry about serving images in appropriate size or format. I basically just upload them with the highes possible quality and Cloudflare takes care of the rest.&lt;/p&gt;</description></item></channel></rss>