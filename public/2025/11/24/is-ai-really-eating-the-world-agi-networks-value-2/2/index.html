<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://gc.zgo.at https://pdub.click; frame-ancestors 'self'; base-uri 'self';"><link rel=preconnect href=https://gc.zgo.at crossorigin><link rel=preconnect href=https://static.philippdubach.com crossorigin><link rel=preconnect href=https://pdub.click crossorigin><link rel=dns-prefetch href=https://gc.zgo.at><link rel=dns-prefetch href=https://static.philippdubach.com><link rel=dns-prefetch href=https://pdub.click><meta name=robots content="index, follow"><title>Is AI Really Eating the World? [Part 2] - philippdubach.com</title><meta name=description content="Part 2: How AI may transform recommendations and whether AGI creates lasting advantages or commoditized markets where value flows elsewhere."><meta name=keywords content="artificial intelligence,large language models,LLMs,recommendation systems,AGI artificial general intelligence,AI market dynamics,machine learning,pattern matching,AI applications,hyperscalers,vertical integration,AI competitive advantage,enterprise AI,AI commoditization"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/2025/11/24/is-ai-really-eating-the-world-agi-networks-value-2/2/><style>*{margin:0;padding:0;box-sizing:border-box}.visually-hidden{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);white-space:nowrap;border:0}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#ffff}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#ffff;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;padding-bottom:3rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem;line-height:1.3}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600;line-height:1.3}.post-title a:hover{color:#007acc}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.post-meta a{color:#007acc;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content p:last-child{margin-bottom:.5rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}@supports(text-wrap:balance){.archive-title{text-wrap:balance}}.single .post-title{font-size:1.5rem;margin-bottom:1rem;line-height:1.3}.pagination{margin-top:2rem;margin-bottom:1rem;text-align:center;padding-top:2rem;padding-bottom:1rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}.img-lightbox{cursor:pointer;transition:opacity .2s}.img-lightbox:hover{opacity:.9}.lightbox-overlay{display:none;position:fixed;top:0;left:0;width:100%;height:100%;background:#f8f9fa;z-index:9999;cursor:pointer;align-items:center;justify-content:center;padding:2rem;box-sizing:border-box}.lightbox-overlay:target{display:flex}.lightbox-overlay img{max-width:95%;max-height:95%;object-fit:contain;background:#f8f9fa}.feedback-footer{margin-top:.75rem;padding-top:.75rem;border-top:1px solid #e9ecef;text-align:center;color:#666;font-size:.9rem;margin-bottom:2rem}.feedback-footer p{margin:0;line-height:1.6}.feedback-footer a{color:#007acc;text-decoration:none}.feedback-footer a:hover{text-decoration:underline}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important;padding-bottom:.5rem !important}.pagination{margin-bottom:1.5rem !important;padding-bottom:1.5rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}.post-title,.post-title a,.single .post-title{line-height:1.2 !important}.post-content p:last-child{margin-bottom:.25rem !important}.feedback-footer{margin-top:.5rem !important;padding-top:.5rem !important;margin-bottom:1rem !important}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="Is AI Really Eating the World? AGI, Networks, Value [2/2]"><meta property="og:description" content="Part 2: How AI may transform recommendations and whether AGI creates lasting advantages or commoditized markets where value flows elsewhere."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2025/11/24/is-ai-really-eating-the-world-agi-networks-value-2/2/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-eatingtheworld2.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-eatingtheworld2.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-eatingtheworld2.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="article:published_time" content="2025-11-24T00:00:00Z"><meta property="article:modified_time" content="2025-11-24T00:00:00Z"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Is AI Really Eating the World? AGI, Networks, Value [2/2]"><meta name=twitter:description content="Part 2: How AI may transform recommendations and whether AGI creates lasting advantages or commoditized markets where value flows elsewhere."><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-eatingtheworld2.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-eatingtheworld2.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"http:\/\/localhost:1313\/posts/"},{"@type":"ListItem","position":3,"name":"Is AI Really Eating the World? AGI, Networks, Value [2\/2]","item":"http:\/\/localhost:1313\/2025\/11\/24\/is-ai-really-eating-the-world-agi-networks-value-2\/2\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Is AI Really Eating the World? AGI, Networks, Value [2\/2]","name":"Is AI Really Eating the World? AGI, Networks, Value [2\/2]","description":"Part 2: How AI may transform recommendations and whether AGI creates lasting advantages or commoditized markets where value flows elsewhere.","keywords":["artificial intelligence","large language models","LLMs","recommendation systems","AGI artificial general intelligence","AI market dynamics","machine learning","pattern matching","AI applications","hyperscalers","vertical integration","AI competitive advantage","enterprise AI","AI commoditization"],"articleBody":"\"Start by reading Is AI Really Eating the World? What we\\u0026rsquo;ve Learned [1/2]\\nAll current recommendation systems work by capturing and analyzing user behavior at scale. Netflix needs millions of users watching millions of hours to train its recommendation algorithm. Amazon needs billions of purchases. The network effect comes from data scale. What if LLMs can bypass this? What if an LLM can provide useful recommendations by reasoning about conceptual relationships rather than requiring massive behavioral datasets? If I ask for \\u0026ldquo;books like Pirsig\\u0026rsquo;s Zen and the Art of Motorcycle Maintenance but more focused on Eastern philosophy,\\u0026rdquo; a sufficiently capable LLM might answer well without needing to observe 100 million readers. It understands (or appears to understand) the conceptual space. I\\u0026rsquo;m uncertain whether LLMs can do this reliably by the end of 2025. The fundamental question is whether they reason or pattern-match at a very sophisticated level. Recent research suggests LLMs may rely more on statistical correlations than true reasoning. If it\\u0026rsquo;s mostly pattern-matching, they still need the massive datasets and we\\u0026rsquo;re back to conventional network effects. If they can actually reason over conceptual spaces, that\\u0026rsquo;s different. That would unbundle data network effects from recommendation quality. Recommendation quality would depend on model capability, not data scale. And if model capability is commoditizing, then the value in recommendations flows to whoever owns customer relationships and distribution, not to whoever has the most data or the best model. I lean toward thinking LLMs are sophisticated pattern-matchers rather than reasoners, which means traditional network effects still apply. But this is one area where I\\u0026rsquo;m genuinely waiting to see more evidence.\\nNow, on AGI. The Silicon Valley consensus, articulated by Sutskever, Altman, Musk, and others, is that we\\u0026rsquo;re on a clear path to artificial general intelligence in the next few years, possibly by 2027 or 2028. The argument goes: scaling laws continue to hold, we\\u0026rsquo;re seeing emergent capabilities at each scale jump, and there\\u0026rsquo;s no obvious wall before we reach human-level performance across all cognitive domains. I remain unconvinced. Not because I think AGI is impossible, but because the path from \\u0026ldquo;really good at pattern completion and probabilistic next-token prediction\\u0026rdquo; to \\u0026ldquo;general reasoning and planning capabilities\\u0026rdquo; seems less straightforward than the AI CEOs suggest. Current LLMs still fail in characteristic ways on tasks requiring actual causal reasoning, spatial reasoning, or planning over extended horizons. They\\u0026rsquo;re getting better, but the improvement curve on these specific capabilities looks different from the improvement curve on language modeling perplexity. That suggests to me that we might need architectural innovations beyond just scaling, and those are harder to predict.\\nBut let\\u0026rsquo;s say I\\u0026rsquo;m wrong. Let\\u0026rsquo;s say AGI arrives by 2028. Even then, I find it hard to model why this would be tremendously economically beneficial specifically to the companies that control the models. Here\\u0026rsquo;s why: we already have multiple competing frontier models (ChatGPT, Claude, Gemini, Microsoft\\u0026rsquo;s offerings, and now DeepSeek). If AGI arrives, it likely arrives for multiple players at roughly the same time, given how quickly capabilities diffuse in this space. Multiple competing AGIs means price competition. Price competition in a product with near-zero marginal cost means prices collapse toward marginal cost. Where does economic value flow in that scenario? It flows to the users of AI, not the providers. Engineering firms using AGI for materials development capture value through better materials. Pharmaceutical companies using AGI for drug discovery capture value through better drugs. Retailers using AGI for inventory management capture value through better margins. The AGI providers compete with each other to offer the capability at the lowest price. This is basic microeconomics. You capture value when you have market power, either through monopoly, through differentiation, or through control of a scarce input. If models are commodities or near-commodities, model providers have none of these.\\nThe counterargument is that one provider achieves escape velocity and reaches AGI first with enough of a lead that they establish dominance before others catch up. This is the OpenAI/Microsoft theory of the case. Maybe. But the evidence so far suggests capability leads are measured in months, not years. GPT-4 launched in March 2023 with a substantial lead. Within six months, Claude 2 was comparable. Within a year, multiple models clustered around similar capability. The diffusion is fast. Another counterargument is vertical integration. Maybe the hyperscalers that control cloud infrastructure plus model development plus customer relationships plus application distribution can capture value even if models themselves commoditize. This is more plausible, essentially the AWS playbook. Amazon didn\\u0026rsquo;t make money by having the best database. They made money by owning the infrastructure, the customer relationships, and the entire stack from hardware to application platform. Microsoft is clearly pursuing this strategy with Azure plus OpenAI plus Copilot plus Office integration. Google has Search plus Cloud plus Gemini plus Workspace. This could work, but it\\u0026rsquo;s a different thesis than \\u0026ldquo;we have the best model.\\u0026rdquo; It\\u0026rsquo;s \\u0026ldquo;we control the distribution and can bundle.\\u0026rdquo;\\nEvans shows a scatter plot (Slide 34) of model benchmark scores from standard evaluations like MMLU and HumanEval. Leaders change weekly. The gaps are small. Meanwhile, consumer awareness doesn\\u0026rsquo;t track model quality. ChatGPT dominates with over 700 million weekly active users not because it has the best model anymore, but because it got there first and built brand. If models are commodities, value moves up the stack to product design, distribution, vertical integration, and customer relationships. This is exactly what happened with databases. Oracle didn\\u0026rsquo;t win because they had the best database engine. They won through enterprise sales, support contracts, and ecosystem lock-in. Microsoft didn\\u0026rsquo;t beat them with a better database. They won by bundling SQL Server with Windows Server and offering acceptable performance at a lower price. The SaaS pattern suggests something similar happens here. The model becomes an input. The applications built on top, the customer relationships, the distribution, those become the valuable assets. Why do I think this pattern applies rather than, say, the search pattern where Google maintained dominance despite no fundamental technical moat? Two reasons: (1) Search had massive data network effects. Every search improved the algorithm, and Google\\u0026rsquo;s scale meant they improved faster. LLMs have weaker data network effects because the pretraining data is largely static and publicly available, and fine-tuning data requirements are smaller. (2) Search had winner-take-all dynamics through defaults and single-answer demand. You pick one search engine and use it for everything. AI applications look more diverse. You might use different models for different tasks, or your applications might switch between models transparently based on price and performance. The switching costs are lower.\\nSo where does this leave us? The technology exists and the underlying capabilities are real. But I think the current evidence points toward a world where value flows to applications and customer relationships, and where the $400 billion the hyperscalers are spending buys them competitive positioning rather than monopoly. The integrators are making money now by helping enterprises navigate uncertainty. Some of that will produce real productivity gains. Much of it is expensive signaling and competitive positioning. The startups unbundling existing software will see mixed results, the ones that succeed will do so by owning distribution or solving really specific problems where switching costs are high, not by having better access to AI. The biggest uncertainty is whether the hyperscalers can use vertical integration to capture value anyway, or whether the applications layer fragments and value flows to thousands of specialized companies. That depends less on AI capabilities and more on competitive dynamics, regulation, and whether enterprises prefer integrated platforms or best-of-breed solutions. My guess is we end up somewhere in between. The hyperscalers maintain strong positions through bundling and infrastructure control. A long tail of specialized applications captures value in specific verticals. The model providers themselves, unless they\\u0026rsquo;re also infrastructure providers, struggle to capture value proportional to the capability they\\u0026rsquo;re creating. But I\\u0026rsquo;m genuinely uncertain, and that uncertainty is where the interesting bets are.\\nWhat makes Evans\\u0026rsquo; presentation valuable is precisely what frustrated me about it initially: his refusal to collapse uncertainty prematurely. I\\u0026rsquo;ve spent this entire post arguing for a specific view of how value will flow in AI markets, but Evans is right that we\\u0026rsquo;re pattern-matching from incomplete data. Every previous platform shift looked obvious in retrospect and uncertain in real time. The PC revolution, the internet boom, mobile, they all had credible skeptics who turned out wrong and credible bulls who were right for the wrong reasons. Evans\\u0026rsquo; discipline in laying out the full range of possibilities, from commodity to monopoly to something entirely new, is the intellectually honest position. I\\u0026rsquo;ve made specific bets here because that\\u0026rsquo;s useful for readers trying to navigate the space, but I\\u0026rsquo;m more confident in my framework than in my conclusions.\\n\"","wordCount":1449,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-eatingtheworld2.jpg","datePublished":"2025-11-24T00:00:00Z","dateModified":"2025-11-24T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/2025\/11\/24\/is-ai-really-eating-the-world-agi-networks-value-2\/2\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><div class=site-title><a href=http://localhost:1313/>philippdubach</a></div><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/posts/>Archive</a></li><li><a href=/about/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title>Is AI Really Eating the World? AGI, Networks, Value [2/2]</h1><div class=post-meta><time datetime=2025-11-24T00:00:00Z>November 24, 2025
</time>• 1500 words
• 7 min read
• <a href=https://www.ben-evans.com/presentations/ target=_blank rel=noopener>via</a>
• <a href=# id=share-link title="Copy short link" aria-label="Copy short link" style=text-decoration:none>∞</a>
<span id=share-status></span></div></header><div class=post-content><p><em>Start by reading <a href=/2025/11/23/is-ai-really-eating-the-world-what-weve-learned-1/2/>Is AI Really Eating the World? What we&rsquo;ve Learned [1/2]</a></em></p><p>All current <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendation systems</a> work by capturing and analyzing user behavior at scale. Netflix needs millions of users watching millions of hours to train its recommendation algorithm. Amazon needs billions of purchases. The <a href=https://en.wikipedia.org/wiki/Network_effect>network effect</a> comes from data scale. What if LLMs can bypass this? What if an LLM can provide useful recommendations by reasoning about conceptual relationships rather than requiring massive behavioral datasets? If I ask for &ldquo;books like Pirsig&rsquo;s Zen and the Art of Motorcycle Maintenance but more focused on Eastern philosophy,&rdquo; a sufficiently capable LLM might answer well without needing to observe 100 million readers. It understands (or appears to understand) the conceptual space. I&rsquo;m uncertain whether LLMs can do this reliably by the end of 2025. The fundamental question is whether they reason or pattern-match at a very sophisticated level. <a href=https://arxiv.org/abs/2308.03762>Recent research suggests LLMs may rely more on statistical correlations than true reasoning</a>. If it&rsquo;s mostly pattern-matching, they still need the massive datasets and we&rsquo;re back to conventional network effects. If they can actually reason over conceptual spaces, that&rsquo;s different. That would unbundle data network effects from recommendation quality. Recommendation quality would depend on model capability, not data scale. And if model capability is commoditizing, then the value in recommendations flows to whoever owns customer relationships and distribution, not to whoever has the most data or the best model. I lean toward thinking LLMs are sophisticated pattern-matchers rather than reasoners, which means traditional network effects still apply. But this is one area where I&rsquo;m genuinely waiting to see more evidence.</p><p>Now, on AGI. The Silicon Valley consensus, articulated by <a href=https://sherwood.news/tech/gi-artificial-general-intelligence-when-predictions/>Sutskever, Altman, Musk, and others</a>, is that we&rsquo;re on a clear path to artificial general intelligence in the next few years, possibly by 2027 or 2028. The argument goes: <a href=https://arxiv.org/abs/2001.08361>scaling laws</a> continue to hold, we&rsquo;re seeing emergent capabilities at each scale jump, and there&rsquo;s no obvious wall before we reach human-level performance across all cognitive domains. I remain unconvinced. Not because I think AGI is impossible, but because the path from &ldquo;really good at pattern completion and probabilistic next-token prediction&rdquo; to &ldquo;general reasoning and planning capabilities&rdquo; seems less straightforward than the AI CEOs suggest. <a href=https://arxiv.org/abs/2305.00050>Current LLMs still fail in characteristic ways on tasks requiring actual causal reasoning</a>, spatial reasoning, or planning over extended horizons. They&rsquo;re getting better, but the improvement curve on these specific capabilities looks different from the improvement curve on language modeling perplexity. That suggests to me that we might need architectural innovations beyond just scaling, and those are harder to predict.</p><p>But let&rsquo;s say I&rsquo;m wrong. Let&rsquo;s say AGI arrives by 2028. Even then, I find it hard to model why this would be tremendously economically beneficial specifically to the companies that control the models. Here&rsquo;s why: we already have multiple competing frontier models (ChatGPT, Claude, Gemini, Microsoft&rsquo;s offerings, and now DeepSeek). If AGI arrives, it likely arrives for multiple players at roughly the same time, given how quickly capabilities diffuse in this space. Multiple competing AGIs means price competition. Price competition in a product with near-zero marginal cost means prices collapse toward marginal cost. Where does economic value flow in that scenario? It flows to the users of AI, not the providers. Engineering firms using AGI for materials development capture value through better materials. Pharmaceutical companies using AGI for drug discovery capture value through better drugs. Retailers using AGI for inventory management capture value through better margins. The AGI providers compete with each other to offer the capability at the lowest price. This is basic microeconomics. You capture value when you have market power, either through monopoly, through differentiation, or through control of a scarce input. If models are commodities or near-commodities, model providers have none of these.</p><p>The counterargument is that one provider achieves escape velocity and reaches AGI first with enough of a lead that they establish dominance before others catch up. This is the OpenAI/Microsoft theory of the case. Maybe. But the evidence so far suggests capability leads are measured in months, not years. <a href=https://openai.com/index/gpt-4-research/>GPT-4 launched in March 2023</a> with a substantial lead. Within six months, <a href=https://www.anthropic.com/news/claude-2>Claude 2 was comparable</a>. Within a year, multiple models clustered around similar capability. The diffusion is fast. Another counterargument is vertical integration. Maybe the hyperscalers that control cloud infrastructure plus model development plus customer relationships plus application distribution can capture value even if models themselves commoditize. This is more plausible, essentially the AWS playbook. Amazon didn&rsquo;t make money by having the best database. They made money by owning the infrastructure, the customer relationships, and the entire stack from hardware to application platform. Microsoft is clearly pursuing this strategy with <a href=https://www.microsoft.com/en-us/microsoft-365/blog/2023/03/16/introducing-microsoft-365-copilot-a-whole-new-way-to-work/>Azure plus OpenAI plus Copilot plus Office integration</a>. Google has Search plus Cloud plus Gemini plus Workspace. This could work, but it&rsquo;s a different thesis than &ldquo;we have the best model.&rdquo; It&rsquo;s &ldquo;we control the distribution and can bundle.&rdquo;</p><p>Evans shows a scatter plot (Slide 34) of model benchmark scores from <a href=https://arxiv.org/abs/2009.03300>standard evaluations like MMLU and HumanEval</a>. Leaders change weekly. The gaps are small. Meanwhile, consumer awareness doesn&rsquo;t track model quality. ChatGPT dominates with over <a href=https://openai.com/index/how-people-are-using-chatgpt/>700 million weekly active users</a> not because it has the best model anymore, but because it got there first and built brand. If models are commodities, value moves up the stack to product design, distribution, vertical integration, and customer relationships. This is exactly what happened with databases. Oracle didn&rsquo;t win because they had the best database engine. They won through enterprise sales, support contracts, and ecosystem lock-in. Microsoft didn&rsquo;t beat them with a better database. They won by bundling SQL Server with Windows Server and offering acceptable performance at a lower price. The SaaS pattern suggests something similar happens here. The model becomes an input. The applications built on top, the customer relationships, the distribution, those become the valuable assets. Why do I think this pattern applies rather than, say, the search pattern where Google maintained dominance despite no fundamental technical moat? Two reasons: (1) Search had massive data network effects. Every search improved the algorithm, and Google&rsquo;s scale meant they improved faster. LLMs have weaker data network effects because the pretraining data is largely static and publicly available, and fine-tuning data requirements are smaller. (2) Search had winner-take-all dynamics through defaults and single-answer demand. You pick one search engine and use it for everything. AI applications look more diverse. You might use different models for different tasks, or your applications might switch between models transparently based on price and performance. The switching costs are lower.</p><p>So where does this leave us? The technology exists and the underlying capabilities are real. But I think the current evidence points toward a world where value flows to applications and customer relationships, and where the $400 billion the hyperscalers are spending buys them competitive positioning rather than monopoly. The integrators are making money now by helping enterprises navigate uncertainty. Some of that will produce real productivity gains. Much of it is expensive signaling and competitive positioning. The startups unbundling existing software will see mixed results, the ones that succeed will do so by owning distribution or solving really specific problems where switching costs are high, not by having better access to AI. The biggest uncertainty is whether the hyperscalers can use vertical integration to capture value anyway, or whether the applications layer fragments and value flows to thousands of specialized companies. That depends less on AI capabilities and more on competitive dynamics, regulation, and whether enterprises prefer integrated platforms or best-of-breed solutions. My guess is we end up somewhere in between. The hyperscalers maintain strong positions through bundling and infrastructure control. A long tail of specialized applications captures value in specific verticals. The model providers themselves, unless they&rsquo;re also infrastructure providers, struggle to capture value proportional to the capability they&rsquo;re creating. But I&rsquo;m genuinely uncertain, and that uncertainty is where the interesting bets are.</p><p>What makes Evans&rsquo; presentation valuable is precisely what frustrated me about it initially: his refusal to collapse uncertainty prematurely. I&rsquo;ve spent this entire post arguing for a specific view of how value will flow in AI markets, but Evans is right that we&rsquo;re pattern-matching from incomplete data. Every previous platform shift looked obvious in retrospect and uncertain in real time. The PC revolution, the internet boom, mobile, they all had credible skeptics who turned out wrong and credible bulls who were right for the wrong reasons. Evans&rsquo; discipline in laying out the full range of possibilities, from commodity to monopoly to something entirely new, is the intellectually honest position. I&rsquo;ve made specific bets here because that&rsquo;s useful for readers trying to navigate the space, but I&rsquo;m more confident in my framework than in my conclusions.</p></div></article><footer class=feedback-footer><p>Have feedback, comments, or ideas? <a href=mailto:info@philippdubach.com>I'd love to hear from you</a>.</p><p class=latest-post>Latest: <a href=/2025/12/12/how-ai-is-shaping-my-investment-portfolio-for-2026/>How AI is Shaping My Investment Portfolio for 2026</a></p><p class=most-read id=top-post-week style=min-height:1.5em></p></footer><script>(function(){var e,n,t=document.getElementById("top-post-week");if(t&&fetch("https://weekly-top-goatcounter-api.philippd.workers.dev").then(function(e){return e.ok?e.json():Promise.reject()}).then(function(e){if(e.hits&&e.hits.length>0){var n=e.hits[0];t.innerHTML='Most read: <a href="'+n.path+'">'+n.title.replace(" - philippdubach.com","")+"</a>"}else t.remove()}).catch(function(){t.remove()}),n=document.getElementById("share-link"),e=document.getElementById("share-status"),!n)return;n.addEventListener("click",function(t){t.preventDefault(),e.textContent="...";var s,n=window.location.href;navigator.clipboard&&navigator.clipboard.write&&typeof ClipboardItem!="undefined"?(s=new ClipboardItem({"text/plain":fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(e){var t=e.shorturl||"";return new Blob([t],{type:"text/plain"})}).catch(function(){return new Blob([""],{type:"text/plain"})})}),navigator.clipboard.write([s]).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})):fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(t){var n=t.shorturl;n&&navigator.clipboard&&navigator.clipboard.writeText?navigator.clipboard.writeText(n).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent=n,setTimeout(function(){e.textContent=""},4e3)}):n?(e.textContent=n,setTimeout(function(){e.textContent=""},4e3)):(e.textContent="error",setTimeout(function(){e.textContent=""},2e3))}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})})})()</script></main></div></body></html>