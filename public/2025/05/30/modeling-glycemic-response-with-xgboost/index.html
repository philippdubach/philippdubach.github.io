<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Modeling Glycemic Response with XGBoost - philippdubach.com</title><meta name=description content="A machine learning project using XGBoost to predict postprandial glucose responses from meal macronutrients and individual characteristics."><meta name=keywords content="continuous glucose monitoring,CGM data,postprandial glucose response,XGBoost regressor,machine learning,personalized nutrition,glycemic response prediction,glucose curve modeling,macronutrients,blood sugar prediction,MIT MOOC,Hall dataset,Gaussian curve fitting,hyperparameter tuning,feature engineering"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.147.8"><link rel=canonical href=http://localhost:1313/2025/05/30/modeling-glycemic-response-with-xgboost/><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#f8f9fa}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#f8f9fa;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600}.post-title a:hover{color:#007acc}.external-link{color:#007acc;font-weight:400;margin-left:.25rem}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.permalink{text-decoration:none;color:#999;font-weight:400}.permalink:hover{color:#007acc}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}.archive-title .permalink{margin-left:.5rem}.single .post-title{font-size:1.75rem;margin-bottom:1rem}.pagination{margin-top:2rem;text-align:center;padding-top:2rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}@media(prefers-color-scheme:dark){.pagination{border-top-color:#404040}.pagination a{color:#4da6ff}.pagination a:hover{color:#66b3ff}}@media(prefers-color-scheme:dark){.project-tag{background-color:#404040;color:#b0b0b0;border-color:#555}}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}}@media(prefers-color-scheme:dark){body{background-color:#2a2a2a;color:#e0e0e0}.sidebar{background-color:#2a2a2a;border-right-color:#404040}.site-title a{color:#e0e0e0}.post-title a{color:#e0e0e0}.archive-title a{color:#e0e0e0}.post-title a:hover,.navigation a:hover,.social-links a:hover,.archive-title a:hover{color:#4da6ff}.post{border-bottom-color:#404040}.footer{border-top-color:#404040}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="Modeling Glycemic Response with XGBoost"><meta property="og:description" content="A machine learning project using XGBoost to predict postprandial glucose responses from meal macronutrients and individual characteristics."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2025/05/30/modeling-glycemic-response-with-xgboost/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-xgboost.jpg"><meta property="article:published_time" content="2025-05-30T00:00:00Z"><meta property="article:modified_time" content="2025-05-30T00:00:00Z"><meta property="article:section" content="posts"><meta property="article:tag" content="Project"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Modeling Glycemic Response with XGBoost"><meta name=twitter:description content="A machine learning project using XGBoost to predict postprandial glucose responses from meal macronutrients and individual characteristics."><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-xgboost.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"http:\/\/localhost:1313\/posts/"},{"@type":"ListItem","position":3,"name":"Modeling Glycemic Response with XGBoost","item":"http:\/\/localhost:1313\/2025\/05\/30\/modeling-glycemic-response-with-xgboost\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Modeling Glycemic Response with XGBoost","name":"Modeling Glycemic Response with XGBoost","description":"A machine learning project using XGBoost to predict postprandial glucose responses from meal macronutrients and individual characteristics.","keywords":["continuous glucose monitoring","CGM data","postprandial glucose response","XGBoost regressor","machine learning","personalized nutrition","glycemic response prediction","glucose curve modeling","macronutrients","blood sugar prediction","MIT MOOC","Hall dataset","Gaussian curve fitting","hyperparameter tuning","feature engineering"],"articleBody":"\"Earlier this year I wrote how I built a CGM data reader after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an MIT MOOC I became curious if given a meal\\u0026rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on Personalized Nutrition by Prediction of Glycemic Responses which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my own glycemic response curve. So I decided to build my own model. In the process I wrote this working paper. The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by Zeevi et al.\\u0026rsquo;s approach. I quickly realized that training a model on my own data only was not very promising if not impossible. To tackle this, I used the publicly available Hall dataset containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper). Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts). The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there\\u0026rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged. I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.\\nWhile the model achieved moderate success predicting amplitude (R² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (R² = -0.76), and curve width prediction was barely better (R² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of an R² \\u0026gt; 0.7. Studies that have achieved better predictive performance typically used much larger datasets (\\u0026gt;1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training datasets, would be necessary.\\nThe complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my GitHub repository. _ _\\n(10/06/2025) Update: Today I came across Marcel Salathé\\u0026rsquo;s LinkedIn post on a publication out of EPFL: Personalized glucose prediction using in situ data only.\\nWith data from over 1,000 participants of the Food \\u0026amp; You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).\\nAs expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs R² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the Hall dataset) represents a fundamental difference in statistical power and generalizability. They addressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the \\u0026ldquo;Food \\u0026amp; You\\u0026rdquo; study (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).\\nApart from that I am excited to - at a first glance - observe the following similarities: (1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications. (2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (R², RMSE, MAE, Pearson correlation). (3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics. (4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC). (5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning. (6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.\\n\"","wordCount":833,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-xgboost.jpg","datePublished":"2025-05-30T00:00:00Z","dateModified":"2025-05-30T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/2025\/05\/30\/modeling-glycemic-response-with-xgboost\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"http:\/\/localhost:1313\/posts/"},{"@type":"ListItem","position":3,"name":"Modeling Glycemic Response with XGBoost","item":"http:\/\/localhost:1313\/2025\/05\/30\/modeling-glycemic-response-with-xgboost\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Modeling Glycemic Response with XGBoost","name":"Modeling Glycemic Response with XGBoost","description":"A machine learning project using XGBoost to predict postprandial glucose responses from meal macronutrients and individual characteristics.","keywords":["continuous glucose monitoring","CGM data","postprandial glucose response","XGBoost regressor","machine learning","personalized nutrition","glycemic response prediction","glucose curve modeling","macronutrients","blood sugar prediction","MIT MOOC","Hall dataset","Gaussian curve fitting","hyperparameter tuning","feature engineering"],"articleBody":"\"Earlier this year I wrote how I built a CGM data reader after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an MIT MOOC I became curious if given a meal\\u0026rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on Personalized Nutrition by Prediction of Glycemic Responses which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my own glycemic response curve. So I decided to build my own model. In the process I wrote this working paper. The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by Zeevi et al.\\u0026rsquo;s approach. I quickly realized that training a model on my own data only was not very promising if not impossible. To tackle this, I used the publicly available Hall dataset containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper). Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts). The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there\\u0026rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged. I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.\\nWhile the model achieved moderate success predicting amplitude (R² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (R² = -0.76), and curve width prediction was barely better (R² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of an R² \\u0026gt; 0.7. Studies that have achieved better predictive performance typically used much larger datasets (\\u0026gt;1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training datasets, would be necessary.\\nThe complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my GitHub repository. _ _\\n(10/06/2025) Update: Today I came across Marcel Salathé\\u0026rsquo;s LinkedIn post on a publication out of EPFL: Personalized glucose prediction using in situ data only.\\nWith data from over 1,000 participants of the Food \\u0026amp; You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).\\nAs expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs R² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the Hall dataset) represents a fundamental difference in statistical power and generalizability. They addressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the \\u0026ldquo;Food \\u0026amp; You\\u0026rdquo; study (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).\\nApart from that I am excited to - at a first glance - observe the following similarities: (1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications. (2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (R², RMSE, MAE, Pearson correlation). (3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics. (4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC). (5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning. (6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.\\n\"","wordCount":833,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-xgboost.jpg","datePublished":"2025-05-30T00:00:00Z","dateModified":"2025-05-30T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/2025\/05\/30\/modeling-glycemic-response-with-xgboost\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script><script>(function(){let e=[],n=[],t=null;const s=["offsetHeight","offsetWidth","offsetTop","offsetLeft","scrollHeight","scrollWidth","scrollTop","scrollLeft","clientHeight","clientWidth","clientTop","clientLeft"];s.forEach(t=>{const s=Object.getOwnPropertyDescriptor(HTMLElement.prototype,t);s&&s.get&&Object.defineProperty(HTMLElement.prototype,t,{get:function(){return e.length>0&&(console.warn(`⚠️ FORCED REFLOW: Reading ${t} after DOM write!`),console.log("Recent writes:",e),console.log("Element:",this),console.trace()),n.push({prop:t,element:this.tagName}),s.get.call(this)}})});const o=Object.getOwnPropertyDescriptor(HTMLElement.prototype,"style");Object.defineProperty(HTMLElement.prototype,"style",{get:function(){const s=o.get.call(this);return new Proxy(s,{set:function(s,o,i){return e.push({property:o,value:i,element:s.parentElement?.tagName}),n=[],t||(t=requestAnimationFrame(()=>{e=[],t=null})),s[o]=i,!0}})}});const i=Element.prototype.getBoundingClientRect;Element.prototype.getBoundingClientRect=function(){return e.length>0&&(console.warn("⚠️ FORCED REFLOW: getBoundingClientRect() called after DOM write!"),console.trace()),i.call(this)}})()</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><h1 class=site-title><a href=http://localhost:1313/>philippdubach</a></h1><p class=site-description>Personal Projects, Curated Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Archive</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title>Modeling Glycemic Response with XGBoost</h1><div class=post-meta><time datetime=2025-05-30T00>May 30, 2025</time></div></header><div class=post-content><p>Earlier this year I wrote how <a href=/2025/01/02/i-built-a-cgm-data-reader/>I built a CGM data reader</a> after wearing a continuous glucose monitor myself. Since I was already logging my macronutrients and learning more about molecular biology in an <a href=https://ocw.mit.edu/courses/res-7-008-7-28x-molecular-biology/>MIT MOOC</a> I became curious if given a meal&rsquo;s macronutrients (carbs, protein, fat) and some basic individual characteristics (age, BMI), these could serve as features in a regressor machine learning model to predict the curve parameters of the postprandial glucose curve (how my blood sugar levels change after eating). I came across a paper on <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Personalized Nutrition by Prediction of Glycemic Responses</a> which did exactly that. Unfortunately, neither the data nor the code were publicly available. And - I wanted to predict my <em>own</em> glycemic response curve. So I decided to build my own model. In the process I wrote this <a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf>working paper</a>.
<a href=https://static.philippdubach.com/pdf/Modeling_Postprandial_Glycemic_Response_in_Non_Diabetic_Adults_Using_XGBRegressor.pdf><picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/working_paper_overview.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/working_paper_overview.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/working_paper_overview.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/working_paper_overview.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/working_paper_overview.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/working_paper_overview.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/working_paper_overview.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/working_paper_overview.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/working_paper_overview.jpg" alt="Overview of Working Paper Pages" loading=lazy style=width:100%;height:auto;display:block>
</picture></a>The paper represents an exercise in applying machine learning techniques to medical applications. The methodologies employed were largely inspired by <a href="https://www.cell.com/cell/fulltext/S0092-8674(15)01481-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014816%3Fshowall%3Dtrue">Zeevi et al.</a>&rsquo;s approach. I quickly realized that training a model on my own data <em>only</em> was not very promising if not impossible. To tackle this, I used the publicly available <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a> containing continuous glucose monitoring data from 57 adults, which I narrowed down to 112 standardized meals from 19 non-diabetic subjects with their respective glucose curve after the meal (full methodology in the paper).
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-workflow-graph.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-workflow-graph.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-workflow-graph.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-workflow-graph.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-workflow-graph.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-workflow-graph.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-workflow-graph.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-workflow-graph.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-workflow-graph.jpg" alt="Overview of the CGM pipeline workflow" loading=lazy style=width:100%;height:auto;display:block>
</picture>Rather than trying to predict the entire glucose curve, I simplified the problem by fitting each postprandial response to a normalized Gaussian function. This gave me three key parameters to predict: amplitude (how high glucose rises), time-to-peak (when it peaks), and curve width (how long the response lasts).
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/cgm-fitted-curve-large1.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/cgm-fitted-curve-large1.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/cgm-fitted-curve-large1.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/cgm-fitted-curve-large1.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/cgm-fitted-curve-large1.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/cgm-fitted-curve-large1.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/cgm-fitted-curve-large1.jpg" alt="Overview of single fitted curve of cgm measurements" loading=lazy style=width:100%;height:auto;display:block>
</picture>The Gaussian approximation worked surprisingly well for characterizing most glucose responses. While some curves fit better than others, the majority of postprandial responses were well-captured, though there&rsquo;s clear variation between individuals and meals. Some responses were high amplitude, narrow width, while others are more gradual and prolonged.
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/example-fitted-cgm-measurements.jpg 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/example-fitted-cgm-measurements.jpg 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/example-fitted-cgm-measurements.jpg 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/example-fitted-cgm-measurements.jpg 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/example-fitted-cgm-measurements.jpg 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/example-fitted-cgm-measurements.jpg 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/example-fitted-cgm-measurements.jpg" alt="Overview of selected fitted curves" loading=lazy style=width:100%;height:auto;display:block>
</picture>I then trained an XGBoost regressor with 27 engineered features including meal composition, participant characteristics, and interaction terms. XGBoost was chosen for its ability to handle mixed data types, built-in feature importance, and strong performance on tabular data. The pipeline included hyperparameter tuning with 5-fold cross-validation to optimize learning rate, tree depth, and regularization parameters. Rather than relying solely on basic meal macronutrients, I engineered features across multiple categories and implemented CGM statistical features calculated over different time windows (24-hour and 4-hour periods), including time-in-range and glucose variability metrics. Architecture wise, I trained three separate XGBoost regressors - one for each Gaussian parameter.</p><p>While the model achieved moderate success predicting amplitude (R² = 0.46), it completely failed at predicting timing - time-to-peak prediction was essentially random (R² = -0.76), and curve width prediction was barely better (R² = 0.10). Even the amplitude prediction, while statistically significant, falls well short of an R² > 0.7. Studies that have achieved better predictive performance typically used much larger datasets (>1000 participants). For my original goal of predicting my own glycemic responses, this suggests that either individual-specific models trained on extensive personal data, or much more sophisticated approaches incorporating larger training datasets, would be necessary.</p><p>The complete code, Jupyter notebooks, processed datasets, and supplementary results are available in my <a href=https://github.com/philippdubach/glucose-response-analysis>GitHub repository</a>.<br>_ _</p><p><em>(10/06/2025) Update: Today I came across Marcel Salathé&rsquo;s <a href="https://www.linkedin.com/posts/salathe_myfoodrepo-digitalhealth-precisionnutrition-activity-7337806988082393088-2Lsu?utm_source=share&amp;utm_medium=member_ios&amp;rcm=ACoAADeInT4BJMhtg5DSjxX1jVtIAs5w_KxZm-g">LinkedIn post</a> on a publication out of EPFL: <a href=https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2025.1539118/full>Personalized glucose prediction using in situ data only</a>.</em></p><blockquote><p><em>With data from over 1,000 participants of the Food & You digital cohort, we show that a machine learning model using only food data from myFoodRepo and a glucose monitor can closely track real blood sugar responses to any meal (correlation of 0.71).</em></p></blockquote><p><em>As expected Singh et. al. achieve a substantially better predictive performance (R = 0.71 vs R² = 0.46). Besides probably higher methodological rigor and scientific quality, the most critical difference is sample size - their 1'000+ participants versus my 19 participants (from the <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005143">Hall dataset</a>) represents a fundamental difference in statistical power and generalizability. They addressed one of the shortcomings I faced by leveraging a large digital nutritional cohort from the <a href=https://pubmed.ncbi.nlm.nih.gov/38033170/>&ldquo;Food & You&rdquo; study</a> (including high-resolution data of nutritional intake of more than 46 million kcal collected from 315'126 dishes over 23'335 participant days, 1'470'030 blood glucose measurements, 49'110 survey responses, and 1'024 samples for gut microbiota analysis).</em></p><p><em>Apart from that I am excited to - at a first glance - observe the following similarities:
(1) Both aim to predict postprandial glycemic responses using machine learning, with a focus on personalized nutrition applications.
(2) Both employ XGBoost regression as their primary predictive algorithm and use similar performance metrics (R², RMSE, MAE, Pearson correlation).
(3) Both extract comprehensive feature sets including meal composition (macronutrients), temporal features, and individual characteristics.
(4) Both use mathematical approaches to characterize glucose responses - I used Gaussian curve fitting, while Singh et. al. use incremental area under the curve (iAUC).
(5) Both employ cross-validation techniques for model evaluation and hyperparameter tuning.
(6) SHAP Analysis: Both use SHAP for model interpretability and feature importance analysis.</em><a id=update></p></div></article></main></div></body></html>