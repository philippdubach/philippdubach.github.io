<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://newsletter-api.philippd.workers.dev https://gc.zgo.at https://pdub.click; frame-ancestors 'self'; base-uri 'self';"><link rel=preconnect href=https://gc.zgo.at crossorigin><link rel=preconnect href=https://static.philippdubach.com crossorigin><link rel=preconnect href=https://pdub.click crossorigin><link rel=preconnect href=https://newsletter-api.philippd.workers.dev crossorigin><link rel=dns-prefetch href=https://gc.zgo.at><link rel=dns-prefetch href=https://static.philippdubach.com><link rel=dns-prefetch href=https://pdub.click><link rel=dns-prefetch href=https://newsletter-api.philippd.workers.dev><meta name=robots content="index, follow"><title>Book Review: Why Machines Learn - philippdubach.com</title><meta name=description content="A review of Ananthaswamy's Why Machines Learn: A clear tour of the math behind modern machine learning, with real derivations and geometry."><meta name=keywords content="machine learning,book review,mathematics,neural networks,AI"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/2025/12/27/book-review-why-machines-learn/><style></style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="Book Review: Why Machines Learn"><meta property="og:description" content="A review of Ananthaswamy's Why Machines Learn: A clear tour of the math behind modern machine learning, with real derivations and geometry."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2025/12/27/book-review-why-machines-learn/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-aibookreview.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-aibookreview.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-aibookreview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="article:published_time" content="2025-12-27T00:00:00Z"><meta property="article:modified_time" content="2025-12-27T00:00:00Z"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Book Review: Why Machines Learn"><meta name=twitter:description content="A review of Ananthaswamy's Why Machines Learn: A clear tour of the math behind modern machine learning, with real derivations and geometry."><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-aibookreview.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-aibookreview.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"http:\/\/localhost:1313\/posts/"},{"@type":"ListItem","position":3,"name":"Book Review: Why Machines Learn","item":"http:\/\/localhost:1313\/2025\/12\/27\/book-review-why-machines-learn\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Book Review: Why Machines Learn","name":"Book Review: Why Machines Learn","description":"A review of Ananthaswamy\u0027s Why Machines Learn: A clear tour of the math behind modern machine learning, with real derivations and geometry.","keywords":["machine learning","book review","mathematics","neural networks","AI"],"articleBody":"\" We cannot leave decisions about how AI will be built and deployed solely to its practitioners. If we are to effectively regulate this technology, another layer of society, educators, politicians, policymakers [\\u0026hellip;], must come to grips with the basics of the mathematics of machine learning.\\nI read a book that is sort of related to my recent writing on AI: Why Machines Learn: The Elegant Math Behind Modern AI by Anil Ananthaswamy.\\nI admire the attempt to actually explain the math, with a ton of equations, instead of doing the usual human drama story about geniuses and labs. I also admit I did not absorb all of it. That is not a complaint. It is a good sign that the author did not flatten the material into a few metaphors and call it a day.\\nIf you have read my posts on why AI might commoditize rather than stay a winner-takes-all business, for example Is AI Really Eating the World?, this book is a useful reminder that the story still starts with linear algebra. Ananthaswamy begins at the beginning: vectors, dot products, projections. The move here is to treat these as geometry, not just arithmetic. A dot product is a way to measure alignment, but it is also a way to map one space onto another. Once you see that, a neural network layer reads less like mysticism and more like a pipeline of linear maps plus nonlinearities.\\nThat framing is the book’s main strength. When it works, you get an intuition for how high-dimensional data gets rotated, scaled, and squeezed until classes separate or features become easier to represent. When it stops working, you still have the derivations, so you can slow down and check what you missed.\\nThe tour is broad. It moves from perceptrons to backpropagation, then through Principal Component Analysis and Support Vector Machines, and later into convolutional networks and generative models like GANs. There is history, but it is there to support the technical arc, not to replace it. The “graded ascent” idea mostly holds. Early chapters give you enough scaffolding to follow later ones. If you have not looked at derivatives or matrix calculus in a while, you will feel it, but you can still keep pace if you accept that this is a book you sometimes read with a pencil.\\nTwo things I liked in particular: (1) It does not pretend there is a single “deep learning trick” that explains everything. The methods are varied and the trade-offs are real. (2) It gives you enough math to see why some ideas scale and others do not, without turning into a textbook.\\n\"","wordCount":438,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-aibookreview.jpg","datePublished":"2025-12-27T00:00:00Z","dateModified":"2025-12-27T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/2025\/12\/27\/book-review-why-machines-learn\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><div class=site-title><a href=http://localhost:1313/>philippdubach</a></div><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/posts/>Archive</a></li><li><a href=/about/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title>Book Review: Why Machines Learn</h1><div class=post-meta><time datetime=2025-12-27T00:00:00Z>December 27, 2025
</time>• 500 words
• 3 min read
• <a href=# id=share-link title="Copy short link" aria-label="Copy short link" style=text-decoration:none>∞</a>
<span id=share-status></span></div></header><div class=post-content><blockquote><p>We cannot leave decisions about how AI will be built and deployed solely to its practitioners. If we are to effectively regulate this technology, another layer of society, educators, politicians, policymakers [&mldr;], must come to grips with the basics of the mathematics of machine learning.</p></blockquote><p>I read a book that is sort of related to my recent writing on AI: <em>Why Machines Learn: The Elegant Math Behind Modern AI</em> by <a href=https://www.anilananthaswamy.com/>Anil Ananthaswamy</a>.</p><p>I admire the attempt to actually explain the math, with a ton of equations, instead of doing the <a href=https://en.wikipedia.org/wiki/Nexus:_A_Brief_History_of_Information_Networks_from_the_Stone_Age_to_AI>usual human drama story</a> about geniuses and labs. I also admit I did not absorb all of it. That is not a complaint. It is a good sign that the author did not flatten the material into a few metaphors and call it a day.</p><p>If you have read my posts on why AI might commoditize rather than stay a winner-takes-all business, for example <a href=https://philippdubach.com/2025/11/23/is-ai-really-eating-the-world-1/2/>Is AI Really Eating the World?</a>, this book is a useful reminder that the story still starts with linear algebra. Ananthaswamy begins at the beginning: vectors, dot products, projections. The move here is to treat these as geometry, not just arithmetic. A dot product is a way to measure alignment, but it is also a way to map one space onto another. Once you see that, a neural network layer reads less like mysticism and more like a pipeline of linear maps plus nonlinearities.</p><p>That framing is the book’s main strength. When it works, you get an intuition for how high-dimensional data gets rotated, scaled, and squeezed until classes separate or features become easier to represent. When it stops working, you still have the derivations, so you can slow down and check what you missed.</p><p>The tour is broad. It moves from perceptrons to backpropagation, then through Principal Component Analysis and Support Vector Machines, and later into convolutional networks and generative models like GANs. There is history, but it is there to support the technical arc, not to replace it. The “graded ascent” idea mostly holds. Early chapters give you enough scaffolding to follow later ones. If you have not looked at derivatives or matrix calculus in a while, you will feel it, but you can still keep pace if you accept that this is a book you sometimes read with a pencil.</p><p>Two things I liked in particular: (1) It does not pretend there is a single “deep learning trick” that explains everything. The methods are varied and the trade-offs are real. (2) It gives you enough math to see why some ideas scale and others do not, without turning into a textbook.</p></div></article><footer class=feedback-footer><p>Have feedback, comments, or ideas? <a href=mailto:info@philippdubach.com>I'd love to hear from you</a>.</p><p class=latest-post>Latest: <a href=/2025/12/27/book-review-why-machines-learn/>Book Review: Why Machines Learn</a></p><p class=most-read id=top-post-week style=min-height:1.5em></p></footer><script>(function(){var e,n,t=document.getElementById("top-post-week");if(t&&fetch("https://weekly-top-goatcounter-api.philippd.workers.dev").then(function(e){return e.ok?e.json():Promise.reject()}).then(function(e){if(e.hits&&e.hits.length>0){var n=e.hits[0];t.innerHTML='Most read: <a href="'+n.path+'">'+n.title.replace(" - philippdubach.com","")+"</a>"}else t.remove()}).catch(function(){t.remove()}),n=document.getElementById("share-link"),e=document.getElementById("share-status"),!n)return;n.addEventListener("click",function(t){t.preventDefault(),e.textContent="...";var s,n=window.location.href;navigator.clipboard&&navigator.clipboard.write&&typeof ClipboardItem!="undefined"?(s=new ClipboardItem({"text/plain":fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(e){var t=e.shorturl||"";return new Blob([t],{type:"text/plain"})}).catch(function(){return new Blob([""],{type:"text/plain"})})}),navigator.clipboard.write([s]).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})):fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(t){var n=t.shorturl;n&&navigator.clipboard&&navigator.clipboard.writeText?navigator.clipboard.writeText(n).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent=n,setTimeout(function(){e.textContent=""},4e3)}):n?(e.textContent=n,setTimeout(function(){e.textContent=""},4e3)):(e.textContent="error",setTimeout(function(){e.textContent=""},2e3))}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})})})()</script></main></div></body></html>