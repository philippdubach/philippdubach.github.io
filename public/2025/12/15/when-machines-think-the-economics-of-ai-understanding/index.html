<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://gc.zgo.at; frame-ancestors 'self'; base-uri 'self';"><link rel=preconnect href=https://gc.zgo.at crossorigin><link rel=preconnect href=https://static.philippdubach.com crossorigin><link rel=dns-prefetch href=https://gc.zgo.at><link rel=dns-prefetch href=https://static.philippdubach.com><meta name=robots content="index, follow"><title>When Machines Think: The Economics of AI Understanding - philippdubach.com</title><meta name=description content="Examining whether AI models actually think or just pattern-match, and what this means for economic value creation. Based on recent neuroscience research and the commoditization of AI capabilities, we explore whether understanding creates competitive moats or flows to applications and distribution."><meta name=keywords content="artificial intelligence,AI thinking,machine learning economics,neural networks,AI commoditization,cognitive economics,AI model performance,pattern matching,AI understanding,neuroscience AI,AI investment,large language models"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=https://philippdubach.com/2025/12/15/when-machines-think-the-economics-of-ai-understanding/><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#ffff}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#ffff;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;padding-bottom:3rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem;line-height:1.3}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600;line-height:1.3}.post-title a:hover{color:#007acc}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.post-meta a{color:#007acc;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content p:last-child{margin-bottom:.5rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}@supports(text-wrap:balance){.archive-title{text-wrap:balance}}.single .post-title{font-size:1.5rem;margin-bottom:1rem;line-height:1.3}.pagination{margin-top:2rem;margin-bottom:1rem;text-align:center;padding-top:2rem;padding-bottom:1rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}.img-lightbox{cursor:pointer;transition:opacity .2s}.img-lightbox:hover{opacity:.9}.lightbox-overlay{display:none;position:fixed;top:0;left:0;width:100%;height:100%;background:#f8f9fa;z-index:9999;cursor:pointer;align-items:center;justify-content:center;padding:2rem;box-sizing:border-box}.lightbox-overlay:target{display:flex}.lightbox-overlay img{max-width:95%;max-height:95%;object-fit:contain;background:#f8f9fa}.feedback-footer{margin-top:.75rem;padding-top:.75rem;border-top:1px solid #e9ecef;text-align:center;color:#666;font-size:.9rem;margin-bottom:2rem}.feedback-footer p{margin:0;line-height:1.6}.feedback-footer a{color:#007acc;text-decoration:none}.feedback-footer a:hover{text-decoration:underline}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important;padding-bottom:.5rem !important}.pagination{margin-bottom:1.5rem !important;padding-bottom:1.5rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}.post-title,.post-title a,.single .post-title{line-height:1.2 !important}.post-content p:last-child{margin-bottom:.25rem !important}.feedback-footer{margin-top:.5rem !important;padding-top:.5rem !important;margin-bottom:1rem !important}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="When Machines Think: The Economics of AI Understanding"><meta property="og:description" content="Examining whether AI models actually think or just pattern-match, and what this means for economic value creation. Based on recent neuroscience research and the commoditization of AI capabilities, we explore whether understanding creates competitive moats or flows to applications and distribution."><meta property="og:type" content="article"><meta property="og:url" content="https://philippdubach.com/2025/12/15/when-machines-think-the-economics-of-ai-understanding/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="https://philippdubach.com/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="article:published_time" content="2025-12-15T00:00:00Z"><meta property="article:modified_time" content="2025-12-15T00:00:00Z"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="When Machines Think: The Economics of AI Understanding"><meta name=twitter:description content="Examining whether AI models actually think or just pattern-match, and what this means for economic value creation. Based on recent neuroscience research and the commoditization of AI capabilities, we explore whether understanding creates competitive moats or flows to applications and distribution."><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-ai-thinking.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/philippdubach.com\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"https:\/\/philippdubach.com\/posts/"},{"@type":"ListItem","position":3,"name":"When Machines Think: The Economics of AI Understanding","item":"https:\/\/philippdubach.com\/2025\/12\/15\/when-machines-think-the-economics-of-ai-understanding\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"When Machines Think: The Economics of AI Understanding","name":"When Machines Think: The Economics of AI Understanding","description":"Examining whether AI models actually think or just pattern-match, and what this means for economic value creation. Based on recent neuroscience research and the commoditization of AI capabilities, we explore whether understanding creates competitive moats or flows to applications and distribution.","keywords":["artificial intelligence","AI thinking","machine learning economics","neural networks","AI commoditization","cognitive economics","AI model performance","pattern matching","AI understanding","neuroscience AI","AI investment","large language models"],"articleBody":"\"In November 2025, The New Yorker published \\u0026ldquo;The Case That A.I. Is Thinking\\u0026rdquo;, a piece that captured the strange moment we\\u0026rsquo;re in. Dario Amodei predicts AI smarter than Nobel Prize winners by 2027. Sam Altman writes about digital superintelligence. Meanwhile, most people interact with AI tools that feel like Clippy, Microsoft\\u0026rsquo;s old assistant that was more annoying than useful. The gap between the hype and daily experience creates a fog where it\\u0026rsquo;s tempting to conclude there\\u0026rsquo;s nothing to see here.\\nBut there\\u0026rsquo;s a more interesting question than whether AI is thinking. What does thinking mean for value creation? If compression equals understanding, as Eric Baum argued decades ago, and if today\\u0026rsquo;s models compress the internet into something that fits on your laptop, does that create economic moats or just better commodities? The neuroscience insights are real. The economic implications are less clear.\\nEric Baum\\u0026rsquo;s 2003 book \\u0026ldquo;What Is Thought?\\u0026rdquo; makes a simple argument: understanding is compression, and compression is understanding. When you compress data effectively, you\\u0026rsquo;re not just shrinking files. You\\u0026rsquo;re finding the underlying structure. A calculator program compresses millions of arithmetic examples more efficiently than a zip file because it understands the rules. Large language models trained on terabytes of text compress that into models one six-hundredth the size. DeepSeek, one of the best open-source models, can write novels, suggest medical diagnoses, and speak dozens of languages. The training data is massive. The model you download is tiny. That compression ratio keeps improving.\\nFrom an information theory perspective, this makes sense. Better compression means better understanding of the underlying patterns. But information theory doesn\\u0026rsquo;t tell us about economic value. If understanding is just better compression, and compression keeps improving, what happens to the companies building these models? The cost of training frontier models has collapsed. DeepSeek proved that anyone with $500 million can build a competitive model. That\\u0026rsquo;s still a high barrier, but it\\u0026rsquo;s not a moat. When OpenAI launched ChatGPT in November 2022, it had a massive quality advantage. Today, dozens of models cluster around similar performance. The compression is getting better. The competitive advantage is getting smaller.\\nNeuroscientists are using AI models to study how brains work. Doris Tsao at UC Berkeley, who decoded how macaque monkeys perceive faces, says the advances in machine learning have taught us more about intelligence than neuroscience discovered in the past hundred years. Jonathan Cohen at Princeton argues that large language models mirror the neocortex, the part of the brain responsible for higher-order thinking. Kenneth Norman at Princeton calls working AI systems that instantiate theories of human intelligence the dream of cognitive neuroscience.\\nThis convergence between AI and neuroscience is real. But what does it mean for business? If AI models work like brains, does that create defensible advantages? The evidence suggests the opposite. OpenAI\\u0026rsquo;s API pricing has dropped by 97% since GPT-3\\u0026rsquo;s launch. Every year brings an order of magnitude decline in the price of a given output. The models are getting more brain-like. The prices are collapsing toward marginal cost. That\\u0026rsquo;s what happens when capabilities commoditize.\\nThe commoditization is visible in the data. GPT-4 launched in March 2023 with a substantial lead. Within six months, Claude 2 was comparable. Within a year, multiple models clustered around similar capability. The diffusion is fast. When you plot benchmark scores on standard evaluations like MMLU and HumanEval, leaders change weekly. The gaps are small. Consumer awareness doesn\\u0026rsquo;t track model quality. ChatGPT dominates with over 700 million weekly active users not because it has the best model anymore, but because it got there first and built brand.\\nThis pattern suggests that brain-like processing, even if real, doesn\\u0026rsquo;t create lasting competitive advantages. The models are getting smarter. They\\u0026rsquo;re also getting cheaper and more interchangeable. If understanding is compression, and compression keeps improving, the value flows to whoever owns customer relationships and distribution, not to whoever has the best compression algorithm.\\nDouglas Hofstadter\\u0026rsquo;s framework helps explain why. He argues that cognition is recognition. Thinking is seeing one thing as another. You see a patch of color as a car. You see a chess position as similar to games you\\u0026rsquo;ve played before. You see a meeting as an emperor-has-no-clothes situation. For Hofstadter, that\\u0026rsquo;s intelligence in a nutshell. Large language models appear to have this seeing-as machine at their core. They represent words as coordinates in high-dimensional space. Words that appear together get nudged closer. This creates dense representations where analogy becomes geometry. Take the vector for Paris, subtract France, add Italy, and you get Rome.\\nBut here\\u0026rsquo;s the economic question: does this create moats or is it just better pattern matching? Recent research suggests LLMs may rely more on statistical correlations than true reasoning. If it\\u0026rsquo;s mostly pattern-matching, even very sophisticated pattern-matching, they still need massive datasets and we\\u0026rsquo;re back to conventional network effects. If they can actually reason over conceptual spaces, that\\u0026rsquo;s different. But the evidence so far suggests the pattern-matching view is closer to reality. Current LLMs still fail in characteristic ways on tasks requiring actual causal reasoning, spatial reasoning, or planning over extended horizons. They\\u0026rsquo;re getting better, but the improvement curve on these specific capabilities looks different from the improvement curve on language modeling.\\nThe efficiency gap is telling. GPT-4 was exposed to trillions of words in training. Children need only a few million to become fluent. Human babies have inductive biases that accelerate learning. They expect the world is made of objects. They expect other beings have beliefs and intentions. When a parent says banana, an infant connects that word to the entire yellow object, not just its tip or peel. Infants perform experiments. They\\u0026rsquo;re motivated by emotions. Their learning is efficient because it\\u0026rsquo;s embodied, adaptive, deliberate, and continuous.\\nAI\\u0026rsquo;s experience, in comparison, is impoverished. Large language models are trained on data that\\u0026rsquo;s already extraordinarily refined. Language is like experience pre-chewed. Other kinds of data are less dense with meaning. Vision models still struggle with common-sense reasoning about physics. When an LLM is given a virtual walk-through of a building and then asked questions about routes and shortcuts, it tends to fail or hallucinate nonexistent paths. The models are getting better at language. They\\u0026rsquo;re not getting proportionally better at understanding the physical world.\\nThis efficiency gap has economic implications. If human learning is orders of magnitude more efficient, what does that mean for AI\\u0026rsquo;s economic viability? The models require massive compute and data. The outputs are getting cheaper. The training costs are enormous. Microsoft, Google, Amazon, and Meta will invest roughly $400 billion in AI infrastructure in 2025, more than global telecommunications capex. Microsoft now spends over 30% of revenue on capex, double what Verizon spends. What has this produced? Models that are simultaneously more capable and less defensible.\\nThe investment reality is stark. The hyperscalers are spending historic amounts. The models are clustering around similar performance. The prices are collapsing. When GPT-5 came out in August 2025, it was a merely incremental improvement, and so profound a disappointment that it threatened to pop the AI investment bubble. The moment demands a middle kind of skepticism: one that takes today\\u0026rsquo;s AI models seriously without believing that there are no hard problems left.\\nThe neuroscience insights are real. The models do appear to work in brain-like ways. Compression does seem to create understanding. But the economic value flows elsewhere. If models are commodities or near-commodities, model providers have little market power. The value flows to the users of AI, not the providers. Engineering firms using AI for materials development capture value through better materials. Pharmaceutical companies using AI for drug discovery capture value through better drugs. Retailers using AI for inventory management capture value through better margins. The AI providers compete with each other to offer the capability at the lowest price.\\nThis is basic microeconomics. You capture value when you have market power, either through monopoly, through differentiation, or through control of a scarce input. If models are commodities, model providers have none of these. The counterargument is vertical integration. Maybe the hyperscalers that control cloud infrastructure plus model development plus customer relationships can capture value even if models themselves commoditize. This is more plausible, essentially the AWS playbook. Amazon didn\\u0026rsquo;t make money by having the best database. They made money by owning the infrastructure, the customer relationships, and the entire stack from hardware to application platform.\\nSo where does this leave us? The technology exists and the underlying capabilities are real. The neuroscience insights are genuine. But the current evidence points toward a world where value flows to applications and customer relationships, and where the $400 billion the hyperscalers are spending buys them competitive positioning rather than monopoly. The models are thinking, or something close to it. That doesn\\u0026rsquo;t mean the companies building them will capture the economic value. Understanding may be compression. Compression may be getting better. But in competitive markets, better compression becomes cheaper compression. The thinking is real. The moats are not.\\n\"","wordCount":1484,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-ai-thinking.jpg","datePublished":"2025-12-15T00:00:00Z","dateModified":"2025-12-15T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/philippdubach.com\/2025\/12\/15\/when-machines-think-the-economics-of-ai-understanding\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"https:\/\/philippdubach.com\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><div class=site-title><a href=https://philippdubach.com/>philippdubach</a></div><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/posts/>Archive</a></li><li><a href=/about/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title>When Machines Think: The Economics of AI Understanding</h1><div class=post-meta><time datetime=2025-12-15T00:00:00Z>December 15, 2025
</time>• 1500 words
• 7 min read
• <a href=https://www.newyorker.com/magazine/2025/11/10/the-case-that-ai-is-thinking target=_blank rel=noopener>via</a></div></header><div class=post-content><p>In November 2025, The New Yorker published <a href=https://www.newyorker.com/magazine/2025/11/10/the-case-that-ai-is-thinking>&ldquo;The Case That A.I. Is Thinking&rdquo;</a>, a piece that captured the strange moment we&rsquo;re in. Dario Amodei predicts AI smarter than Nobel Prize winners by 2027. Sam Altman writes about digital superintelligence. Meanwhile, most people interact with AI tools that feel like Clippy, Microsoft&rsquo;s old assistant that was more annoying than useful. The gap between the hype and daily experience creates a fog where it&rsquo;s tempting to conclude there&rsquo;s nothing to see here.</p><p>But there&rsquo;s a more interesting question than whether AI is thinking. What does thinking mean for value creation? If compression equals understanding, as Eric Baum argued decades ago, and if today&rsquo;s models compress the internet into something that fits on your laptop, does that create economic moats or just better commodities? The neuroscience insights are real. The economic implications are less clear.</p><p>Eric Baum&rsquo;s 2003 book &ldquo;What Is Thought?&rdquo; makes a simple argument: understanding is compression, and compression is understanding. When you compress data effectively, you&rsquo;re not just shrinking files. You&rsquo;re finding the underlying structure. A calculator program compresses millions of arithmetic examples more efficiently than a zip file because it understands the rules. Large language models trained on terabytes of text compress that into models one six-hundredth the size. DeepSeek, one of the best open-source models, can write novels, suggest medical diagnoses, and speak dozens of languages. The training data is massive. The model you download is tiny. That compression ratio keeps improving.</p><p>From an information theory perspective, this makes sense. Better compression means better understanding of the underlying patterns. But information theory doesn&rsquo;t tell us about economic value. If understanding is just better compression, and compression keeps improving, what happens to the companies building these models? The <a href=https://www.semianalysis.com/p/deepseek-debates>cost of training frontier models has collapsed</a>. DeepSeek proved that anyone with $500 million can build a competitive model. That&rsquo;s still a high barrier, but it&rsquo;s not a moat. When OpenAI launched ChatGPT in November 2022, it had a massive quality advantage. Today, dozens of models cluster around similar performance. The compression is getting better. The competitive advantage is getting smaller.</p><p>Neuroscientists are using AI models to study how brains work. Doris Tsao at UC Berkeley, who decoded how macaque monkeys perceive faces, says the advances in machine learning have taught us more about intelligence than neuroscience discovered in the past hundred years. Jonathan Cohen at Princeton argues that large language models mirror the neocortex, the part of the brain responsible for higher-order thinking. Kenneth Norman at Princeton calls working AI systems that instantiate theories of human intelligence the dream of cognitive neuroscience.</p><p>This convergence between AI and neuroscience is real. But what does it mean for business? If AI models work like brains, does that create defensible advantages? The evidence suggests the opposite. <a href=https://techcrunch.com/2025/08/08/openai-priced-gpt-5-so-low-it-may-spark-a-price-war/>OpenAI&rsquo;s API pricing has dropped by 97% since GPT-3&rsquo;s launch</a>. Every year brings an order of magnitude decline in the price of a given output. The models are getting more brain-like. The prices are collapsing toward marginal cost. That&rsquo;s what happens when capabilities commoditize.</p><p>The commoditization is visible in the data. <a href=https://openai.com/index/gpt-4-research/>GPT-4 launched in March 2023</a> with a substantial lead. Within six months, <a href=https://www.anthropic.com/news/claude-2>Claude 2 was comparable</a>. Within a year, multiple models clustered around similar capability. The diffusion is fast. When you plot benchmark scores on standard evaluations like MMLU and HumanEval, leaders change weekly. The gaps are small. Consumer awareness doesn&rsquo;t track model quality. ChatGPT dominates with <a href=https://openai.com/index/how-people-are-using-chatgpt/>over 700 million weekly active users</a> not because it has the best model anymore, but because it got there first and built brand.</p><p>This pattern suggests that brain-like processing, even if real, doesn&rsquo;t create lasting competitive advantages. The models are getting smarter. They&rsquo;re also getting cheaper and more interchangeable. If understanding is compression, and compression keeps improving, the value flows to whoever owns customer relationships and distribution, not to whoever has the best compression algorithm.</p><p>Douglas Hofstadter&rsquo;s framework helps explain why. He argues that cognition is recognition. Thinking is seeing one thing as another. You see a patch of color as a car. You see a chess position as similar to games you&rsquo;ve played before. You see a meeting as an emperor-has-no-clothes situation. For Hofstadter, that&rsquo;s intelligence in a nutshell. Large language models appear to have this seeing-as machine at their core. They represent words as coordinates in high-dimensional space. Words that appear together get nudged closer. This creates dense representations where analogy becomes geometry. Take the vector for Paris, subtract France, add Italy, and you get Rome.</p><p>But here&rsquo;s the economic question: does this create moats or is it just better pattern matching? <a href=https://arxiv.org/abs/2308.03762>Recent research suggests LLMs may rely more on statistical correlations than true reasoning</a>. If it&rsquo;s mostly pattern-matching, even very sophisticated pattern-matching, they still need massive datasets and we&rsquo;re back to conventional network effects. If they can actually reason over conceptual spaces, that&rsquo;s different. But the evidence so far suggests the pattern-matching view is closer to reality. Current LLMs still fail in characteristic ways on tasks requiring actual causal reasoning, spatial reasoning, or planning over extended horizons. They&rsquo;re getting better, but the improvement curve on these specific capabilities looks different from the improvement curve on language modeling.</p><a href=#lightbox-learning_efficiency1-png-0 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/learning_efficiency1.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/learning_efficiency1.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/learning_efficiency1.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/learning_efficiency1.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/learning_efficiency1.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/learning_efficiency1.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/learning_efficiency1.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/learning_efficiency1.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/learning_efficiency1.png" alt="Human vs AI Learning Efficiency: Data Requirements Comparison" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-learning_efficiency1-png-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/learning_efficiency1.png" alt="Human vs AI Learning Efficiency: Data Requirements Comparison"></a><p>The efficiency gap is telling. GPT-4 was exposed to trillions of words in training. Children need only a few million to become fluent. Human babies have inductive biases that accelerate learning. They expect the world is made of objects. They expect other beings have beliefs and intentions. When a parent says banana, an infant connects that word to the entire yellow object, not just its tip or peel. Infants perform experiments. They&rsquo;re motivated by emotions. Their learning is efficient because it&rsquo;s embodied, adaptive, deliberate, and continuous.</p><p>AI&rsquo;s experience, in comparison, is impoverished. Large language models are trained on data that&rsquo;s already extraordinarily refined. Language is like experience pre-chewed. Other kinds of data are less dense with meaning. Vision models still struggle with common-sense reasoning about physics. When an LLM is given a virtual walk-through of a building and then asked questions about routes and shortcuts, it tends to fail or hallucinate nonexistent paths. The models are getting better at language. They&rsquo;re not getting proportionally better at understanding the physical world.</p><p>This efficiency gap has economic implications. If human learning is orders of magnitude more efficient, what does that mean for AI&rsquo;s economic viability? The models require massive compute and data. The outputs are getting cheaper. The training costs are enormous. <a href=https://techblog.comsoc.org/2025/11/01/ai-spending-boom-accelerates-big-tech-to-invest-invest-an-aggregate-of-400-billion-in-2025-more-in-2026/>Microsoft, Google, Amazon, and Meta will invest roughly $400 billion in AI infrastructure in 2025</a>, more than global telecommunications capex. Microsoft now spends over 30% of revenue on capex, double what Verizon spends. What has this produced? Models that are simultaneously more capable and less defensible.</p><a href=#lightbox-investment_vs_capability1-png-1 style="display:block;width:80%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/investment_vs_capability1.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/investment_vs_capability1.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/investment_vs_capability1.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/investment_vs_capability1.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/investment_vs_capability1.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/investment_vs_capability1.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/investment_vs_capability1.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/investment_vs_capability1.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/investment_vs_capability1.png" alt="AI Investment vs Model Capability Gains Over Time" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-investment_vs_capability1-png-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/investment_vs_capability1.png" alt="AI Investment vs Model Capability Gains Over Time"></a><p>The investment reality is stark. The hyperscalers are spending historic amounts. The models are clustering around similar performance. The prices are collapsing. When GPT-5 came out in August 2025, it was a merely incremental improvement, and so profound a disappointment that it threatened to pop the AI investment bubble. The moment demands a middle kind of skepticism: one that takes today&rsquo;s AI models seriously without believing that there are no hard problems left.</p><p>The neuroscience insights are real. The models do appear to work in brain-like ways. Compression does seem to create understanding. But the economic value flows elsewhere. If models are commodities or near-commodities, model providers have little market power. The value flows to the users of AI, not the providers. Engineering firms using AI for materials development capture value through better materials. Pharmaceutical companies using AI for drug discovery capture value through better drugs. Retailers using AI for inventory management capture value through better margins. The AI providers compete with each other to offer the capability at the lowest price.</p><p>This is basic microeconomics. You capture value when you have market power, either through monopoly, through differentiation, or through control of a scarce input. If models are commodities, model providers have none of these. The counterargument is vertical integration. Maybe the hyperscalers that control cloud infrastructure plus model development plus customer relationships can capture value even if models themselves commoditize. This is more plausible, essentially the AWS playbook. Amazon didn&rsquo;t make money by having the best database. They made money by owning the infrastructure, the customer relationships, and the entire stack from hardware to application platform.</p><p>So where does this leave us? The technology exists and the underlying capabilities are real. The neuroscience insights are genuine. But the current evidence points toward a world where value flows to applications and customer relationships, and where the $400 billion the hyperscalers are spending buys them competitive positioning rather than monopoly. The models are thinking, or something close to it. That doesn&rsquo;t mean the companies building them will capture the economic value. Understanding may be compression. Compression may be getting better. But in competitive markets, better compression becomes cheaper compression. The thinking is real. The moats are not.</p></div></article><footer class=feedback-footer><p>Have feedback, comments, or ideas? <a href=mailto:info@philippdubach.com>I'd love to hear from you</a>.</p><p class=latest-post>Latest: <a href=/2025/12/15/book-review-why-machines-learn-by-anil-ananthaswamy/>Book Review: Why Machines Learn by Anil Ananthaswamy</a></p><p class=most-read id=top-post-week style=min-height:1.5em></p></footer><script src=/js/goatcounter-top.js></script></main></div><script>window.goatcounter=window.goatcounter||{},document.referrer&&document.referrer.includes("pdub.click")&&(window.goatcounter.no_onload=!1)</script><script data-goatcounter=https://philippdubach.goatcounter.com/count async src=https://gc.zgo.at/count.js></script></body></html>