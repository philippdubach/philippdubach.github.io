<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Content-Security-Policy content="default-src 'self'; script-src 'self' 'unsafe-inline' https://gc.zgo.at https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://philippdubach.goatcounter.com https://weekly-top-goatcounter-api.philippd.workers.dev https://gc.zgo.at https://pdub.click; frame-ancestors 'self'; base-uri 'self';"><link rel=preconnect href=https://gc.zgo.at crossorigin><link rel=preconnect href=https://static.philippdubach.com crossorigin><link rel=preconnect href=https://pdub.click crossorigin><link rel=dns-prefetch href=https://gc.zgo.at><link rel=dns-prefetch href=https://static.philippdubach.com><link rel=dns-prefetch href=https://pdub.click><meta name=robots content="index, follow"><title>Building a Serverless Hacker News Archive - philippdubach.com</title><meta name=description content="A deep dive into building a serverless Hacker News archiver using Cloudflare Workers, D1, Workers AI for topic classification, and Vectorize for semantic search. Architecture patterns for real-time data collection at scale."><meta name=keywords content="Cloudflare Workers,D1 database,Workers AI,Vectorize,serverless architecture,real-time archiving,Hacker News API,TypeScript,cron jobs,embeddings,semantic search,data engineering"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/standalone/hn-archiver/><style>*{margin:0;padding:0;box-sizing:border-box}.visually-hidden{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);white-space:nowrap;border:0}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#ffff}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#ffff;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;padding-bottom:3rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem;line-height:1.3}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600;line-height:1.3}.post-title a:hover{color:#007acc}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.post-meta a{color:#007acc;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content p:last-child{margin-bottom:.5rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}@supports(text-wrap:balance){.archive-title{text-wrap:balance}}.single .post-title{font-size:1.5rem;margin-bottom:1rem;line-height:1.3}.pagination{margin-top:2rem;margin-bottom:1rem;text-align:center;padding-top:2rem;padding-bottom:1rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}.img-lightbox{cursor:pointer;transition:opacity .2s}.img-lightbox:hover{opacity:.9}.lightbox-overlay{display:none;position:fixed;top:0;left:0;width:100%;height:100%;background:#f8f9fa;z-index:9999;cursor:pointer;align-items:center;justify-content:center;padding:2rem;box-sizing:border-box}.lightbox-overlay:target{display:flex}.lightbox-overlay img{max-width:95%;max-height:95%;object-fit:contain;background:#f8f9fa}.feedback-footer{margin-top:.75rem;padding-top:.75rem;border-top:1px solid #e9ecef;text-align:center;color:#666;font-size:.9rem;margin-bottom:2rem}.feedback-footer p{margin:0;line-height:1.6}.feedback-footer a{color:#007acc;text-decoration:none}.feedback-footer a:hover{text-decoration:underline}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important;padding-bottom:.5rem !important}.pagination{margin-bottom:1.5rem !important;padding-bottom:1.5rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}.post-title,.post-title a,.single .post-title{line-height:1.2 !important}.post-content p:last-child{margin-bottom:.25rem !important}.feedback-footer{margin-top:.5rem !important;padding-top:.5rem !important;margin-bottom:1rem !important}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts"><meta property="og:description" content="A deep dive into building a serverless Hacker News archiver using Cloudflare Workers, D1, Workers AI for topic classification, and Vectorize for semantic search. Architecture patterns for real-time data collection at scale."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/standalone/hn-archiver/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-hn-technical.jpg"><meta property="og:image:secure_url" content="https://static.philippdubach.com/ograph/ograph-hn-technical.jpg"><meta property="og:image:url" content="https://static.philippdubach.com/ograph/ograph-hn-technical.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="article:published_time" content="0001-01-01T00:00:00Z"><meta property="article:modified_time" content="0001-01-01T00:00:00Z"><meta property="article:section" content="standalone"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts"><meta name=twitter:description content="A deep dive into building a serverless Hacker News archiver using Cloudflare Workers, D1, Workers AI for topic classification, and Vectorize for semantic search. Architecture patterns for real-time data collection at scale."><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-hn-technical.jpg"><meta name=twitter:image:src content="https://static.philippdubach.com/ograph/ograph-hn-technical.jpg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"http:\/\/localhost:1313\/"},{"@type":"ListItem","position":2,"name":"Standalone","item":"http:\/\/localhost:1313\/standalone/"},{"@type":"ListItem","position":3,"name":"Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts","item":"http:\/\/localhost:1313\/standalone\/hn-archiver\/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts","name":"Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts","description":"A deep dive into building a serverless Hacker News archiver using Cloudflare Workers, D1, Workers AI for topic classification, and Vectorize for semantic search. Architecture patterns for real-time data collection at scale.","keywords":["Cloudflare Workers","D1 database","Workers AI","Vectorize","serverless architecture","real-time archiving","Hacker News API","TypeScript","cron jobs","embeddings","semantic search","data engineering"],"articleBody":"\" This is the technical companion to The First Two Hours: What 100,000 HN Posts Reveal About Online Attention. For the research results, see The Attention Paradox.\\nI wanted to study how attention flows on Hacker News, but existing datasets only capture snapshots. To understand temporal patterns, score velocity, and content lifecycle, I needed continuous observation. So I built a real-time archiver.\\nThe system runs entirely on Cloudflare\\u0026rsquo;s edge platform: Workers for compute, D1 for storage, Workers AI for classification, and Vectorize for similarity search. After a week of operation, it had collected 98,586 items with 22,457 temporal snapshots, enough data to reveal some surprising patterns about how online attention works.\\nHere\\u0026rsquo;s how it works.\\nArchitecture Overview Three cron-triggered workers handle the data pipeline:\\nWorker Schedule Function Discovery Every 3 min Fetches new items from lastSeen+1 to current maxitem Updates Every 10 min Refreshes recently changed items via /v0/updates Backfill Every 2 hours Revisits stale high-value items, runs AI analysis, generates embeddings The HN API is straightforward. /v0/maxitem returns the highest item ID, /v0/updates returns recently changed items and profiles. Individual items come from /v0/item/{id}. Firebase-style, real-time capable, but I opted for polling to stay within rate limits.\\nDiscovery: Catching New Content The discovery worker runs every 3 minutes. It reads the last seen item ID from state, fetches the current max from HN, then iterates through the gap:\\nexport async function runDiscovery(env: WorkerEnv): Promise\\u0026lt;WorkerResult\\u0026gt; { const state = await getArchivingState(env.DB); const currentMaxId = await fetchMaxItemId(); const startId = state.maxItemIdSeen + 1; const endId = Math.min(currentMaxId, startId + BATCH_SIZE - 1); const items = await fetchItemsBatch(startId, endId); const result = await batchUpsertItems(env.DB, items, getCurrentTimestampMs()); await updateMaxItemId(env.DB, endId); return result; } Batch size is capped at 500 items per run. During peak hours, HN generates 50-100 new items per minute, so 3-minute intervals with 500-item batches keeps up comfortably.\\nThe batchUpsertItems function is where things get interesting. It\\u0026rsquo;s designed for idempotency:\\nFetch existing items by ID Compare each field to detect actual changes Only write rows that differ Create snapshots based on change magnitude This means re-running discovery on the same ID range is safe. The function returns { processed, changed, snapshots } counts for monitoring.\\nSnapshots: Capturing Score Evolution Not every update deserves a snapshot. Writing 100K snapshots per day would exhaust D1\\u0026rsquo;s row limits quickly. Instead, I use selective triggers:\\nfunction shouldCreateSnapshot( existing: HNItem | null, incoming: HNItem, reason: string ): boolean { if (reason === \\u0026#39;new_item\\u0026#39;) return true; if (reason === \\u0026#39;front_page\\u0026#39;) return true; if (existing \\u0026amp;\\u0026amp; incoming.score - existing.score \\u0026gt;= 20) { return true; // score_spike } // Sample every 4th update if (existing \\u0026amp;\\u0026amp; existing.update_count % 4 === 0) { return true; } return false; } The snapshot_reason enum captures why each snapshot was created: score_spike, front_page, sample, or new_item. This metadata proved essential for the research analysis, letting me filter for specific observation types.\\nSnapshot schema:\\nCREATE TABLE item_snapshots ( id INTEGER PRIMARY KEY AUTOINCREMENT, item_id INTEGER NOT NULL, score INTEGER, descendants INTEGER, snapshot_reason TEXT, created_at INTEGER NOT NULL, FOREIGN KEY (item_id) REFERENCES items(id) ); CREATE INDEX idx_snapshots_item_time ON item_snapshots(item_id, created_at); The compound index on (item_id, created_at) makes lifecycle queries fast: \\u0026ldquo;Give me all snapshots for item X ordered by time.\\u0026rdquo;\\nAI Classification Pipeline Every story gets three AI treatments:\\nTopic Classification uses @cf/meta/llama-3.2-1b-instruct with a structured prompt:\\nconst TOPIC_PROMPT = `Classify this Hacker News story into exactly one category. Categories: artificial-intelligence, programming, web-development, startups, science, security, crypto-blockchain, hardware, career, politics, business, gaming, other Title: ${title} URL: ${url} Respond with only the category name.`; const response = await env.AI.run(\\u0026#39;@cf/meta/llama-3.2-1b-instruct\\u0026#39;, { prompt: TOPIC_PROMPT, max_tokens: 20, temperature: 0.1 }); Low temperature (0.1) keeps responses consistent. The 13-category taxonomy emerged from initial clustering of HN content types.\\nSentiment Analysis uses @cf/huggingface/distilbert-sst-2-int8:\\nconst sentiment = await env.AI.run( \\u0026#39;@cf/huggingface/distilbert-sst-2-int8\\u0026#39;, { text: title } ); // Returns: [{ label: \\u0026#34;POSITIVE\\u0026#34;|\\u0026#34;NEGATIVE\\u0026#34;, score: 0-1 }] Embeddings for similarity search use @cf/baai/bge-base-en-v1.5:\\nconst embedding = await env.AI.run(\\u0026#39;@cf/baai/bge-base-en-v1.5\\u0026#39;, { text: `${title} ${url}` }); // Returns: { data: [[...768 floats]] } await env.VECTORIZE.insert([{ id: itemId.toString(), values: embedding.data[0], metadata: { topic: item.ai_topic, score: item.score } }]); The 768-dimensional BGE embeddings go into Cloudflare\\u0026rsquo;s Vectorize index for cosine similarity search. Finding related posts becomes a single API call:\\nconst similar = await env.VECTORIZE.query(embedding, { topK: 5 }); Budget Constraints Cloudflare\\u0026rsquo;s paid plan includes generous but finite quotas. The system is designed to stay well within them:\\n// src/types.ts export const BudgetLimits = { VECTORIZE_QUERIES_PER_DAY: 1500, VECTORIZE_MAX_STORED_VECTORS: 10000, EMBEDDING_BATCH_SIZE: 50, D1_READS_PER_DAY: 500_000_000 }; Usage tracking happens in the usage_counters table:\\nasync function checkUsageLimits(db: D1Database, key: string): Promise\\u0026lt;boolean\\u0026gt; { const today = new Date().toISOString().split(\\u0026#39;T\\u0026#39;)[0]; const counter = await getUsageCounter(db, `${key}_${today}`); return counter \\u0026lt; BudgetLimits[key]; } async function incrementUsageCounter(db: D1Database, key: string, delta: number) { await db.prepare( `INSERT INTO usage_counters (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value = value + ?` ).bind(key, delta, delta).run(); } The /api/usage endpoint exposes current consumption. Warnings appear at 80% of limits.\\nSecurity Patterns Several patterns keep the system safe:\\nRate limiting uses an in-memory map with 100 requests/IP/minute limit:\\nconst rateLimitMap = new Map\\u0026lt;string, { count: number; resetAt: number }\\u0026gt;(); function checkRateLimit(ip: string): boolean { const now = Date.now(); const limit = rateLimitMap.get(ip); if (!limit || limit.resetAt \\u0026lt; now) { rateLimitMap.set(ip, { count: 1, resetAt: now + 60000 }); return true; } if (limit.count \\u0026gt;= 100) return false; limit.count++; return true; } Timing-safe auth comparison prevents timing attacks on the trigger secret:\\nimport { timingSafeEqual } from \\u0026#39;./utils\\u0026#39;; function validateAuth(header: string | null, secret: string): boolean { if (!header?.startsWith(\\u0026#39;Bearer \\u0026#39;)) return false; const token = header.slice(7); return timingSafeEqual(token, secret); } Fail-closed auth returns 503 if TRIGGER_SECRET isn\\u0026rsquo;t configured, never proceeds with missing credentials:\\nif (!env.TRIGGER_SECRET) { return new Response(\\u0026#39;Auth not configured\\u0026#39;, { status: 503 }); } Parameterized SQL everywhere. No string interpolation, ever:\\n// Good const items = await db.prepare( \\u0026#39;SELECT * FROM items WHERE id = ?\\u0026#39; ).bind(itemId).all(); // Never const items = await db.prepare( `SELECT * FROM items WHERE id = ${itemId}` // SQL injection risk ).all(); Local Development The full stack runs locally via Wrangler:\\n# Initialize local D1 npx wrangler d1 execute hn-archiver --local --file=schema.sql # Start dev server npm run dev # localhost:8787 # Trigger workers manually curl -H \\u0026#34;Authorization: Bearer $SECRET\\u0026#34; localhost:8787/trigger/discovery For testing, Vitest with Miniflare provides mocked D1/AI/Vectorize bindings:\\ndescribe(\\u0026#39;batchUpsertItems\\u0026#39;, () =\\u0026gt; { it(\\u0026#39;creates snapshots on score spikes\\u0026#39;, async () =\\u0026gt; { const db = await getMiniflareD1(); // Insert initial item await batchUpsertItems(db, [{ id: 1, score: 10, ... }], now); // Update with 25-point jump const result = await batchUpsertItems(db, [{ id: 1, score: 35, ... }], now + 1000); expect(result.snapshots).toBe(1); const snapshot = await db.prepare( \\u0026#39;SELECT * FROM item_snapshots WHERE item_id = 1\\u0026#39; ).first(); expect(snapshot.snapshot_reason).toBe(\\u0026#39;score_spike\\u0026#39;); }); }); What I Learned Building this system taught me several lessons:\\nIdempotency matters for data pipelines. Cron jobs fail, restart, and overlap. Every write operation needs to handle re-runs gracefully. The upsert pattern with change detection made debugging much simpler.\\nSelective snapshots beat exhaustive logging. I initially tried capturing every score change. D1\\u0026rsquo;s row limits forced a better approach. The trigger-based system captures the interesting moments while staying within budget.\\nEdge AI is production-ready. Workers AI handled 50 stories per backfill run without issues. Latency is acceptable (200-500ms per classification), and the models are good enough for research categorization. I wouldn\\u0026rsquo;t use them for customer-facing classification without human review, but for analytics they work well.\\nBudget awareness should be built in. Tracking usage counters from day one prevented nasty surprises. The 10K vector limit in Vectorize shaped the retention policy: I only embed high-scoring stories, not every comment.\\nThe full source is at github.com/philippdubach/hn-archiver. Analysis code is at github.com/philippdubach/hn-analyzer. PRs welcome.\\nThe architecture patterns here, serverless cron workers, idempotent upserts, selective event capture, edge AI classification, transfer directly to enterprise use cases. I\\u0026rsquo;ve applied similar approaches to client analytics systems in banking, where real-time behavioral data feeds ML models for personalization and next-best-action recommendations. The technical constraints differ (compliance, latency requirements, integration complexity), but the core design principles remain: build for observability, design for failure, and let budget constraints shape architecture decisions early.\\n\"","wordCount":1347,"inLanguage":"en","image":"https:\/\/static.philippdubach.com\/ograph\/ograph-hn-technical.jpg","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/localhost:1313\/standalone\/hn-archiver\/"},"publisher":{"@type":"Organization","name":"philippdubach","logo":{"@type":"ImageObject","url":"http:\/\/localhost:1313\/icons/favicon.ico"}},"author":{"@type":"Person","name":"Philipp Dubach"}}</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><div class=site-title><a href=http://localhost:1313/>philippdubach</a></div><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/posts/>Archive</a></li><li><a href=/about/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><article class="post single"><header class=post-header><h1 class=post-title>Building a Real-Time HN Archive: Cloudflare Workers, AI, and 100K Posts</h1></header><div class=post-content><blockquote><p><em>This is the technical companion to <a href=/>The First Two Hours: What 100,000 HN Posts Reveal About Online Attention</a>. For the research results, see <a href=/standalone/hn-research/>The Attention Paradox</a>.</em></p></blockquote><p>I wanted to study how attention flows on Hacker News, but existing datasets only capture snapshots. To understand temporal patterns, score velocity, and content lifecycle, I needed continuous observation. So I built a real-time archiver.</p><p>The system runs entirely on Cloudflare&rsquo;s edge platform: Workers for compute, D1 for storage, Workers AI for classification, and Vectorize for similarity search. After a week of operation, it had collected 98,586 items with 22,457 temporal snapshots, enough data to reveal some surprising patterns about how online attention works.</p><p>Here&rsquo;s how it works.</p><h2 id=architecture-overview>Architecture Overview</h2><a href=#lightbox-hn_architecture-png-0 style="display:block;width:100%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/hn_architecture.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/hn_architecture.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/hn_architecture.png 640w" sizes=100%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/hn_architecture.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/hn_architecture.png 1024w" sizes=100%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn_architecture.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/hn_architecture.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/hn_architecture.png 2000w" sizes=100%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/hn_architecture.png" alt="System architecture: HN API to Workers to D1 to AI to Vectorize" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-hn_architecture-png-0 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/hn_architecture.png" alt="System architecture: HN API to Workers to D1 to AI to Vectorize"></a><p>Three cron-triggered workers handle the data pipeline:</p><table><thead><tr><th>Worker</th><th>Schedule</th><th>Function</th></tr></thead><tbody><tr><td><strong>Discovery</strong></td><td>Every 3 min</td><td>Fetches new items from <code>lastSeen+1</code> to current <code>maxitem</code></td></tr><tr><td><strong>Updates</strong></td><td>Every 10 min</td><td>Refreshes recently changed items via <code>/v0/updates</code></td></tr><tr><td><strong>Backfill</strong></td><td>Every 2 hours</td><td>Revisits stale high-value items, runs AI analysis, generates embeddings</td></tr></tbody></table><p>The HN API is straightforward. <code>/v0/maxitem</code> returns the highest item ID, <code>/v0/updates</code> returns recently changed items and profiles. Individual items come from <code>/v0/item/{id}</code>. Firebase-style, real-time capable, but I opted for polling to stay within rate limits.</p><a href=#lightbox-hn_cron_timeline-png-1 style="display:block;width:100%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/hn_cron_timeline.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/hn_cron_timeline.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/hn_cron_timeline.png 640w" sizes=100%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/hn_cron_timeline.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/hn_cron_timeline.png 1024w" sizes=100%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn_cron_timeline.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/hn_cron_timeline.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/hn_cron_timeline.png 2000w" sizes=100%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/hn_cron_timeline.png" alt="Cron execution timeline showing worker frequency over 2 hours" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-hn_cron_timeline-png-1 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/hn_cron_timeline.png" alt="Cron execution timeline showing worker frequency over 2 hours"></a><h2 id=discovery-catching-new-content>Discovery: Catching New Content</h2><p>The discovery worker runs every 3 minutes. It reads the last seen item ID from state, fetches the current max from HN, then iterates through the gap:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>runDiscovery</span>(<span style=color:#a6e22e>env</span>: <span style=color:#66d9ef>WorkerEnv</span>)<span style=color:#f92672>:</span> <span style=color:#a6e22e>Promise</span>&lt;<span style=color:#f92672>WorkerResult</span>&gt; {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>state</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>getArchivingState</span>(<span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>DB</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>currentMaxId</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>fetchMaxItemId</span>();
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>startId</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>state</span>.<span style=color:#a6e22e>maxItemIdSeen</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>endId</span> <span style=color:#f92672>=</span> Math.<span style=color:#a6e22e>min</span>(<span style=color:#a6e22e>currentMaxId</span>, <span style=color:#a6e22e>startId</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>BATCH_SIZE</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>items</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>fetchItemsBatch</span>(<span style=color:#a6e22e>startId</span>, <span style=color:#a6e22e>endId</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>result</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>batchUpsertItems</span>(<span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>DB</span>, <span style=color:#a6e22e>items</span>, <span style=color:#a6e22e>getCurrentTimestampMs</span>());
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>updateMaxItemId</span>(<span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>DB</span>, <span style=color:#a6e22e>endId</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>result</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Batch size is capped at 500 items per run. During peak hours, HN generates 50-100 new items per minute, so 3-minute intervals with 500-item batches keeps up comfortably.</p><p>The <code>batchUpsertItems</code> function is where things get interesting. It&rsquo;s designed for idempotency:</p><ol><li>Fetch existing items by ID</li><li>Compare each field to detect actual changes</li><li>Only write rows that differ</li><li>Create snapshots based on change magnitude</li></ol><p>This means re-running discovery on the same ID range is safe. The function returns <code>{ processed, changed, snapshots }</code> counts for monitoring.</p><h2 id=snapshots-capturing-score-evolution>Snapshots: Capturing Score Evolution</h2><p>Not every update deserves a snapshot. Writing 100K snapshots per day would exhaust D1&rsquo;s row limits quickly. Instead, I use selective triggers:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>function</span> <span style=color:#a6e22e>shouldCreateSnapshot</span>(
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>existing</span>: <span style=color:#66d9ef>HNItem</span> <span style=color:#f92672>|</span> <span style=color:#66d9ef>null</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>incoming</span>: <span style=color:#66d9ef>HNItem</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>reason</span>: <span style=color:#66d9ef>string</span>
</span></span><span style=display:flex><span>)<span style=color:#f92672>:</span> <span style=color:#66d9ef>boolean</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>reason</span> <span style=color:#f92672>===</span> <span style=color:#e6db74>&#39;new_item&#39;</span>) <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>reason</span> <span style=color:#f92672>===</span> <span style=color:#e6db74>&#39;front_page&#39;</span>) <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>existing</span> <span style=color:#f92672>&amp;&amp;</span> <span style=color:#a6e22e>incoming</span>.<span style=color:#a6e22e>score</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>existing</span>.<span style=color:#a6e22e>score</span> <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>20</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>; <span style=color:#75715e>// score_spike
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  }
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// Sample every 4th update
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>existing</span> <span style=color:#f92672>&amp;&amp;</span> <span style=color:#a6e22e>existing</span>.<span style=color:#a6e22e>update_count</span> <span style=color:#f92672>%</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>===</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>false</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The <code>snapshot_reason</code> enum captures why each snapshot was created: <code>score_spike</code>, <code>front_page</code>, <code>sample</code>, or <code>new_item</code>. This metadata proved essential for the research analysis, letting me filter for specific observation types.</p><p>Snapshot schema:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> item_snapshots (
</span></span><span style=display:flex><span>  id INTEGER <span style=color:#66d9ef>PRIMARY</span> <span style=color:#66d9ef>KEY</span> AUTOINCREMENT,
</span></span><span style=display:flex><span>  item_id INTEGER <span style=color:#66d9ef>NOT</span> <span style=color:#66d9ef>NULL</span>,
</span></span><span style=display:flex><span>  score INTEGER,
</span></span><span style=display:flex><span>  descendants INTEGER,
</span></span><span style=display:flex><span>  snapshot_reason TEXT,
</span></span><span style=display:flex><span>  created_at INTEGER <span style=color:#66d9ef>NOT</span> <span style=color:#66d9ef>NULL</span>,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>FOREIGN</span> <span style=color:#66d9ef>KEY</span> (item_id) <span style=color:#66d9ef>REFERENCES</span> items(id)
</span></span><span style=display:flex><span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>INDEX</span> idx_snapshots_item_time <span style=color:#66d9ef>ON</span> item_snapshots(item_id, created_at);
</span></span></code></pre></div><p>The compound index on <code>(item_id, created_at)</code> makes lifecycle queries fast: &ldquo;Give me all snapshots for item X ordered by time.&rdquo;</p><h2 id=ai-classification-pipeline>AI Classification Pipeline</h2><a href=#lightbox-hn_ai_pipeline-png-2 style="display:block;width:100%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/hn_ai_pipeline.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/hn_ai_pipeline.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/hn_ai_pipeline.png 640w" sizes=100%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/hn_ai_pipeline.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/hn_ai_pipeline.png 1024w" sizes=100%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn_ai_pipeline.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/hn_ai_pipeline.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/hn_ai_pipeline.png 2000w" sizes=100%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/hn_ai_pipeline.png" alt="AI pipeline: Raw story to Llama to DistilBERT to BGE to Vectorize" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-hn_ai_pipeline-png-2 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/hn_ai_pipeline.png" alt="AI pipeline: Raw story to Llama to DistilBERT to BGE to Vectorize"></a><p>Every story gets three AI treatments:</p><p><strong>Topic Classification</strong> uses <code>@cf/meta/llama-3.2-1b-instruct</code> with a structured prompt:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>TOPIC_PROMPT</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>`Classify this Hacker News story into exactly one category.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Categories: artificial-intelligence, programming, web-development, startups, 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>science, security, crypto-blockchain, hardware, career, politics, business, 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gaming, other
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Title: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>title</span><span style=color:#e6db74>}</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>URL: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>url</span><span style=color:#e6db74>}</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Respond with only the category name.`</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>response</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>AI</span>.<span style=color:#a6e22e>run</span>(<span style=color:#e6db74>&#39;@cf/meta/llama-3.2-1b-instruct&#39;</span>, {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>prompt</span>: <span style=color:#66d9ef>TOPIC_PROMPT</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>max_tokens</span>: <span style=color:#66d9ef>20</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>temperature</span>: <span style=color:#66d9ef>0.1</span>
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><p>Low temperature (0.1) keeps responses consistent. The 13-category taxonomy emerged from initial clustering of HN content types.</p><p><strong>Sentiment Analysis</strong> uses <code>@cf/huggingface/distilbert-sst-2-int8</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>sentiment</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>AI</span>.<span style=color:#a6e22e>run</span>(
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;@cf/huggingface/distilbert-sst-2-int8&#39;</span>,
</span></span><span style=display:flex><span>  { <span style=color:#a6e22e>text</span>: <span style=color:#66d9ef>title</span> }
</span></span><span style=display:flex><span>);
</span></span><span style=display:flex><span><span style=color:#75715e>// Returns: [{ label: &#34;POSITIVE&#34;|&#34;NEGATIVE&#34;, score: 0-1 }]
</span></span></span></code></pre></div><p><strong>Embeddings</strong> for similarity search use <code>@cf/baai/bge-base-en-v1.5</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>embedding</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>AI</span>.<span style=color:#a6e22e>run</span>(<span style=color:#e6db74>&#39;@cf/baai/bge-base-en-v1.5&#39;</span>, {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>text</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`</span><span style=color:#e6db74>${</span><span style=color:#a6e22e>title</span><span style=color:#e6db74>}</span><span style=color:#e6db74> </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>url</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span><span style=color:#75715e>// Returns: { data: [[...768 floats]] }
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>await</span> <span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>VECTORIZE</span>.<span style=color:#a6e22e>insert</span>([{
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>id</span>: <span style=color:#66d9ef>itemId.toString</span>(),
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>values</span>: <span style=color:#66d9ef>embedding.data</span>[<span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>metadata</span><span style=color:#f92672>:</span> { <span style=color:#a6e22e>topic</span>: <span style=color:#66d9ef>item.ai_topic</span>, <span style=color:#a6e22e>score</span>: <span style=color:#66d9ef>item.score</span> }
</span></span><span style=display:flex><span>}]);
</span></span></code></pre></div><p>The 768-dimensional BGE embeddings go into Cloudflare&rsquo;s Vectorize index for cosine similarity search. Finding related posts becomes a single API call:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>similar</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>VECTORIZE</span>.<span style=color:#a6e22e>query</span>(<span style=color:#a6e22e>embedding</span>, { <span style=color:#a6e22e>topK</span>: <span style=color:#66d9ef>5</span> });
</span></span></code></pre></div><h2 id=budget-constraints>Budget Constraints</h2><p>Cloudflare&rsquo;s paid plan includes generous but finite quotas. The system is designed to stay well within them:</p><a href=#lightbox-hn_budget_limits-png-3 style="display:block;width:90%;margin:0 auto;padding:1rem 0;text-decoration:none"><picture class=img-lightbox><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/hn_budget_limits.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/hn_budget_limits.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/hn_budget_limits.png 640w" sizes=90%><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/hn_budget_limits.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/hn_budget_limits.png 1024w" sizes=90%><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn_budget_limits.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/hn_budget_limits.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/hn_budget_limits.png 2000w" sizes=90%><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/hn_budget_limits.png" alt="Budget constraints: Vectorize queries, stored vectors, embeddings per run" loading=lazy style=width:100%;height:auto;display:block>
</picture></a><a href=#_ id=lightbox-hn_budget_limits-png-3 class=lightbox-overlay><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/hn_budget_limits.png" alt="Budget constraints: Vectorize queries, stored vectors, embeddings per run"></a><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#75715e>// src/types.ts
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>BudgetLimits</span> <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>VECTORIZE_QUERIES_PER_DAY</span>: <span style=color:#66d9ef>1500</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>VECTORIZE_MAX_STORED_VECTORS</span>: <span style=color:#66d9ef>10000</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>EMBEDDING_BATCH_SIZE</span>: <span style=color:#66d9ef>50</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>D1_READS_PER_DAY</span>: <span style=color:#66d9ef>500_000_000</span>
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>Usage tracking happens in the <code>usage_counters</code> table:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>checkUsageLimits</span>(<span style=color:#a6e22e>db</span>: <span style=color:#66d9ef>D1Database</span>, <span style=color:#a6e22e>key</span>: <span style=color:#66d9ef>string</span>)<span style=color:#f92672>:</span> <span style=color:#a6e22e>Promise</span>&lt;<span style=color:#f92672>boolean</span>&gt; {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>today</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Date().<span style=color:#a6e22e>toISOString</span>().<span style=color:#a6e22e>split</span>(<span style=color:#e6db74>&#39;T&#39;</span>)[<span style=color:#ae81ff>0</span>];
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>counter</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>getUsageCounter</span>(<span style=color:#a6e22e>db</span>, <span style=color:#e6db74>`</span><span style=color:#e6db74>${</span><span style=color:#a6e22e>key</span><span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>${</span><span style=color:#a6e22e>today</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>counter</span> <span style=color:#f92672>&lt;</span> <span style=color:#a6e22e>BudgetLimits</span>[<span style=color:#a6e22e>key</span>];
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>incrementUsageCounter</span>(<span style=color:#a6e22e>db</span>: <span style=color:#66d9ef>D1Database</span>, <span style=color:#a6e22e>key</span>: <span style=color:#66d9ef>string</span>, <span style=color:#a6e22e>delta</span>: <span style=color:#66d9ef>number</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>db</span>.<span style=color:#a6e22e>prepare</span>(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>`INSERT INTO usage_counters (key, value) VALUES (?, ?)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>     ON CONFLICT(key) DO UPDATE SET value = value + ?`</span>
</span></span><span style=display:flex><span>  ).<span style=color:#a6e22e>bind</span>(<span style=color:#a6e22e>key</span>, <span style=color:#a6e22e>delta</span>, <span style=color:#a6e22e>delta</span>).<span style=color:#a6e22e>run</span>();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The <code>/api/usage</code> endpoint exposes current consumption. Warnings appear at 80% of limits.</p><h2 id=security-patterns>Security Patterns</h2><p>Several patterns keep the system safe:</p><p><strong>Rate limiting</strong> uses an in-memory map with 100 requests/IP/minute limit:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>rateLimitMap</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Map</span>&lt;<span style=color:#f92672>string</span>, { <span style=color:#a6e22e>count</span><span style=color:#960050;background-color:#1e0010>:</span> <span style=color:#a6e22e>number</span><span style=color:#960050;background-color:#1e0010>;</span> <span style=color:#a6e22e>resetAt</span><span style=color:#960050;background-color:#1e0010>:</span> <span style=color:#a6e22e>number</span> }&gt;();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>function</span> <span style=color:#a6e22e>checkRateLimit</span>(<span style=color:#a6e22e>ip</span>: <span style=color:#66d9ef>string</span>)<span style=color:#f92672>:</span> <span style=color:#66d9ef>boolean</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>now</span> <span style=color:#f92672>=</span> Date.<span style=color:#a6e22e>now</span>();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>limit</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>rateLimitMap</span>.<span style=color:#66d9ef>get</span>(<span style=color:#a6e22e>ip</span>);
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#f92672>!</span><span style=color:#a6e22e>limit</span> <span style=color:#f92672>||</span> <span style=color:#a6e22e>limit</span>.<span style=color:#a6e22e>resetAt</span> <span style=color:#f92672>&lt;</span> <span style=color:#a6e22e>now</span>) {
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>rateLimitMap</span>.<span style=color:#66d9ef>set</span>(<span style=color:#a6e22e>ip</span>, { <span style=color:#a6e22e>count</span>: <span style=color:#66d9ef>1</span>, <span style=color:#a6e22e>resetAt</span>: <span style=color:#66d9ef>now</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>60000</span> });
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>limit</span>.<span style=color:#a6e22e>count</span> <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>100</span>) <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>false</span>;
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>limit</span>.<span style=color:#a6e22e>count</span><span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><strong>Timing-safe auth comparison</strong> prevents timing attacks on the trigger secret:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>timingSafeEqual</span> } <span style=color:#66d9ef>from</span> <span style=color:#e6db74>&#39;./utils&#39;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>function</span> <span style=color:#a6e22e>validateAuth</span>(<span style=color:#a6e22e>header</span>: <span style=color:#66d9ef>string</span> <span style=color:#f92672>|</span> <span style=color:#66d9ef>null</span>, <span style=color:#a6e22e>secret</span>: <span style=color:#66d9ef>string</span>)<span style=color:#f92672>:</span> <span style=color:#66d9ef>boolean</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (<span style=color:#f92672>!</span><span style=color:#a6e22e>header</span><span style=color:#f92672>?</span>.<span style=color:#a6e22e>startsWith</span>(<span style=color:#e6db74>&#39;Bearer &#39;</span>)) <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>false</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>token</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>header</span>.<span style=color:#a6e22e>slice</span>(<span style=color:#ae81ff>7</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>timingSafeEqual</span>(<span style=color:#a6e22e>token</span>, <span style=color:#a6e22e>secret</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><strong>Fail-closed auth</strong> returns 503 if <code>TRIGGER_SECRET</code> isn&rsquo;t configured, never proceeds with missing credentials:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#66d9ef>if</span> (<span style=color:#f92672>!</span><span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>TRIGGER_SECRET</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Response</span>(<span style=color:#e6db74>&#39;Auth not configured&#39;</span>, { <span style=color:#a6e22e>status</span>: <span style=color:#66d9ef>503</span> });
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><strong>Parameterized SQL everywhere</strong>. No string interpolation, ever:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#75715e>// Good
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>items</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>db</span>.<span style=color:#a6e22e>prepare</span>(
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;SELECT * FROM items WHERE id = ?&#39;</span>
</span></span><span style=display:flex><span>).<span style=color:#a6e22e>bind</span>(<span style=color:#a6e22e>itemId</span>).<span style=color:#a6e22e>all</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Never
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>items</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>db</span>.<span style=color:#a6e22e>prepare</span>(
</span></span><span style=display:flex><span>  <span style=color:#e6db74>`SELECT * FROM items WHERE id = </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>itemId</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span> <span style=color:#75715e>// SQL injection risk
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>).<span style=color:#a6e22e>all</span>();
</span></span></code></pre></div><h2 id=local-development>Local Development</h2><p>The full stack runs locally via Wrangler:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Initialize local D1</span>
</span></span><span style=display:flex><span>npx wrangler d1 execute hn-archiver --local --file<span style=color:#f92672>=</span>schema.sql
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Start dev server</span>
</span></span><span style=display:flex><span>npm run dev  <span style=color:#75715e># localhost:8787</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Trigger workers manually</span>
</span></span><span style=display:flex><span>curl -H <span style=color:#e6db74>&#34;Authorization: Bearer </span>$SECRET<span style=color:#e6db74>&#34;</span> localhost:8787/trigger/discovery
</span></span></code></pre></div><p>For testing, Vitest with Miniflare provides mocked D1/AI/Vectorize bindings:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span><span style=color:#a6e22e>describe</span>(<span style=color:#e6db74>&#39;batchUpsertItems&#39;</span>, () <span style=color:#f92672>=&gt;</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>it</span>(<span style=color:#e6db74>&#39;creates snapshots on score spikes&#39;</span>, <span style=color:#66d9ef>async</span> () <span style=color:#f92672>=&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>db</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>getMiniflareD1</span>();
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Insert initial item
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>batchUpsertItems</span>(<span style=color:#a6e22e>db</span>, [{ <span style=color:#a6e22e>id</span>: <span style=color:#66d9ef>1</span>, <span style=color:#a6e22e>score</span>: <span style=color:#66d9ef>10</span>, ... }], <span style=color:#a6e22e>now</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Update with 25-point jump
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>result</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>batchUpsertItems</span>(<span style=color:#a6e22e>db</span>, [{ <span style=color:#a6e22e>id</span>: <span style=color:#66d9ef>1</span>, <span style=color:#a6e22e>score</span>: <span style=color:#66d9ef>35</span>, ... }], <span style=color:#a6e22e>now</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>1000</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>expect</span>(<span style=color:#a6e22e>result</span>.<span style=color:#a6e22e>snapshots</span>).<span style=color:#a6e22e>toBe</span>(<span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>snapshot</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>db</span>.<span style=color:#a6e22e>prepare</span>(
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#39;SELECT * FROM item_snapshots WHERE item_id = 1&#39;</span>
</span></span><span style=display:flex><span>    ).<span style=color:#a6e22e>first</span>();
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>expect</span>(<span style=color:#a6e22e>snapshot</span>.<span style=color:#a6e22e>snapshot_reason</span>).<span style=color:#a6e22e>toBe</span>(<span style=color:#e6db74>&#39;score_spike&#39;</span>);
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><h2 id=what-i-learned>What I Learned</h2><p>Building this system taught me several lessons:</p><p><strong>Idempotency matters for data pipelines.</strong> Cron jobs fail, restart, and overlap. Every write operation needs to handle re-runs gracefully. The upsert pattern with change detection made debugging much simpler.</p><p><strong>Selective snapshots beat exhaustive logging.</strong> I initially tried capturing every score change. D1&rsquo;s row limits forced a better approach. The trigger-based system captures the interesting moments while staying within budget.</p><p><strong>Edge AI is production-ready.</strong> Workers AI handled 50 stories per backfill run without issues. Latency is acceptable (200-500ms per classification), and the models are good enough for research categorization. I wouldn&rsquo;t use them for customer-facing classification without human review, but for analytics they work well.</p><p><strong>Budget awareness should be built in.</strong> Tracking usage counters from day one prevented nasty surprises. The 10K vector limit in Vectorize shaped the retention policy: I only embed high-scoring stories, not every comment.</p><p>The full source is at <a href=https://github.com/philippdubach/hn-archiver>github.com/philippdubach/hn-archiver</a>. Analysis code is at <a href=https://github.com/philippdubach/hn-analyzer>github.com/philippdubach/hn-analyzer</a>. PRs welcome.</p><hr><p>The architecture patterns here, serverless cron workers, idempotent upserts, selective event capture, edge AI classification, transfer directly to enterprise use cases. I&rsquo;ve applied similar approaches to client analytics systems in banking, where real-time behavioral data feeds ML models for personalization and next-best-action recommendations. The technical constraints differ (compliance, latency requirements, integration complexity), but the core design principles remain: build for observability, design for failure, and let budget constraints shape architecture decisions early.</p></div></article><footer class=feedback-footer><p>Have feedback, comments, or ideas? <a href=mailto:info@philippdubach.com>I'd love to hear from you</a>.</p><p class=latest-post>Latest: <a href=/2025/12/12/how-ai-is-shaping-my-investment-portfolio-for-2026/>How AI is Shaping My Investment Portfolio for 2026</a></p><p class=most-read id=top-post-week style=min-height:1.5em></p></footer><script>(function(){var e,n,t=document.getElementById("top-post-week");if(t&&fetch("https://weekly-top-goatcounter-api.philippd.workers.dev").then(function(e){return e.ok?e.json():Promise.reject()}).then(function(e){if(e.hits&&e.hits.length>0){var n=e.hits[0];t.innerHTML='Most read: <a href="'+n.path+'">'+n.title.replace(" - philippdubach.com","")+"</a>"}else t.remove()}).catch(function(){t.remove()}),n=document.getElementById("share-link"),e=document.getElementById("share-status"),!n)return;n.addEventListener("click",function(t){t.preventDefault(),e.textContent="...";var s,n=window.location.href;navigator.clipboard&&navigator.clipboard.write&&typeof ClipboardItem!="undefined"?(s=new ClipboardItem({"text/plain":fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(e){var t=e.shorturl||"";return new Blob([t],{type:"text/plain"})}).catch(function(){return new Blob([""],{type:"text/plain"})})}),navigator.clipboard.write([s]).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})):fetch("https://pdub.click/yourls-api.php?signature=4807288869&action=shorturl&format=json&url="+encodeURIComponent(n)).then(function(e){return e.json()}).then(function(t){var n=t.shorturl;n&&navigator.clipboard&&navigator.clipboard.writeText?navigator.clipboard.writeText(n).then(function(){e.textContent="url copied",setTimeout(function(){e.textContent=""},2e3)}).catch(function(){e.textContent=n,setTimeout(function(){e.textContent=""},4e3)}):n?(e.textContent=n,setTimeout(function(){e.textContent=""},4e3)):(e.textContent="error",setTimeout(function(){e.textContent=""},2e3))}).catch(function(){e.textContent="error",setTimeout(function(){e.textContent=""},2e3)})})})()</script></main></div></body></html>