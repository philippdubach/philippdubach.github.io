<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Home - philippdubach.com</title><meta name=description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=keywords content="Finance,Economics,Technology,Data,Machine Learning"><meta name=author content="Philipp Dubach"><meta name=generator content="Hugo 0.149.0"><link rel=canonical href=http://localhost:1313/><link href=/index.xml rel=alternate type=application/rss+xml title=philippdubach><link href=/index.xml rel=feed type=application/rss+xml title=philippdubach><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:helvetica neue,Helvetica,Arial,segoe ui,sans-serif;padding-top:90px;line-height:1.6;color:#333;background-color:#f8f9fa}blockquote{margin:1em 0;padding-left:1em;border-left:2px solid #ccc;color:#666}blockquote p{margin:.5em 0}.container{display:flex;max-width:1200px;margin:0 auto;min-height:100vh}.sidebar{width:200px;background-color:#f8f9fa;padding:1.5rem;border-right:0 solid #e9ecef;position:sticky;top:0;height:100vh;overflow-y:auto}.site-title a{text-decoration:none;color:#333;font-size:1.5rem;font-weight:700}.site-description{color:#666;margin:.5rem 0 2rem;font-size:.9rem}.navigation ul{list-style:none;margin-bottom:2rem}.navigation li{margin-bottom:.5rem}.navigation a{text-decoration:none;color:#007acc;font-weight:500}.navigation a:hover{text-decoration:underline}.social-links a{display:inline-block;margin-right:1rem;color:#666;text-decoration:none;font-size:.9rem}.social-links a:hover{color:#007acc}.content{flex:1;padding:2rem;max-width:800px}.posts{max-width:90%}.post{margin-bottom:1rem;padding-bottom:1rem}.post:last-child{border-bottom:none}.post-title{margin-bottom:.5rem}.post-title a{text-decoration:none;color:#333;font-size:1.25rem;font-weight:600}.post-title a:hover{color:#007acc}.external-link{color:#007acc;font-weight:400;margin-left:.25rem}.post-meta{font-size:.85rem;color:#666;margin-bottom:0}.permalink{text-decoration:none;color:#999;font-weight:400}.permalink:hover{color:#007acc}.post-content{line-height:1.7}.post-content p{margin-bottom:1rem}.post-content a{color:#007acc;text-decoration:none}.post-content a:hover{text-decoration:underline}.project-tag{background-color:#e9ecef;color:#495057;padding:2px 6px;border-radius:3px;font-size:9px;font-weight:500;text-transform:uppercase;letter-spacing:.3px;margin-left:6px;display:inline-block;vertical-align:middle;border:1px solid #dee2e6}.archive{max-width:90%}.year h2{margin:2rem 0 1rem;color:#333;font-size:1.5rem}.archive-item{display:flex;margin-bottom:.75rem;align-items:baseline}.archive-meta{width:60px;flex-shrink:0;font-size:.85rem;color:#666}.archive-title{flex:1}.archive-title a{text-decoration:none;color:#333}.archive-title a:hover{color:#007acc}.archive-title .permalink{margin-left:.5rem}.single .post-title{font-size:1.75rem;margin-bottom:1rem}.pagination{margin-top:2rem;text-align:center;padding-top:2rem;border-top:1px solid #e9ecef}.pagination a{color:#007acc;text-decoration:none;font-weight:500}.pagination a:hover{text-decoration:underline}@media(prefers-color-scheme:dark){.pagination{border-top-color:#404040}.pagination a{color:#4da6ff}.pagination a:hover{color:#66b3ff}}@media(prefers-color-scheme:dark){.project-tag{background-color:#404040;color:#b0b0b0;border-color:#555}}@media screen and (max-width:768px){html{font-size:8px !important}body{font-size:1rem !important}.sidebar{width:100px !important;padding:.75rem !important}.container{max-width:600px !important;margin:0 20px !important}.content{max-width:400px !important;padding:1rem !important}.project-tag{padding:1px 3px !important;border-radius:1.5px !important;font-size:4.5px !important;letter-spacing:.15px !important;margin-left:3px !important}.archive-meta{width:30px !important}}@media(prefers-color-scheme:dark){body{background-color:#2a2a2a;color:#e0e0e0}.sidebar{background-color:#2a2a2a;border-right-color:#404040}.site-title a{color:#e0e0e0}.post-title a{color:#e0e0e0}.archive-title a{color:#e0e0e0}.post-title a:hover,.navigation a:hover,.social-links a:hover,.archive-title a:hover{color:#4da6ff}.post{border-bottom-color:#404040}.footer{border-top-color:#404040}}</style><link rel=icon type=image/png href=/icons/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/icons/favicon.svg><link rel="shortcut icon" href=/icons/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="philippdubach.com"><link rel=manifest href=/icons/site.webmanifest><meta name=theme-color content="#2c3e50"><meta name=msapplication-TileColor content="#2c3e50"><meta property="og:title" content="philippdubach"><meta property="og:description" content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/"><meta property="og:site_name" content="philippdubach.com"><meta property="og:locale" content="en_US"><meta property="og:logo" content="http://localhost:1313/icons/favicon.ico"><meta property="og:image" content="https://static.philippdubach.com/ograph/ograph-post.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="philippdubach"><meta name=twitter:description content="Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology"><meta name=twitter:image content="https://static.philippdubach.com/ograph/ograph-post.jpg"><script>(function(){let e=[],n=[],t=null;const s=["offsetHeight","offsetWidth","offsetTop","offsetLeft","scrollHeight","scrollWidth","scrollTop","scrollLeft","clientHeight","clientWidth","clientTop","clientLeft"];s.forEach(t=>{const s=Object.getOwnPropertyDescriptor(HTMLElement.prototype,t);s&&s.get&&Object.defineProperty(HTMLElement.prototype,t,{get:function(){return e.length>0&&(console.warn(`⚠️ FORCED REFLOW: Reading ${t} after DOM write!`),console.log("Recent writes:",e),console.log("Element:",this),console.trace()),n.push({prop:t,element:this.tagName}),s.get.call(this)}})});const o=Object.getOwnPropertyDescriptor(HTMLElement.prototype,"style");Object.defineProperty(HTMLElement.prototype,"style",{get:function(){const s=o.get.call(this);return new Proxy(s,{set:function(s,o,i){return e.push({property:o,value:i,element:s.parentElement?.tagName}),n=[],t||(t=requestAnimationFrame(()=>{e=[],t=null})),s[o]=i,!0}})}});const i=Element.prototype.getBoundingClientRect;Element.prototype.getBoundingClientRect=function(){return e.length>0&&(console.warn("⚠️ FORCED REFLOW: getBoundingClientRect() called after DOM write!"),console.trace()),i.call(this)}})()</script></head><body class=linkblog><div class=container><aside class=sidebar><div class=sidebar-content><div class=site-header><h1 class=site-title><a href=http://localhost:1313/>philippdubach</a></h1><p class=site-description>Blog about Personal Projects, Articles and Papers on Economics, Finance and Technology</p></div><nav class=navigation><ul><li><a href=/>Home</a></li><li><a href=/projects/>Projects</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Archive</a></li><li><a href=/index.xml>RSS</a></li></ul></nav><div class=social-links><a href=https://github.com/philippdubach target=_blank rel=noopener>GitHub</a>
<a href=mailto:info@philippdubach.com>Email</a></div></div></aside><main class=content><div class=posts><article class=post><header class=post-header><div class=post-meta><time datetime=2025-11-16T00:00:00Z>November 16, 2025
</time>• <a href=http://localhost:1313/2025/11/16/damodaran-on-golds-2025-surge/ class=permalink>∞</a></div><h2 class=post-title><a href=https://aswathdamodaran.blogspot.com/2025/11/a-golden-year-2025-golds-price-surge.html target=_blank rel=noopener>Damodaran on Gold's 2025 Surge
<span class=external-link>→</span></a></h2></header><div class=post-content><p><a href=https://pages.stern.nyu.edu/~adamodar/>Aswath Damodaran&rsquo;s</a> latest analysis into gold&rsquo;s 2025 surge walks through gold&rsquo;s contradictory nature as a collectible rather than an asset with cash flows, showing why it&rsquo;s impossible to &ldquo;value&rdquo; gold in the traditional sense, yet entirely possible to understand what drives its pricing.</p><p>Even though gold is outperforming almost all other assets in my portfolio this year I fundamentally don&rsquo;t like holding it. I&rsquo;m a <a href=https://buffett.cnbc.com/2011-berkshire-hathaway-annual-meeting/>Buffett disciple</a>: gold is an unproductive asset that generates no earnings, pays no dividends.</p><p>But Damodaran&rsquo;s framework helps to understand why tolerating it anyway might be worth it. It&rsquo;s less an investment than insurance against the tail risks of hyperinflation and catastrophic market dislocations, scenarios where correlations go to one and traditional diversification fails. The dissonance between what I believe intellectually (productive assets compound wealth) and what I&rsquo;m actually doing (holding some gold anyway) probably says more about 2025&rsquo;s macro uncertainty than any principled investment thesis.</p><p><em>Damodaran&rsquo;s blog linked in this post’s title.</em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-11-09T00:00:00Z>November 9, 2025
</time>• <a href=http://localhost:1313/2025/11/09/ai-models-as-standalone-pls/ class=permalink>∞</a></div><h2 class=post-title><a href=https://www.theregister.com/2025/10/29/microsoft_earnings_q1_26_openai_loss/ target=_blank rel=noopener>AI models as standalone P&amp;Ls
<span class=external-link>→</span></a></h2></header><div class=post-content><blockquote><p>Microsoft reported earnings for the quarter ended Sept. [&mldr;] buried in its financial filings were a couple of passages suggesting that OpenAI suffered a net loss of $11.5 billion or more during the quarter.</p></blockquote><p>For every dollar of revenue, they&rsquo;re allegedly spending roughly $5 to deliver the product. What initially sounds like a joke about &ldquo;making it up on volume&rdquo; points to a more fundamental problem facing OpenAI and its competitors. AI companies are locked into continuously releasing more powerful (and expensive) models. If they stop, <a href=https://arxiv.org/abs/2311.16989>open-source alternatives will catch up</a> and offer equivalent capabilities at substantially lower costs. This creates an uncomfortable dynamic. If your current model requires spending more than you earn just to fund the next generation, the path to profitability becomes unclear—perhaps impossible.</p><p>Anthropic CEO Dario Amodei (everybody&rsquo;s favorite AI CEO) recently offered a different perspective in a <a href="https://youtu.be/GcqQ1ebBqkc?si=sEDGAVBuZsjtLpZS&amp;t=1016">conversation with Stripe co-founder John Collison</a>. He argues that treating each model as an independent business unit reveals a different picture than conventional accounting suggests.</p><blockquote><p>Let&rsquo;s say in 2023, you train a model that costs $100 million, and then you deploy it in 2024 and it makes $200 million of revenue.</p></blockquote><p>So far, this looks profitable, a solid 2x return on the training investment. But here&rsquo;s where it gets complicated.</p><blockquote><p>Meanwhile, because of the scaling laws, in 2024, you also train a model that costs $1 billion. If you look in a conventional way at the profit and loss of the company you&rsquo;ve lost $100 million the first year, you&rsquo;ve lost $800 million the second year, and you&rsquo;ve lost $8 billion in the third year, so it looks like it&rsquo;s getting worse and worse.</p></blockquote><p>The pattern continues:</p><blockquote><p>In 2025, you get $2 billion of revenue from that $1 billion model trained the previous year.</p></blockquote><p>Again, viewed in isolation, this model returned 2x its training cost.</p><blockquote><p>And you spend $10 billion to train the model for the following year.</p></blockquote><p>The losses appear to accelerate dramatically, from $100 million to $800 million to $8 billion.</p><p>This is where Amodei&rsquo;s reframing becomes interesting.</p><blockquote><p>If you consider each model to be a company, the model that was trained in 2023 was profitable. You paid $100 million and then it made $200 million of revenue."</p></blockquote><p>He also acknowledges there are inference costs (the actual computing expenses of running the model for users) but suggests these don&rsquo;t fundamentally change the picture in his simplified example.His core argument:</p><blockquote><p>If every model was a company, the model in this example is actually profitable. What&rsquo;s going on is that at the same time as you&rsquo;re reaping the benefits from one company, you&rsquo;re founding another company that&rsquo;s much more expensive and requires much more upfront R&amp;D investment.</p></blockquote><p>This is essentially an argument that AI companies are building a portfolio of profitable products, but the accounting makes it look terrible because each successive &ldquo;product&rdquo; costs 10x more than the last to develop. The losses stem from overlapping these profitable cycles while exponentially increasing investment scale. But this framework only works if two critical assumptions hold: (1) Each model consistently returns roughly 2x its training cost in revenue, and (2) The improvements from spending 10x more justify that investment—meaning customers will pay enough more for the better model to maintain that 2x return.</p><p>Amodei outlines two ways this resolves:</p><blockquote><p>So the way that it&rsquo;s going to shake out is this will keep going up until the numbers go very large and the models can&rsquo;t get larger, and, you know, then it&rsquo;ll be a large, very profitable business.</p></blockquote><p>In this first scenario, scaling hits physical or practical limits. You&rsquo;ve maxed out available compute, data, or capability improvements. Training costs plateau because you literally can&rsquo;t build a meaningfully larger model. At that point, companies stop needing exponentially larger investments and begin harvesting profits from their final-generation models. The second scenario is less optimistic:</p><blockquote><p>Or at some point the models will stop getting better, right? The march to AGI will be halted for some reason.</p></blockquote><p>If the improvements stop delivering proportional returns before reaching natural limits, companies face what Amodei calls overhang.</p><blockquote><p>And then perhaps there&rsquo;ll be some overhang, so there&rsquo;ll be a one-time, &lsquo;Oh man, we spent a lot of money and we didn&rsquo;t get anything for it,&rsquo; and then the business returns to whatever scale it was at.</p></blockquote><p>What Amodei&rsquo;s framework doesn&rsquo;t directly address is the open-source problem. If training Model C costs $10 billion but open-source alternatives <a href=https://synaptic.com/resources/open-source-ai-2024>reach comparable performance six months later</a>, that 2x return window might not materialize. The entire argument depends on maintaining a significant capability lead that customers will pay premium prices for. There&rsquo;s also the question of whether the 2x return assumption holds as models become more expensive. The jump from $100 million to $1 billion to $10 billion in training costs assumes that customers will consistently value the improvements enough to double revenue.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-11-08T00:00:00Z>November 8, 2025
</time>• <a href=http://localhost:1313/2025/11/08/working-with-models/ class=permalink>∞</a></div><h2 class=post-title><a href=https://arxiv.org/abs/2510.21890 target=_blank rel=noopener>Working with Models
<span class=external-link>→</span></a></h2></header><div class=post-content><p>There was this &ldquo;<a href=https://us1.discourse-cdn.com/flex001/uploads/ultralytics1/original/1X/45c604467b6f4212858281cf28f71a77083fb45e.jpeg>I work with Models</a>&rdquo; joke which I first heard years ago from an analyst working on a valuation model (<a href=/2025/10/19/everything-is-a-dcf-model/>see my previous post</a>). I guess it has become more relevant than ever:</p><blockquote><p>This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions.</p></blockquote><p>If you want to get into this topic in the first place, be sure to check out <a href=https://deepgenerativemodels.github.io>Stefano Ermon&rsquo;s CS236 Deep Generative Models Course</a>. Lecture recordings of the full course can also be found on <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8">YouTube</a>.</p><p><em>Original paper linked in this post&rsquo;s title.</em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-10-19T00:00:00Z>October 19, 2025
</time>• <a href=http://localhost:1313/2025/10/19/everything-is-a-dcf-model/ class=permalink>∞</a></div><h2 class=post-title><a href=https://www.morganstanley.com/content/dam/im/assets/publication/thought-leadership/consilient-observer/article_everythingisadcfmodel_us.pdf target=_blank rel=noopener>Everything Is a DCF Model
<span class=external-link>→</span></a></h2></header><div class=post-content><p>A brilliant piece of writing from <a href=https://www.morganstanley.com/im/en-us/individual-investor/about-us/people-and-teams/investment-professionals/michael-mauboussin.html>Michael Mauboussin</a> and <a href=https://www.morganstanley.com/im/en-us/individual-investor/about-us/people-and-teams/investment-professionals/dan-callahan.html>Dan Callahan</a> at Morgan Stanley that was formative in what I personally believe when it comes to valuation.</p><blockquote><p>[…] we want to suggest the mantra &ldquo;everything is a DCF model.&rdquo; The point is that whenever investors value a stake in a cash-generating asset, they should recognize that they are using a discounted cash flow (DCF) model. […] The value of those businesses is the present value of the cash they can distribute to their owners. This suggests a mindset that is very different from that of a speculator, who buys a stock in anticipation that it will go up without reference to its value. Investors and speculators have always coexisted in markets, and the behavior of many market participants is a blend of the two.</p></blockquote><p><em>Original paper linked in this post&rsquo;s title.</em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-10-18T00:00:00Z>October 18, 2025
</time>• <a href=http://localhost:1313/2025/10/18/llm-helped-discover-a-new-cancer-therapy-pathway/ class=permalink>∞</a></div><h2 class=post-title><a href=https://www.biorxiv.org/content/10.1101/2025.04.14.648850v3.full.pdf target=_blank rel=noopener>LLM Helped Discover a New Cancer Therapy Pathway
<span class=external-link>→</span></a></h2></header><div class=post-content><p>Google gets a lot of scrutiny for some of their work in other domains; nevertheless, it&rsquo;s fair to appreciate that they continue to put major resources behind using AI to accelerate therapeutic discovery. The <a href=https://huggingface.co/vandijklab/C2S-Scale-Gemma-2-27B>model</a> and <a href=https://github.com/vandijklab/cell2sentence>resources</a> are open access and available to the research community.</p><blockquote><p>How C2S-Scale 27B works: A major challenge in cancer immunotherapy is that many tumors are &ldquo;cold&rdquo; — invisible to the body&rsquo;s immune system. A key strategy to make them &ldquo;hot&rdquo; is to force them to display immune-triggering signals through a process called antigen presentation. We gave our new C2S-Scale 27B model a task: Find a drug that acts as a conditional amplifier, one that would boost the immune signal only in a specific &ldquo;immune-context-positive&rdquo; environment where low levels of interferon (a key immune-signaling protein) were already present, but inadequate to induce antigen presentation on their own.</p></blockquote><p>From their <a href=https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/>press release</a>:</p><blockquote><p>C2S-Scale generated a novel hypothesis about cancer cellular behavior and we have since confirmed its prediction with experimental validation in living cells. This discovery reveals a promising new pathway for developing therapies to fight cancer.</p></blockquote><p>For a 27B model, that&rsquo;s really really neat! And on a more general note, scaling seems to deliver:</p><blockquote><p>This work raised a critical question: Does a larger model just get better at existing tasks, or can it acquire entirely new capabilities? The true promise of scaling lies in the creation of new ideas, and the discovery of the unknown.</p></blockquote><p>On a more critical note, it would be interesting to see whether this model can perform any better than existing simple linear models for predicting gene expression interactions.</p><p><em>Original bioRxiv paper linked in this post&rsquo;s title.</em></p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-10-12T00:00:00Z>October 12, 2025
</time>• <a href=http://localhost:1313/2025/10/12/the-state-of-ai-report-2025/ class=permalink>∞</a></div><h2 class=post-title><a href="https://docs.google.com/presentation/d/1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go/edit?usp=sharing" target=_blank rel=noopener>The State of AI Report 2025
<span class=external-link>→</span></a></h2></header><div class=post-content><p>This year&rsquo;s rendition of <a href=https://www.stateof.ai>The State of AI Report</a> is making rounds on LinkedIn (yes, LinkedIn the place where the great <a href="https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fy9dk1prvwf2b1.jpg">E = MC2 + AI</a> equation was &ldquo;discovered&rdquo;).</p><p>Worth keeping in mind this is made by <a href=https://www.nathanbenaich.com>Nathan Benaich</a> the Founder of Air Street Capital, a venture capital firm investing in &ldquo;AI-first companies&rdquo;, so obviously comes with a lot of bias. It&rsquo;s also a relatively small, open survey, with 1'200 &ldquo;AI practitioners&rdquo; surveyed.
An example of the bias:</p><blockquote><p>shows that 95% of professionals now use AI at work or home</p></blockquote><p>It&rsquo;s obvious that 95% of professionals don&rsquo;t use AI at work or home, and these results are heavily skewed. Nevertheless, the <a href="https://docs.google.com/presentation/d/1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go/edit?usp=sharing">slide deck</a> has a nice comprehensive review of research headlines over the year:</p><ul><li>OpenAI, Google, Anthropic, and DeepSeek all releasing reasoning models capable of planning, verification, and self-correction.</li><li>China&rsquo;s AI systems closed the gap to establish the country as a credible #2 in global AI capability.</li><li>44% of U.S. businesses now paying for AI tools (up from just 5% in 2023), average contracts reaching $530'000, and 95% of surveyed professionals using AI regularly—while the capability-to-price ratio doubles every 6-8 months.</li><li>Multi-gigawatt data centers backed by sovereign funds compete globally, with power supply and land becoming as critical as GPUs.<br></br><em>(13/10/2025) Update: I was just reminded that a sample size of 1'200 is highly statistically significant, even for a national-level poll. The main concern here, however, remains, which is potential selection bias, likely stemming from the fact that participation is driven by people who want to take the survey. It&rsquo;s unclear how much this bias affects the results, but purely in terms of sample size, it is more than sufficient.</em></li></ul></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-10-11T00:00:00Z>October 11, 2025
</time>• <a href=http://localhost:1313/2025/10/11/popular-science-nobel-prize/ class=permalink>∞</a></div><h2 class=post-title><a href=https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-2.pdf target=_blank rel=noopener>Popular Science Nobel Prize
<span class=external-link>→</span></a></h2></header><div class=post-content><p><a href=https://en.wikipedia.org/wiki/Mary_E._Brunkow>Mary E. Brunkow</a> just won the Nobel Prize in Physiology or Medicine 2025 for their (she was jointly awarded) discoveries concerning <a href=https://en.wikipedia.org/wiki/Peripheral_tolerance>peripheral immune tolerance</a>.</p><blockquote><p>Brunkow, meanwhile, got the news of her prize from an AP photographer who came to her Seattle home in the early hours of the morning. She said she had ignored the earlier call from the Nobel Committee. &ldquo;My phone rang and I saw a number from Sweden and thought: &lsquo;That&rsquo;s just, that&rsquo;s spam of some sort.&rsquo;&rdquo;</p></blockquote><p>The reason why this is worth sharing (besides their fantastic work) is that the Nobel Prize always has a &ldquo;<a href=https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-2.pdf>Popular Science</a>&rdquo; publication with nice layman descriptions of what was discovered and why it was important. It&rsquo;s an in-depth look at the discoveries at a university level I would say. Worth a read!</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-08-30T00:00:00Z>August 30, 2025
</time>• <a href=http://localhost:1313/2025/08/30/agent-based-systems-for-modeling-wealth-distribution/ class=permalink>∞</a></div><h2 class=post-title><a href=https://arxiv.org/abs/1604.02370 target=_blank rel=noopener>Agent-based Systems for Modeling Wealth Distribution
<span class=external-link>→</span></a></h2></header><div class=post-content><p>A question <a href=https://www.youtube.com/garyseconomics>Gary Stevenson</a>, the self-proclaimed <a href=https://on.ft.com/4n7z5jD>best trader in the world</a>, has been asking for some time is <a href=https://uclrethinkingeconomics.com/2025/06/25/gary-stevenson-can-a-wealth-tax-fix-britains-economy/>if a wealth tax can fix Britain&rsquo;s economy</a>.</p><blockquote><p>[&mldr;] he believed the continued parlous state of the economy would halt any interest rate hikes. The reason? Because when ordinary people receive money, they spend it, stimulating the economy, while the wealthy tend to save it. But our economic model promotes the concentration of wealth among a select few at the expense of everybody else&rsquo;s living standards.</p></blockquote><p><em>Owen Jones on Gary Stevenson for <a href=https://www.theguardian.com/commentisfree/2022/jan/13/super-rich-spend-2m-on-whisky-wealth-tax-pandemic>The Guardian</a></em></p><p>Something I generally find very useful and appealing is visualizing systems, models and complexities. Wealth distribution definitely classifies as such a complex system. The <a href=https://arxiv.org/abs/1604.02370>Affine Wealth Model</a></p><blockquote><p>a stochastic, agent-based, binary-transaction Asset-Exchange Model (AEM) for wealth distribution that allows for agents with negative wealth</p></blockquote><p>elegantly demonstrates how random transactions inevitably lead to Pareto distributions without intervention. In this <a href=https://notebooks.manganiello.tech/fabio/wealth-inequality.ipynb>Jupyter Notebook Fabio Manganiello</a> provides great visualizations of the wealth model. He shows how wealth distributes in an open market where a set of agents trades without any mechanisms in place to prevent a situation of extreme inequality.
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/wealth-dist-0-tp5-tax.gif 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/wealth-dist-0-tp5-tax.gif" alt="Animation of two side-by-side histogram charts showing wealth distribution. Left chart titled Wealth Distribution (wealth tax: 0%) Right chart titled Wealth Distribution (wealth tax: 5%)" loading=lazy style=width:100%;height:auto;display:block>
</picture>It can be seen in the left graph that with no tax wealth quickly stashes up in the pockets of a very small group of agents, while most of the other agents end up piling up in the lowest bucket. As we introduce a wealth tax of 25%, then 5% (right graph) and 1% we can see how the distribution becomes more even and therefore more desirable from the perspective of wealth equality, and also very stable over time, with the agents in the highest buckets quickly having at most 3-4x of their initial amount.</p><p>As with any model, the paper as well as the simulation have it&rsquo;s <a href=https://notebooks.manganiello.tech/fabio/wealth-inequality.ipynb#Limitations>limitations</a>, but again my interest is more in the way a few lines of code can visualize a economic relationships elegantly. It would be interesting to further investigate: (1) How sensitive are these equilibrium distributions to the transaction constraint (max_exchanged_share)? Does allowing larger transfers accelerate concentration or fundamentally alter the <a href=https://en.wikipedia.org/wiki/Gini_coefficient>steady-state Gini coefficient</a>? (2) The above wealth tax implementation taxes the sender - but what happens if we model progressive taxation on received amounts above median wealth instead? Does the locus of taxation matter for distributional outcomes?</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-08-23T00:00:00Z>August 23, 2025
</time>•<span class=project-tag>PROJECT</span></div><h2 class=post-title><a href=http://localhost:1313/2025/08/23/visualizing-gradients-with-pytorch/>Visualizing Gradients with PyTorch</a></h2></header><div class=post-content><p><a href=https://en.wikipedia.org/wiki/Gradient>Gradients</a> are one of the most important concepts in calculus and machine learning, but it&rsquo;s often poorly understood. Trying to understand them better myself, I wanted to build a visualization tool that helps me develop the correct mental picture of what the gradient of a function is. I came across <a href=https://github.com/GistNoesis/VisualizeGradient>GistNoesis/VisualizeGradient</a>, so I went on from there to write my own iteration. This mental model generalizes beautifully to higher dimensions and is crucial for understanding optimization algorithms.
<picture style="display:block;width:80%;margin:0 auto;padding:1rem 0"><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/torch-gradients_Figure_2.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/torch-gradients_Figure_2.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/torch-gradients_Figure_2.png 640w" sizes=80vw><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/torch-gradients_Figure_2.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/torch-gradients_Figure_2.png 1024w" sizes=80vw><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/torch-gradients_Figure_2.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/torch-gradients_Figure_2.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/torch-gradients_Figure_2.png 2000w" sizes=80vw><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/torch-gradients_Figure_2.png" alt="2D Gradient Plot: The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent." loading=lazy style=width:100%;height:auto;display:block>
</picture><em>The colored surface shows function values. Black arrows show gradient vectors in the input plane (x-y space), pointing toward the direction of steepest ascent.</em></p><p>If you are interested in having a closer look or replicating my approach, the full project can be found on my <a href=https://github.com/philippdubach/torch-gradients/>GitHub</a>. I&rsquo;m also looking forward to doing something similar on the <a href=https://blog.foletta.net/post/2025-07-14-clt/>Central Limit Theorem</a> as well as doing a short tutorial on <a href=https://static.philippdubach.com/opt_vol_surface_plot_fig1.png>plotting options volatility surfaces with python</a>, a project I have been waiting to finish for some time now.</p></div></article><article class=post><header class=post-header><div class=post-meta><time datetime=2025-07-07T00:00:00Z>July 7, 2025
</time>• <a href=http://localhost:1313/2025/07/07/sentiment-trading-revisited/ class=permalink>∞</a></div><h2 class=post-title><a href=https://arxiv.org/abs/2507.01970 target=_blank rel=noopener>Sentiment Trading Revisited
<span class=external-link>→</span></a></h2></header><div class=post-content><p>Interesting new paper that builds on many of the ideas <a href=/2025/02/20/trading-on-market-sentiment/>I explored in this project</a>. The research, by Ayaan Qayyum, an <a href=https://soe.rutgers.edu/news/ayaan-qayyum-electrical-and-computer-engineering>Undergraduate Research Scholar at Rutgers</a>, shows that the core concept of using advanced language models for sentiment trading is not only viable but highly effective. The study takes a similar but more advanced approach. Instead of using a model like GPT-3.5 to generate a simple sentiment score, it uses <a href=https://platform.openai.com/docs/guides/embeddings/embedding-models>OpenAI&rsquo;s embedding models</a> to convert news headlines into rich, high-dimensional vectors. By training a <a href=https://arxiv.org/html/2507.01970v1/extracted/6556003/diagrams/model_comb_diagram.png>battery of neural networks</a> including</p><blockquote><p>Gated Recurrent Units (GRU), Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), Temporal Convolutional Networks (TCN), and a Feed-Forward Neural Network (FFNN). All were implemented using PyTorch.</p></blockquote><p>on these embeddings alongside economic data, the study found it could <a href=https://arxiv.org/html/2507.01970v1/extracted/6556003/diagrams/models_ranked_smape.png>reduce prediction errors by up to 40%</a> compared to models without the news data.</p><p>The most surprising insight to me, and one that directly addresses the challenge of temporal drift I discussed, was that Qayyum&rsquo;s time-independent models performed just as well, if not better, than the time-dependent ones. By shuffling the data, the models were forced to learn the pure semantic impact of a headline, independent of its specific place in time. This suggests that the market reacts to the substance of news in consistent ways, even if the narratives themselves change.</p></div></article><nav class=pagination><a href=/page/2/ class=next>Older Posts →</a></nav></div></main></div></body></html>