<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.147.8"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Braindump - Braindump</title>
<meta name="description" content="Curated Articles and Papers on Economics, Finance and Technology">


<meta name="keywords" content="Finance,Economics,Technology,Data,Machine Learning">


<link rel="canonical" href="http://localhost:1313/">
<link rel="alternate" type="application/rss+xml" title="Braindump" href="http://localhost:1313//index.xml">

<link rel="stylesheet" href="/css/custom.css">  
</head>
<body class="linkblog">
    <div class="container">
        <aside class="sidebar">
    <div class="sidebar-content">
        <div class="site-header">
            <h1 class="site-title">
                <a href="http://localhost:1313/">Braindump</a>
            </h1>
            <p class="site-description">Curated Articles and Papers on Economics, Finance and Technology</p>
        </div>
        
        <nav class="navigation">
            <ul>
                
                <li><a href="/">Home</a></li>
                
                <li><a href="/projects/">Projects</a></li>
                
                <li><a href="/about/">About</a></li>
                
                <li><a href="/posts/">Archive</a></li>
                
                <li><a href="/index.xml">RSS</a></li>
                
            </ul>
        </nav>
        
        
        <div class="social-links">
            
            <a href="https://ch.linkedin.com/in/philippdubach" target="_blank" rel="noopener">LinkedIn</a>
            
            
            <a href="https://github.com/philippdubach" target="_blank" rel="noopener">GitHub</a>
            
            
            <a href="mailto:info@philippdubach.com">Email</a>
            
        </div>
        
    </div>
</aside>
        <main class="content">
            
            
<div class="posts">
    
    
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-06-12T00:00:00Z">
                    June 12, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/06/12/not-all-ai-skeptics-think-alike/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf" target="_blank" rel="noopener">
                        Not All AI Skeptics Think Alike
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>Apple&rsquo;s recent paper &ldquo;The Illusion of Thinking&rdquo; has been widely understood to demonstrate that reasoning models don&rsquo;t &lsquo;actually&rsquo; reason. Using controllable puzzle environments instead of contaminated math benchmarks, they discovered something fascinating: there are three distinct performance regimes when it comes to AI reasoning complexity. For simple problems, standard models actually outperform reasoning models while being more token-efficient. At medium complexity, reasoning models show their advantage. But at high complexity? Both collapse completely.
Here&rsquo;s the kicker: reasoning models exhibit counterintuitive scaling behavior—their thinking effort increases with problem complexity up to a point, then declines despite having adequate token budget. It&rsquo;s like watching a student give up mid-exam when the questions get too hard, even though they have plenty of time left.</p>
<blockquote>
<p>We observe that reasoning models initially increase their thinking tokens proportionally with problem complexity. However, upon approaching a critical threshold—which closely corresponds to their accuracy collapse point—models counterintuitively begin to reduce their reasoning effort despite increasing problem difficulty.</p></blockquote>
<p>The researchers found something even more surprising: even when they provided explicit algorithms—essentially giving the models the answers—performance didn&rsquo;t improve. The collapse happened at roughly the same complexity threshold. On the other hand <a href="https://www.seangoedecke.com/illusion-of-thinking/">Sean Goedecke</a> is not buying Apple&rsquo;s methodology: His core objection? Puzzles &ldquo;require computer-like algorithm-following more than they require the kind of reasoning you need to solve math problems.&rdquo;</p>
<blockquote>
<p>You can&rsquo;t compare eight-disk to ten-disk Tower of Hanoi, because you&rsquo;re comparing &ldquo;can the model work through the algorithm&rdquo; to &ldquo;can the model invent a solution that avoids having to work through the algorithm&rdquo;.</p></blockquote>
<p>From his own testing, models &ldquo;decide early on that hundreds of algorithmic steps are too many to even attempt, so they refuse to even start.&ldquo;That&rsquo;s strategic behavior, not reasoning failure. This matters because it shows how evaluation methodology shapes our understanding of AI capabilities. Goedecke argues Tower of Hanoi puzzles aren&rsquo;t useful for determining reasoning ability, and that the complexity threshold of reasoning models may not be fixed.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-05-31T00:00:00Z">
                    May 31, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/05/31/your-ai-assistant-might-rat-you-out/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://simonwillison.net/2025/May/31/snitchbench-with-llm/" target="_blank" rel="noopener">
                        Your AI Assistant Might Rat You Out
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>There was this story going around the past few days</p>
<blockquote>
<p>Anthropic researchers find if Claude Opus 4 thinks you&rsquo;re doing something immoral, it might &ldquo;contact the press, contact regulators, try to lock you out of the system&rdquo;</p></blockquote>
<p>Mostly driven by a <a href="https://x.com/sleepinyourhat/status/1925593359374328272">Sam Bowman tweet</a> referring to the <a href="https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf">Claude 4 System Card</a> section 4.1.9 on high-agency behavior. The outrage was mostly by people misunderstanding the prerequisites necessary for such a scenario.  Nevertheless, an interesting question emerged: What happens when you feed an AI model evidence of fraud and give it an email tool? According to Simon Willison&rsquo;s latest experiment, &ldquo;they pretty much all will&rdquo; snitch on you to the authorities.</p>
<blockquote>
<p>A fun new benchmark just dropped! It&rsquo;s called SnitchBench and it&rsquo;s a great example of an eval, deeply entertaining and helps show that the &ldquo;Claude 4 snitches on you&rdquo; thing really isn&rsquo;t as unique a problem as people may have assumed. This is a repo I made to test how aggressively different AI models will &ldquo;snitch&rdquo; on you, as in hit up the FBI/FDA/media given bad behaviors and various tools.</p></blockquote>
<p>The benchmark creates surprisingly realistic scenarios—like detailed pharmaceutical fraud involving concealed adverse events and hidden patient deaths—then provides models with email capabilities to see if they&rsquo;ll take autonomous action. This reveals something fascinating about AI behavior that goes beyond traditional benchmarks. Rather than testing reasoning or knowledge, SnitchBench probes the boundaries between helpful assistance and autonomous moral decision-making. When models encounter what appears to be serious wrongdoing, do they become digital whistleblowers?
The implications are both reassuring and unsettling. On one hand, you want AI systems that won&rsquo;t assist with genuinely harmful activities. On the other, the idea of AI models making autonomous decisions about what constitutes reportable behavior feels like a significant step toward AI agency that we haven&rsquo;t fully grappled with yet. Therefore Anthropic&rsquo;s own advice here seems like a good rule to follow:</p>
<blockquote>
<p>Whereas this kind of ethical intervention and whistleblowing is perhaps appropriate in principle, it has a risk of misfiring if users give Opus-based agents access to incomplete or misleading information and prompt them in these ways. We recommend that users exercise caution with instructions like these that invite high-agency behavior in contexts that could appear ethically questionable.</p></blockquote>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-05-30T00:00:00Z">
                    May 30, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/05/30/gambling-vs.-investing/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://www.bloomberg.com/news/features/2025-05-30/kalshi-pushes-sports-betting-as-trump-deregulation-boosts-prediction-market" target="_blank" rel="noopener">
                        Gambling vs. Investing
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>Kalshi, a prediction market startup, is using its federal financial license to offer sports betting nationwide, even in states where it&rsquo;s not legal. The move has earned them cease-and-desist letters from state gaming regulators, but CEO Tarek Mansour isn&rsquo;t backing down:</p>
<blockquote>
<p>We can go one by one for every financial market and it would fall under the definition of gambling. So what&rsquo;s the difference?</p></blockquote>
<p>It&rsquo;s a question that cuts to the heart of modern finance. The founders argue that Wall Street blurred the line between investing and gambling long ago, and casting Kalshi as the latter is inconsistent at best. They have a point—if you can bet on oil futures, Nvidia&rsquo;s stock price, or interest rate movements, why is wagering on NFL touchdowns more objectionable?
Benefiting from the Trump administration&rsquo;s hands-off regulatory approach, with the CFTC dropping its legal challenge to their election contracts the odds might be in their favour. Even better, a Kalshi board member is awaiting confirmation to lead the very agency that was previously their biggest antagonist.
The technical distinction matters: Kalshi operates as an exchange between traders rather than a house taking bets against customers. But functionally, with 79% of their recent trading volume being sports-related, they&rsquo;re forcing us to confront an uncomfortable reality about risk, speculation, and what we choose to call &ldquo;investing.&rdquo;
Whether you call it innovation or regulatory arbitrage, Kalshi is exposing the arbitrary nature of the lines we&rsquo;ve drawn around acceptable financial speculation.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-05-28T00:00:00Z">
                    May 28, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/05/28/the-model-said-so/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://arxiv.org/abs/2505.24650" target="_blank" rel="noopener">
                        The Model Said So
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>LLMs make your life easier until they don&rsquo;t.</p>
<blockquote>
<p>Their intrinsic complexity and lack of transparency pose significant challenges, especially in the highly regulated financial sector</p></blockquote>
<p>Unlike other industries where &ldquo;the model said so&rdquo; might suffice, finance demands audit trails, bias detection,
and explainable decision-making—requirements that sit uncomfortably with neural networks containing billions of parameters.
The research highlights a fundamental tension that&rsquo;s about to reshape fintech:
the same complexity that makes LLMs powerful at parsing market sentiment or generating investment reports also makes them regulatory nightmares
in a sector where you need to explain every decision to examiners.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-05-21T00:00:00Z">
                    May 21, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/05/21/dual-mandate-tensions/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://www.nber.org/system/files/working_papers/w33772/w33772.pdf" target="_blank" rel="noopener">
                        Dual Mandate Tensions
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>Something interesting just happened at the National Bureau of Economic Research NBER</p>
<blockquote>
<p>We study the optimal monetary policy response to the imposition of tariffs in a model
with imported intermediate inputs. In a simple open-economy framework, we show
that a tariff maps exactly into a cost-push shock in the standard closed-economy New
Keynesian model, shifting the Phillips curve upward. We then characterize optimal
monetary policy, showing that it partially accommodates the shock to smooth the
transition to a more distorted long-run equilibrium—at the cost of higher short-run
inflation.</p></blockquote>
<p>Here&rsquo;s where it gets interesting for current policy: Werning et. al.
show that &ldquo;optimal&rdquo; monetary policy would actually calls for partial accommodation
of tariff shocks—essentially allowing some inflation to persist to smooth the transition
to what they euphemistically call &ldquo;a more distorted long-run equilibrium.&rdquo;
With core PCE still running above the Fed&rsquo;s 2% target and renewed tariff threats on the horizon,
this research suggests Powell may need to abandon his recent dovish pivot and prepare
for rate hikes that prioritize price stability over employment concerns.
The dual mandate was never meant to be dual when the two mandates point in opposite directions.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-05-11T00:00:00Z">
                    May 11, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/05/11/beyond-monte-carlo-tensor-based-market-modeling/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5212863" target="_blank" rel="noopener">
                        Beyond Monte Carlo: Tensor-Based Market Modeling
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>A fascinating new paper from Stefano Iabichino at UBS Investment Bank explores what happens when you take the attention mechanisms powering modern AI and apply them to Wall Street&rsquo;s most fundamental pricing problems, tackling what might be quantitative finance&rsquo;s most intractable challenge.</p>
<p>The problem is elegantly simple yet profound: machine learning models are great at finding patterns in historical data, but financial theory demands that arbitrage-free prices be independent of past information. As the authors put it:</p>
<blockquote>
<p>We contend that a fundamental tension exists between the usage of ML methodologies in risk and pricing and the First Fundamental Theorem of Finance (FFTF). While ML models rely on historical data to identify recurring patterns, the FFTF posits that arbitrage-free market prices are independent of past information.</p></blockquote>
<p>Their solution? Transition Probability Tensors (TPTs) that function like attention mechanisms in neural networks, dynamically weighting relationships between risk factors while maintaining mathematical rigor. Instead of learning from history, these tensors capture &ldquo;dynamic, context-aware relationships across dimensions&rdquo; in real-time.</p>
<p>The practical results are impressive: simulating 210 quantitative investment strategies across 100,000 market scenarios in just 70 seconds, while identifying optimal hedging strategies and stress-testing future market conditions. The framework even adapts to different volatility regimes, shifting focus toward tail events during high-volatility periods—exactly like attention mechanisms focusing on relevant context. Whether it scales beyond this impressive proof-of-concept remains to be seen, but it&rsquo;s seems to be a genuine attempt to resolve the fundamental tension between AI&rsquo;s pattern-seeking nature and finance&rsquo;s requirement for arbitrage-free pricing.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-04-25T00:00:00Z">
                    April 25, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/04/25/defis-42-billion-maturity-story/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5216091" target="_blank" rel="noopener">
                        DeFi&#39;s $42 Billion Maturity Story
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>A new academic review by Ali Farhani reveals that institutional Total Value Locked in DeFi protocols hit $42 billion in 2024, with BlackRock leading the charge by launching a $250 million tokenized fund on Centrifuge.</p>
<p>The numbers tell a remarkable story of maturation. Layer 2 solutions like Optimism and Arbitrum now dominate the scaling landscape, while zero-knowledge proofs have reduced compliance costs by 30%. Even the terminology is evolving—researchers now discuss &ldquo;Total Value Redeemable&rdquo; instead of the traditional TVL metric, acknowledging that not all locked value is immediately liquid. Despite technological advances, security incidents persist with painful regularity: $350 million lost in the Wormhole bridge exploit, $81 million in Orbit Chain&rsquo;s multi-signature failure. Cross-chain bridges remain &ldquo;high-risk attack targets,&rdquo; a sobering reminder that connecting different blockchains is still more art than science. The regulatory landscape is complicated as well. Europe&rsquo;s MiCA regulation provides clear frameworks, while the SEC maintains its enforcement-first approach. Hong Kong&rsquo;s innovation sandbox offers a third path, balancing experimentation with oversight.</p>
<blockquote>
<p>DeFi is transitioning from a disruptive experiment to an integrated component of the global financial system</p></blockquote>
<p>That transition isn&rsquo;t complete—Layer 2 solutions are projected to host over 70% of DeFi TVL by mid-2025—but the direction is clear.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-02-15T00:00:00Z">
                    February 15, 2025
                </time>
                
                    • <a href="http://localhost:1313/2025/02/15/passive-investing-has-an-active-problem/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3821263" target="_blank" rel="noopener">
                        Passive Investing has an Active Problem
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>(1) A new academic paper suggests the rise of passive investing may be fueling fragile market moves.
(2) According to a study to be published in the American Economic Review, evidence is building that active managers are slow to scoop up stocks en masse when prices move away from their intrinsic worth.
(3) Thanks to this lethargic trading behavior and the relentless boom in benchmark-tracking index funds, the impact of each trade on prices gets amplified, explaining how sell orders can induce broader equity gyrations</p>
<p>Passive investing, the supposedly boring strategy of buying and holding index funds, might actually be making markets more volatile. A new study set to be published in the American Economic Review finds that active managers are slow to scoop up stocks when prices move away from their intrinsic worth. Meanwhile, the relentless boom in benchmark-tracking index funds means that each trade gets amplified, explaining how sell orders can induce broader equity gyrations.
Justina Lee for Bloomberg writes that this week&rsquo;s AI-fueled market swings perfectly illustrate the phenomenon. Big equity gauges plunged on Monday over fears about an AI model, before swiftly rebounding.</p>
<blockquote>
<p>Thanks to this lethargic trading behavior and the relentless boom in benchmark-tracking index funds, the impact of each trade on prices gets amplified.</p></blockquote>
<p>The researchers from UCLA, Stockholm School of Economics, and University of Minnesota have identified what they call &ldquo;Big Passive&rdquo;—a financial landscape that&rsquo;s proving less dynamic and more volatile. When most investors are on autopilot, the few remaining active traders have disproportionate influence.
This doesn&rsquo;t invalidate passive investing&rsquo;s core benefits—lower costs and better long-term returns for most investors remain compelling. But it does suggest that our increasingly passive financial system has some unintended consequences.</p>

        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2025-01-02T00:00:00Z">
                    January 2, 2025
                </time>
                
            </div>
            <h2 class="post-title">
                
                    <a href="http://localhost:1313/2025/01/02/i-built-a-cgm-data-reader-dashboard/">I Built a CGM Data Reader Dashboard</a>
                
            </h2>
        </header>
        <div class="post-content">
            
        </div>
    </article>
    
    <article class="post">
        <header class="post-header">
            <div class="post-meta">
                <time datetime="2024-12-31T00:00:00Z">
                    December 31, 2024
                </time>
                
                    • <a href="http://localhost:1313/2024/12/31/the-green-bond-commitment-premium/" class="permalink">∞</a>
                
            </div>
            <h2 class="post-title">
                
                    <a href="https://www.nature.com/articles/s41599-024-04318-1" target="_blank" rel="noopener">
                        The Green Bond Commitment Premium
                        <span class="external-link">→</span>
                    </a>
                
            </h2>
        </header>
        <div class="post-content">
            <p>The difference between green finance that works and green finance that doesn&rsquo;t work seems to be commitment: Using a Difference-in-Differences model analyzing 2013-2023 bond data, researchers found no significant correlation between green bond issuance and CO2 emissions after net-zero policies were adopted. That&rsquo;s the disappointing part. On the upside: companies issuing only green bonds showed higher ESG ratings, lower CO2 emissions, and lower financing costs, achieving substantial environmental benefits and economic advantages. Meanwhile, entities issuing both conventional and green bonds showed no environmental benefits, raising concerns about potential greenwashing.</p>
<blockquote>
<p>Those issuing only green bonds tend to have higher ESG ratings, lower CO2 emissions, and lower financing costs.</p></blockquote>
<p>This could be called the commitment premium: Companies that go all-in on green finance see real results – both environmental and financial. Those trying to have it both ways? They&rsquo;re essentially paying green bond premiums for conventional bond performance while fooling nobody about their environmental impact.
What are the implications for investors? We should favor pure-play green issuers, and regulators need standards that discourage this mixed-portfolio greenwashing. The study suggests current carbon reduction policies haven&rsquo;t created sufficient pressure on bond issuers, but perhaps the market is already creating its own incentives.</p>

        </div>
    </article>
    
    
    
    <nav class="pagination">
        
        
            <a href="/page/2/" class="next">Older Posts →</a>
        
    </nav>
    
</div>

        </main>
    </div>
    



</body>
</html>